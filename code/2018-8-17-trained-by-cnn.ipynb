{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Date**: 2018-08-17\n",
    "\n",
    "**Authors**: Zhanyuan Zhang\n",
    "\n",
    "**Purpose**: Apply convolutional neural network (CNN) to train the binary classificaton model. \n",
    "- Use operations like 1D convolution, maxpooling, and dropout to improve accuracy. \n",
    "- Add bias in layers. \n",
    "- Use Relu for learning session, and softmax for final classification.\n",
    "\n",
    "**Background**: Current model trained by recurent neural network (RNN) gives low accuracy. The reason why we switch from CNN to RNN was that this somehow improved the accuracy by 10%. However, given the math behind these two neural networks, CNN should be better in handling spacial data, which is in our case, since the order in a nucleotide sequence does matter. \n",
    "\n",
    "**Experiment**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from utility import flatten\n",
    "from utility import curtail\n",
    "from utility import prepare_input\n",
    "from utility import to_np_array\n",
    "from utility import unpickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_buffer_path = \"/home/ubuntu/formatted/10_percent/random_0.1_instance_7.txt\"\n",
    "# random_buffer_path = \"/home/ubuntu/formatted/random_sequences/random_sequence_buffer.txt\"\n",
    "curtail_len = 3000\n",
    "motif_num = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_record_list = unpickle(real_buffer_path)\n",
    "len(seq_record_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell randomly shuffles the sequences. The shuffling ensures that, for each DNA section (each consists of 24 segments), there are definitely some sequences being allocated to the training data. In this way, the final trained model would be able to learn all the characteristics from the data we have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from random import shuffle\n",
    "\n",
    "first_list = [] # to add to training set\n",
    "second_list = [] # to add to test set\n",
    "current = [] # contains all 24 sequences from the same DNA section\n",
    "\n",
    "for i in range(len(seq_record_list)):\n",
    "    current.append(seq_record_list.pop())\n",
    "    if len(current) == 24:\n",
    "        shuffle(current) # Shuffle the 24 sequences from the same DNA section\n",
    "        random_select = random.randint(18, 24) # Allocate the number of sequences to the training set\n",
    "        first_list.extend(current[:random_select])\n",
    "        second_list.extend(current[random_select:])\n",
    "        current = []\n",
    "\n",
    "shuffle(first_list) # Shuffle again to eliminate dependencies\n",
    "shuffle(second_list) # Shuffle again to eliminate dependencies\n",
    "\n",
    "seq_record_list = first_list + second_list\n",
    "\n",
    "print(\"Number of sequences in training/validation set are: \" + str(len(first_list)))\n",
    "print(\"Number of sequences in testing set are: \" + str(len(second_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_num = len(first_list)\n",
    "test_num = len(second_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell transforms the data into a format that is recognizable by the neural network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = prepare_input(train_val_num, test_num, curtail_len, seq_record_list, motif_num)\n",
    "X_train, y_train, X_test, y_test = to_np_array(X_train, y_train, X_test, y_test)\n",
    "\n",
    "# Check the shape of training and testing data\n",
    "[X_train.shape, y_train.shape, X_test.shape, y_test.shape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Dropout\n",
    "from keras.activations import relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 5e-2\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=1, kernel_size=210, input_shape=(21000, 1, 1), activation=\"relu\")\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Conv1D(filters=1, kernel_size=420, activation=\"relu\")\n",
    "model.add(MaxPooling1D())\n",
    "model.add(Flatten())\n",
    "model.add(Dense(1024, activation=\"relu\"))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(2, activation=\"softmax\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=Adam(lr=LR), \n",
    "                             loss='categorical_crossentropy',\n",
    "                             metrics=['acc'])\n",
    "history = model.fit(X_train_rnn, y_train, epochs=30, batch_size=128, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "accacc  ==  historyhistory..historyhistory[['acc''acc']]\n",
    " val_accval_acc  ==  historyhistory..historyhistory[['val_acc''val_acc ]\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('epoches')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoches')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
