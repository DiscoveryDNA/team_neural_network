{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook is to build a very elementary neural network, trying to predict the expression of certain genes based on DNA sequences in non-coding regions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from Bio import SeqIO\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Processing\n",
    "We first perform the **one hot encoding** to translate the DNA based \"AGCT\" into corresponding 0/1 values. One thing to note is that there does exist 'n's in lots of DNA sequences, and we treat them as all false."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_pairs = {'A': [1, 0, 0, 0], \n",
    "'C': [0, 1, 0, 0],\n",
    "'G': [0, 0, 1, 0],\n",
    "'T': [0, 0, 0, 1],\n",
    "'a': [1, 0, 0, 0],\n",
    "'c': [0, 1, 0, 0],\n",
    "'g': [0, 0, 1, 0],\n",
    "'t': [0, 0, 0, 1],\n",
    "'n': [0, 0, 0, 0],\n",
    "'N': [0, 0, 0, 0]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following are some functions to get the one hot encoded DNA data into some input matrix that can be fed into neural network algorithms. The major things to note are the following:\n",
    "1. DNA sequences are of difference lengths, some very short (100~ bases), some very long (3000~ bases). Since most sequences are in the length range 1000 - 2000, we decide to only take the first 1000 bases of each sequence to train the neural network and make the predictions. If too long, simply truncate it to length 1000. If too short, simply fill with zeros to extend it. \n",
    "2. DNA sequences are in different strands, some in negative strand, some in positive. We take the complement of the sequence if it is taken form the negative strand so thsat all our data is from the same (positive) strand.\n",
    "3. The entire sequence is *flattend*. For example, AGCT would be transformed into [1,0,0,0,0,0,1,0,0,1,0,0,0,0,0,1] where the first four represent A and the next four represent G and so on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_sequence(length, sequence):\n",
    "    if len(sequence) > length:\n",
    "        aligned_seq = sequence[:length]\n",
    "    else:\n",
    "        aligned_seq = sequence + [0]*(length-len(sequence))\n",
    "    return aligned_seq\n",
    "    \n",
    "def to_positive_strand(strand, sequence):\n",
    "    if strand == '-':\n",
    "        unflattened_seq = [base_pairs[n] for n in sequence.complement()]\n",
    "    else:\n",
    "        unflattened_seq = [base_pairs[n] for n in sequence]\n",
    "    return unflattened_seq\n",
    "\n",
    "def process_seq_record(seq_record, X, y):\n",
    "    header = seq_record.description.split('|')\n",
    "    expressed = int(header[1])\n",
    "    y.append(expressed)\n",
    "    unflattened_seq = to_positive_strand(header[3], seq_record.seq)\n",
    "    flattened_seq = [i for x in unflattened_seq for i in x]\n",
    "    aligned_seq = align_sequence(4000, flattened_seq)\n",
    "    X.append(np.array(aligned_seq))\n",
    "    \n",
    "def read_file(file, X, y):\n",
    "    seq_record_list = list(SeqIO.parse(\"data/input/3.24_species_only/\" + file,\"fasta\"))\n",
    "    for i in range(len(seq_record_list)):\n",
    "        process_seq_record(seq_record_list[i], X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training size is the number of files to read for training. Read 100 files would give us 2400 sequences. <br/> For this simple model, we use 2400 sequence to train the neural network and 240 sequences to test its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_size = 100\n",
    "test_size = 10\n",
    "file_count = 0\n",
    "\n",
    "X_train = []\n",
    "y_train = []\n",
    "X_test = []\n",
    "y_test = []\n",
    "\n",
    "for file in os.listdir(\"data/input/3.24_species_only\"):\n",
    "    if (file_count < training_size):\n",
    "        read_file(file, X_train, y_train)\n",
    "    elif (file_count < training_size + test_size):\n",
    "        read_file(file, X_test, y_test)\n",
    "    file_count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We examine the shape of all the training and test data matrix to check that the above code works as we expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2400, 4000), (2400, 1), (240, 4000), (240, 1)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = np.array(X_train).astype(int)\n",
    "y_train = np.transpose(np.array([y_train]).astype(int))\n",
    "X_test = np.array(X_test).astype(int)\n",
    "y_test = np.transpose(np.array([y_test]).astype(int))\n",
    "[X_train.shape, y_train.shape, X_test.shape, y_test.shape]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network\n",
    "Now that we have the data ready in the desired numpy array format with correct shapes, we can proceed to train the neural network with our training data in tensorflow and use our test data to see how accurate it performs.\n",
    "\n",
    "**TODO**: Fix the problem and somehow make the neural network actually **RUN**!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.placeholder(tf.float32, [None, 4000])\n",
    "W = tf.Variable(tf.truncated_normal([4000, 1] ,stddev=0.1))\n",
    "B = tf.Variable(tf.zeros([1]))\n",
    "\n",
    "# model\n",
    "Y = tf.nn.softmax(tf.matmul(X, W) + B)\n",
    "# placeholder for correct labels\n",
    "Y_ = tf.placeholder(tf.float32, [None, 1])\n",
    "init = tf.initialize_all_variables()\n",
    "\n",
    "cross_entropy = -tf.reduce_sum(Y_ * tf.log(Y))\n",
    "\n",
    "# % of correct answers found in batch\n",
    "is_correct = tf.equal(tf.argmax(Y,1), tf.argmax(Y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))\n",
    "\n",
    "optimizer = tf.train.GradientDescentOptimizer(0.003)\n",
    "train_step = optimizer.minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, -0.0]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "train_data={X: X_train, Y_: y_train}\n",
    "sess.run([accuracy, cross_entropy], feed_dict=train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0, -0.0]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data={X: X_test, Y_: y_test}\n",
    "sess.run([accuracy, cross_entropy], feed_dict=test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
