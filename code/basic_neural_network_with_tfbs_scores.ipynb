{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the `pickle` buffered list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"list_buffer.txt\", \"rb\") as buff:\n",
    "    seq_record_list = pickle.load(buff)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell transforms the data into a format that is recognizable by the neural network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function to flatten a 2d list to 1d.\n",
    "# Input: [[1, 2], [2, 3], [3, 4, 5]]\n",
    "# Output: [1, 2, 2, 3, 3, 4, 5]\n",
    "def flatten(lst):\n",
    "    new_lst = []\n",
    "    for sub_lst in lst:\n",
    "        for item in sub_lst:\n",
    "            new_lst.append(item)\n",
    "    return new_lst\n",
    "\n",
    "# A helper function to transform a lst so that its length becomes read_len by:\n",
    "# 1. If len(lst) > read_len, curtail the end of the lst.\n",
    "# 2. If len(lst) < read_len, keep extending the end of the lst with 0 (NA).\n",
    "def curtail(lst, read_len):\n",
    "    if len(lst) > read_len:\n",
    "        lst = lst[:read_len]\n",
    "    else:\n",
    "        for i in range(read_len - len(lst)):\n",
    "            lst.append([0, 0, 0, 0, 0, 0, 0])\n",
    "    return lst\n",
    "\n",
    "# Produce the train-test split\n",
    "# length_read: the length that you want all DNA sequences to conform to\n",
    "def prepare_input(training_size, test_size, length_read):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    seq_count = 0\n",
    "    while seq_count < training_size:\n",
    "        X_train.append(flatten(curtail(seq_record_list[seq_count][3], length_read)))\n",
    "        y_train.append(int(seq_record_list[seq_count][1]))\n",
    "        seq_count += 1\n",
    "    while seq_count < (training_size + test_size):\n",
    "        X_test.append(flatten(curtail(seq_record_list[seq_count][3], length_read)))\n",
    "        y_test.append(int(seq_record_list[seq_count][1]))\n",
    "        seq_count += 1\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# Turn list into numpy tensors that can directly feed into a neural network model\n",
    "def to_np_array(X_train, y_train, X_test, y_test):\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    if len(y_train.shape) == 1:\n",
    "        y_train = np.transpose(np.array([y_train]))\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.transpose(np.array(y_test))\n",
    "    if len(y_test.shape) == 1:\n",
    "        y_test = np.transpose(np.array([y_test]))\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(9600, 14000), (9600, 1), (1152, 14000), (1152, 1)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train, X_test, y_test = prepare_input(9600, 1152, 2000)\n",
    "X_train, y_train, X_test, y_test = to_np_array(X_train, y_train, X_test, y_test)\n",
    "[X_train.shape, y_train.shape, X_test.shape, y_test.shape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input, Dense\n",
    "from keras.models import Model, Sequential"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The rest of the cells build a basic neural network, just for the sake of testing whether the data is usable.\n",
    "\n",
    "Using this neural network prototype, we can achieve a test accuracy of 0.652, incating lots of improvement potentials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_nn(X_train, y_train, pr):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(units=1000, activation='relu', input_dim=14000))\n",
    "    model.add(Dense(units=400, activation='relu'))\n",
    "    model.add(Dense(units=40, activation='relu'))\n",
    "    model.add(Dense(units=10, activation='elu'))\n",
    "    model.add(Dense(units=1, activation='sigmoid'))\n",
    "    model.compile(optimizer = 'SGD',\n",
    "                  loss = 'binary_crossentropy',\n",
    "                  metrics = ['accuracy'])\n",
    "    model.fit(X_train, y_train, batch_size=100, epochs=5, verbose = pr)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(model, X_test, y_test):\n",
    "    result = model.predict(X_test)\n",
    "    correct = list(np.apply_along_axis(lambda x: 0 if x<0.5 else 1, 1, result))==y_test.ravel()\n",
    "    return round(sum(correct)/y_test.shape[0], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "9600/9600 [==============================] - 53s 6ms/step - loss: 0.3456 - acc: 0.8579\n",
      "Epoch 2/5\n",
      "9600/9600 [==============================] - 2s 215us/step - loss: 0.0138 - acc: 0.9997\n",
      "Epoch 3/5\n",
      "9600/9600 [==============================] - 2s 212us/step - loss: 0.0045 - acc: 1.0000\n",
      "Epoch 4/5\n",
      "9600/9600 [==============================] - 2s 212us/step - loss: 0.0025 - acc: 1.0000\n",
      "Epoch 5/5\n",
      "9600/9600 [==============================] - 2s 213us/step - loss: 0.0017 - acc: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.47"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_accuracy(train_nn(X_train, y_train, 1), X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
