{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Date: 2018-9-28\n",
    "\n",
    "Author: Adam Stafford\n",
    "\n",
    "Purpose: Testing a multiclassifcation scheme, where gene expression is separated by developmental stage.\n",
    "\n",
    "Background:\n",
    "\n",
    "* This experiment is a modification of the previous experiments in which transcription factor binding site data and DNA sequences were used to predict gene expression (regardless of developmental stage), to test whether separating developmental stages would improve accuracy.\n",
    "* GPU is necessary to run this notebook.\n",
    "\n",
    "Experiment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-1da603b7b13b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Path variables, `classes_path` is new in this experiment, and refers to the path to the file storing the developmental stages of expression data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_buffer_path = \"/home/ubuntu/newOutput/10_percent/random_0.1_instance_7.txt\"\n",
    "random_buffer_path = \"/home/ubuntu/newOutput/random_sequences/random_sequence_buffer.txt\"\n",
    "classes_path = \"/home/ubuntu/data/team_neural_network/data/input/classification_table3_21Aug2018.csv\"\n",
    "curtail_len = 3000\n",
    "motif_num = 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script replaces the expression column from the existing data (which is restricted to 0 for no expression, 1 for expression) with a string containing the developmental stage data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(real_buffer_path, \"rb\") as buff:\n",
    "    seq_record_list = pickle.load(buff)\n",
    "expression = []\n",
    "with open(classes_path, encoding='utf-8') as csv_file:\n",
    "    for a_line in csv_file:\n",
    "        curr_line = a_line.split(',')\n",
    "        stage = curr_line[3]\n",
    "        vtid = curr_line[1]\n",
    "        if vtid != '\"VTID\"':\n",
    "            expression.append([vtid, stage])\n",
    "for a in range(0,len(seq_record_list)):\n",
    "    seq_record_list[a][0] = seq_record_list[a][0].split('|')[0][2:]    \n",
    "for a in range(0, len(expression)):\n",
    "    expression[a][0] = expression[a][0][3:-1]\n",
    "seq_record_list = pd.DataFrame(seq_record_list)\n",
    "seq_record_list.columns = ['vtid', 1, 2, 3]\n",
    "expression = pd.DataFrame(expression)\n",
    "expression.columns = ['vtid', 1]\n",
    "seq_record_list = seq_record_list.merge(expression, on='vtid')\n",
    "seq_record_list = seq_record_list.values.tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell transforms the data into a format that is recognizable by the neural network model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "from random import shuffle\n",
    "\n",
    "first_list = [] # to add to training set\n",
    "second_list = [] # to add to test set\n",
    "current = [] # contains all 24 sequences from the same DNA section\n",
    "\n",
    "for i in range(len(seq_record_list)):\n",
    "    current.append(seq_record_list.pop())\n",
    "    if len(current) == 24:\n",
    "        shuffle(current) # Shuffle the 24 sequences from the same DNA section\n",
    "        random_select = random.randint(18, 24) # Allocate the number of sequences to the training set\n",
    "        first_list.extend(current[:random_select])\n",
    "        second_list.extend(current[random_select:])\n",
    "        current = []\n",
    "\n",
    "shuffle(first_list) # Shuffle again to eliminate dependencies\n",
    "shuffle(second_list) # Shuffle again to eliminate dependencies\n",
    "\n",
    "seq_record_list = first_list + second_list\n",
    "\n",
    "print(\"Number of sequences in training/validation set are: \" + str(len(first_list)))\n",
    "print(\"Number of sequences in testing set are: \" + str(len(second_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_val_num = len(first_list)\n",
    "test_num = len(second_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function to flatten a 2d list to 1d.\n",
    "# Input: [[1, 2], [2, 3], [3, 4, 5]]\n",
    "# Output: [1, 2, 2, 3, 3, 4, 5]\n",
    "def flatten(lst):\n",
    "    new_lst = []\n",
    "    for sub_lst in lst:\n",
    "        for item in sub_lst:\n",
    "            new_lst.append(item)\n",
    "    return new_lst\n",
    "\n",
    "# A helper function to transform a lst so that its length becomes read_len by:\n",
    "# 1. If len(lst) > read_len, curtail the end of the lst.\n",
    "# 2. If len(lst) < read_len, keep extending the end of the lst with 0 (NA).\n",
    "def curtail(lst, read_len, motif_number):\n",
    "    if len(lst) > read_len:\n",
    "        lst = lst[:read_len]\n",
    "    else:\n",
    "        for i in range(read_len - len(lst)):\n",
    "            lst.append([0 for _ in range(motif_number + 4)])\n",
    "    return lst\n",
    "\n",
    "# Produce the train-test split\n",
    "# length_read: the length that you want all DNA sequences to conform to\n",
    "def prepare_input(training_size, test_size, length_read, original_list, motif_number):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    seq_count = 0\n",
    "    while seq_count < training_size:\n",
    "        X_train.append(flatten(curtail(original_list[seq_count][3], length_read, motif_number)))\n",
    "        y_train.append(original_list[seq_count][4])\n",
    "        seq_count += 1\n",
    "    while seq_count < (training_size + test_size):\n",
    "        X_test.append(flatten(curtail(original_list[seq_count][3], length_read, motif_number)))\n",
    "        y_test.append(original_list[seq_count][4])\n",
    "        seq_count += 1\n",
    "    return X_train, y_train, X_test, y_test\n",
    "\n",
    "# Turn list into numpy tensors that can directly feed into a neural network model\n",
    "def to_np_array(X_train, y_train, X_test, y_test):\n",
    "    X_train = np.array(X_train)\n",
    "    y_train = np.array(y_train)\n",
    "    if len(y_train.shape) == 1:\n",
    "        y_train = np.transpose(np.array([y_train]))\n",
    "    X_test = np.array(X_test)\n",
    "    y_test = np.transpose(np.array(y_test))\n",
    "    if len(y_test.shape) == 1:\n",
    "        y_test = np.transpose(np.array([y_test]))\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = prepare_input(train_val_num, test_num, curtail_len, seq_record_list, motif_num)\n",
    "X_train, y_train, X_test, y_test = to_np_array(X_train, y_train, X_test, y_test)\n",
    "[X_train.shape, y_train.shape, X_test.shape, y_test.shape]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code transforms the development stage srings into integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_train_new = [];\n",
    "for row in y_train:\n",
    "    a = [0]*64\n",
    "    count = 0\n",
    "    if re.search('4_6', row[0]):\n",
    "        count+=1\n",
    "    if re.search('7_8', row[0]):\n",
    "        count+=2\n",
    "    if re.search('9_10', row[0]):\n",
    "        count+=4\n",
    "    if re.search('11_12', row[0]):\n",
    "        count+=8\n",
    "    if re.search('13_14', row[0]):\n",
    "        count+=16\n",
    "    if re.search('15_16', row[0]):\n",
    "        count+=32\n",
    "    a[count] = 1\n",
    "    y_train_new.append(a)\n",
    "y_train_new = np.asarray(y_train_new)\n",
    "y_test_new = [];\n",
    "for row in y_train:\n",
    "    a = [0]*64\n",
    "    count = 0\n",
    "    if re.search('4_6', row[0]):\n",
    "        count+=1\n",
    "    if re.search('7_8', row[0]):\n",
    "        count+=2\n",
    "    if re.search('9_10', row[0]):\n",
    "        count+=4\n",
    "    if re.search('11_12', row[0]):\n",
    "        count+=8\n",
    "    if re.search('13_14', row[0]):\n",
    "        count+=16\n",
    "    if re.search('15_16', row[0]):\n",
    "        count+=32\n",
    "    a[count] = 1\n",
    "    y_test_new.append(a)\n",
    "y_test_new = np.asarray(y_test_new)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells build a RNN with four LSTM layers, with 128, 128, 64 units respectively:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, CuDNNLSTM, CuDNNGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_rnn = X_train.reshape(train_val_num, curtail_len, motif_num + 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(CuDNNLSTM(128, input_shape=(curtail_len, motif_num + 4), return_sequences=True))\n",
    "model.add(CuDNNLSTM(128))\n",
    "model.add(Dense(64, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train_rnn, y_train_new, epochs=5, batch_size=128, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(1, len(acc) + 1)\n",
    "\n",
    "plt.plot(epochs, acc, 'bo', label='Training Accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation Accuracy')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "plt.xlabel('epoches')\n",
    "plt.legend()\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "plt.plot(epochs, loss, 'bo', label='Training Loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation Loss')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.xlabel('epoches')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
