{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil, pickle, shelve\n",
    "#from Bio import SeqIO\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model, Model\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model, Sequential\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, MaxPooling1D, Flatten, Conv1D, LSTM, CuDNNLSTM, Bidirectional\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.initializers import glorot_normal\n",
    "import utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hybrid(opt):\n",
    "    \"\"\"  Return a hybrid network given a optimizer\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters = 30, \n",
    "                     kernel_size = 15, \n",
    "                     padding = 'valid',\n",
    "                     data_format = 'channels_last',\n",
    "                     activation = 'relu'))\n",
    "    model.add(MaxPooling1D(pool_size = 5, strides = 5))\n",
    "    model.add(Dropout(0.6))\n",
    "    model.add(Bidirectional(LSTM(10)))\n",
    "    model.add(Dropout(0.7))\n",
    "    model.add(Dense(20, activation = 'relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "def train(model, train_x, train_y, val_data, config = {'epochs': 35, 'batch_size': 256}):\n",
    "    \"\"\"  Train model for a given config, training data, and validation data\n",
    "    \"\"\"\n",
    "    epochs, batch_size = config['epochs'], config['batch_size']\n",
    "    return model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, validation_data=val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_for_detector(input_x, kernel_size):\n",
    "    \"\"\" Pad the input matrix such that the (i, k) entry of the output \n",
    "        matrix is the score of motif detector k aligned to position i.\n",
    "    input_x has shape = (N, n, 4)\n",
    "    kernel_size has shape m\n",
    "    output has shape = (N, n + 2m - 2, 4)\n",
    "    \"\"\"\n",
    "    N, n, C = input_x.shape\n",
    "    pad_value, num_pad = 0.25, kernel_size - 1\n",
    "    pad_matrix = np.full((N, num_pad, C), pad_value)\n",
    "    return np.concatenate((pad_matrix, input_x, pad_matrix), axis=1)\n",
    "        \n",
    "def get_pwm(test_seqs, kernel, bias):\n",
    "    \"\"\"\n",
    "    test_seqs: (N, n + 2m - 2, 4)\n",
    "    kernel: (m, 4)\n",
    "    bias: (1, )\n",
    "    output: (k, m, 4)\n",
    "    \"\"\"\n",
    "    N, L, C = test_seqs.shape\n",
    "    m, _ = kernel.shape\n",
    "    \n",
    "    ################################\n",
    "    # Reconstruct the motif detector\n",
    "    ################################\n",
    "    conv_layer = Conv1D()\n",
    "    \n",
    "    ###############################################\n",
    "    # Pass TEST_SEQUENCE through the motif detector\n",
    "    # activation has a shape (N, n + m - 1)\n",
    "    ###############################################\n",
    "    activation = kernel(test_sequence)\n",
    "    \n",
    "    #################################################################\n",
    "    # Extract those in the TEST_SEQUENCE that has least one position\n",
    "    #     having positive activation.\n",
    "    #################################################################\n",
    "    \n",
    "    # candidate and potential_start has a shape (N, )\n",
    "    candidate, potential_start = np.max(activation, axis=1), np.argmax(activation, axis=1)\n",
    "    \n",
    "    # activated_indices should have a shape (k, )\n",
    "    activated_indices = [i for i in range(N) if candidate[i] > 0]\n",
    "    \n",
    "    # activated_seq should have a shape(k, n + 2m - 2, 4)\n",
    "    activated_seq, end = test_sequences[activated_indices, :, :], potential_start[activated_indices]\n",
    "    start = end - m + 1\n",
    "    activated_subseq = activated_seq[:, start:end+1, :]\n",
    "    return activated_subseq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('../../models/hybrid_net.h5')\n",
    "\n",
    "filters = model.layers[0].get_weights()[0]\n",
    "bias = model.layers[0].get_weights()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15, 4), ())"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter0 = filters[:, :, 0]\n",
    "bias0 = bias[0]\n",
    "filter0.shape, bias0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 1028, 4)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "N, n, m = 100, 1000, 15\n",
    "test_seq = np.random.randint(2, size = N*n*4).reshape((N, n, 4))\n",
    "padded_test_seq = pad_for_detector(test_seq, m)\n",
    "padded_test_seq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15, 4), ())"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filter0.shape, bias0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<keras.layers.convolutional.Conv1D at 0x7fd4272acc88>,\n",
       " <keras.layers.pooling.MaxPooling1D at 0x7fd4272ac588>,\n",
       " <keras.layers.core.Dropout at 0x7fd4272ac7b8>,\n",
       " <keras.layers.wrappers.Bidirectional at 0x7fd445f65908>,\n",
       " <keras.layers.core.Dropout at 0x7fd4272acac8>,\n",
       " <keras.layers.core.Dense at 0x7fd4272acb00>,\n",
       " <keras.layers.core.Dense at 0x7fd4272acb38>]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You called `set_weights(weights)` on layer \"conv1d_4\" with a  weight list of length 2, but the layer was expecting 0 weights. Provided weights: (array([[ 0.00250294, -0.2061816 , -0.06191448,  0...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-67-e70404c0b647>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m                    \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                    input_shape = (n + 2*m - 2, 4))\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mconv_layer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilter0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/miniconda3/envs/gluon/lib/python3.6/site-packages/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mset_weights\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m   1045\u001b[0m                              \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m                              \u001b[0;34m' weights. Provided weights: '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m                              str(weights)[:50] + '...')\n\u001b[0m\u001b[1;32m   1048\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: You called `set_weights(weights)` on layer \"conv1d_4\" with a  weight list of length 2, but the layer was expecting 0 weights. Provided weights: (array([[ 0.00250294, -0.2061816 , -0.06191448,  0..."
     ]
    }
   ],
   "source": [
    "conv_layer = Conv1D(filters = 1, \n",
    "                    kernel_size = 15,\n",
    "                   padding = 'valid',\n",
    "                   data_format = 'channels_last',\n",
    "                   activation = 'relu',\n",
    "                   input_shape = (n + 2*m - 2, 4))\n",
    "conv_layer.set_weights((filter0, bias0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'conv1d_4',\n",
       " 'trainable': True,\n",
       " 'batch_input_shape': (None, 1028, 4),\n",
       " 'dtype': 'float32',\n",
       " 'filters': 1,\n",
       " 'kernel_size': (15,),\n",
       " 'strides': (1,),\n",
       " 'padding': 'valid',\n",
       " 'data_format': 'channels_last',\n",
       " 'dilation_rate': (1,),\n",
       " 'activation': 'relu',\n",
       " 'use_bias': True,\n",
       " 'kernel_initializer': {'class_name': 'VarianceScaling',\n",
       "  'config': {'scale': 1.0,\n",
       "   'mode': 'fan_avg',\n",
       "   'distribution': 'uniform',\n",
       "   'seed': None}},\n",
       " 'bias_initializer': {'class_name': 'Zeros', 'config': {}},\n",
       " 'kernel_regularizer': None,\n",
       " 'bias_regularizer': None,\n",
       " 'activity_regularizer': None,\n",
       " 'kernel_constraint': None,\n",
       " 'bias_constraint': None}"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv_layer.get_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
