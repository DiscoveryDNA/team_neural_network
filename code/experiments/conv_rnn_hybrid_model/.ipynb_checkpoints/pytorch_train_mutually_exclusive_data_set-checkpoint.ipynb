{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla K80\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "import math\n",
    "import torch\n",
    "from torch.utils import model_zoo\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from models_n_training import *\n",
    "from utilities import sampling, one_hot_encoding, curtail, get_training_data, load_data, data_split, dianostic_plots, pad_for_detector\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "if use_cuda:\n",
    "    print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3543"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subset sampling: save to me_samples; \"me\" for \"mutually exclusive\"\n",
    "output_folder_path = \"../../../../temp/buffers/me_samples\"\n",
    "\n",
    "data_dir = \"/home/ubuntu/group_volume/team_neural_network/data/input/3.24_species_only\"\n",
    "\n",
    "len(os.listdir(data_dir)) # total number of regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the following code chunk to resample training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -r /home/ubuntu/data/temp/train\n",
    "# !mkdir /home/ubuntu/data/temp/train\n",
    "# !rm -r /home/ubuntu/data/temp/val\n",
    "# !mkdir /home/ubuntu/data/temp/val\n",
    "\n",
    "# ###############################################################################\n",
    "# # Sample training and validation data\n",
    "# # IMPORTANT: Make sure that training and validation don't have intersection!!!\n",
    "# ###############################################################################\n",
    "# all_data_lst = np.array(os.listdir(data_dir))\n",
    "# n = len(all_data_lst)\n",
    "# num_trained_regions = int(n * 0.8)\n",
    "# train_files = all_data_lst[:num_trained_regions]\n",
    "# num_val = n - num_trained_regions\n",
    "# val_indices = np.random.choice(np.arange(num_trained_regions, n), num_val, replace = False)\n",
    "# val_files = all_data_lst[val_indices]\n",
    "\n",
    "# train_dest = '/home/ubuntu/data/temp/train/'\n",
    "# for file in train_files:\n",
    "#     shutil.copy(os.path.join(data_dir, file),\n",
    "#                           train_dest)\n",
    "# print('copied training samples to {}'.format(train_dest))\n",
    "\n",
    "# val_dest = '/home/ubuntu/data/temp/val/'\n",
    "# for file in val_files:\n",
    "#     shutil.copy(os.path.join(data_dir, file),\n",
    "#                           val_dest)\n",
    "# print('copied validation samples to {}'.format(val_dest))\n",
    "\n",
    "# # Preprocess train and val data so that they are ready to be fed to models\n",
    "# train_output_path = os.path.join(output_folder_path, 'train.data')\n",
    "# val_output_path = os.path.join(output_folder_path, 'val.data')\n",
    "\n",
    "# train_regions = one_hot_encoding(train_dest, train_output_path)\n",
    "# val_regions = one_hot_encoding(val_dest, val_output_path)\n",
    "# train_x, train_y = get_training_data(train_regions, output_folder_path,\n",
    "#                                    max_len = 1000, \n",
    "#                                    train_x_name = 'train_x.data', \n",
    "#                                    train_y_name = 'train_y.data')\n",
    "# val_x, val_y = get_training_data(val_regions, output_folder_path,\n",
    "#                                    max_len = 1000, \n",
    "#                                    train_x_name = 'val_x.data', \n",
    "#                                    train_y_name = 'val_y.data')\n",
    "# # Pad for motif detectors\n",
    "# train_x, val_x = pad_for_detector(train_x, 15), pad_for_detector(val_x, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_x = pickle.load(open('../../../../temp/buffers/ss_samples/train_x.data', 'rb'))\n",
    "# data_y = pickle.load(open('../../../../temp/buffers/ss_samples/train_y.data', 'rb'))\n",
    "# train_x, train_y, val_x, val_y = data_split(data_x, data_y, seed = 157)\n",
    "# train_x, val_x = pad_for_detector(train_x, 10), pad_for_detector(val_x, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = pickle.load(open(os.path.join(output_folder_path, 'train_x.data'), 'rb'))\n",
    "train_y = pickle.load(open(os.path.join(output_folder_path, 'train_y.data'), 'rb'))\n",
    "val_x = pickle.load(open(os.path.join(output_folder_path, 'val_x.data'), 'rb'))\n",
    "val_y = pickle.load(open(os.path.join(output_folder_path, 'val_y.data'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 15 # number of filters\n",
    "m = 30 # filter size\n",
    "train_x, val_x = pad_for_detector(train_x, m), pad_for_detector(val_x, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, val_x = torch.from_numpy(train_x.transpose([0, 2, 1])).float(), torch.from_numpy(val_x.transpose([0, 2, 1])).float()\n",
    "train_y, val_y = torch.from_numpy(train_y).float(), torch.from_numpy(val_y).float()\n",
    "\n",
    "# Generate dataset for data loader\n",
    "train_dataset = data.TensorDataset(train_x, train_y)\n",
    "val_dataset = data.TensorDataset(val_x, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, pesudo_input, num_filters, filter_size, rnn_size, fc_out, dp1, dp2, \n",
    "                 num_rnn_layers=1, rnn_dropout=0):\n",
    "        super(HybridNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=4, out_channels=num_filters, kernel_size=filter_size)\n",
    "        out = self.conv1(pesudo_input)\n",
    "        out = nn.MaxPool1d(kernel_size=15, stride=15)(out)\n",
    "        ####################################################\n",
    "        print('shape after conv1d {}'.format(out.shape))\n",
    "        N, C, T = out.shape\n",
    "        out = torch.transpose(out, 1, 2)\n",
    "        print('shape before lstm {}'.format(out.shape))\n",
    "        ####################################################\n",
    "        # or input_size*seq_len\n",
    "        self.bi_lstm = nn.LSTM(input_size=C, hidden_size=rnn_size, num_layers=num_rnn_layers,\n",
    "                              batch_first=True, dropout=rnn_dropout, bidirectional=True)\n",
    "        out, _ = self.bi_lstm(out)\n",
    "        print('shape after lstm {}'.format(out.shape))\n",
    "        N, T, C = out.shape\n",
    "        #out = torch.transpose(out, 1, 2)\n",
    "        out = out.reshape(N, -1)\n",
    "        print('shape after flattening {}'.format(out.shape))\n",
    "        self.fc1 = nn.Linear(T*C, fc_out, bias=True)\n",
    "        self.fc2 = nn.Linear(fc_out, 1)\n",
    "        self.p1 = dp1\n",
    "        self.p2 = dp2\n",
    "        \n",
    "    def forward(self, seq):\n",
    "        self.activation_seq = F.relu(self.conv1(seq))\n",
    "        out = nn.MaxPool1d(kernel_size=15, stride=15)(self.activation_seq)\n",
    "        \n",
    "#         out = nn.Dropout(p=self.p1)(self.activation_seq)\n",
    "        \n",
    "        #################################################################################\n",
    "        # Input of LSTM layer should have shape (sequence_length, batch_size, input_size)\n",
    "        #     - Sequence length here should be the length of activation after downsampling\n",
    "        #     - Input size should be the number of filters\n",
    "        #################################################################################\n",
    "        N, C, T = out.shape\n",
    "#         out = out.view(bs, 1, -1)\n",
    "        out = torch.transpose(out, 1, 2)\n",
    "        out, _ = self.bi_lstm(out)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        #################################################################################\n",
    "        # Need to flatten the sequence before feeding them into fully connected layer\n",
    "        #################################################################################\n",
    "        N, T, C = out.shape\n",
    "        #out = torch.transpose(out, 1, 2)\n",
    "        out = out.reshape(N, -1)\n",
    "        out = self.fc1(out)\n",
    "        out = nn.Dropout(p=self.p1)(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = nn.Dropout(p=self.p2)(out)\n",
    "        out = torch.squeeze(out)\n",
    "        return nn.Sigmoid()(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape after conv1d torch.Size([256, 50, 69])\n",
      "shape before lstm torch.Size([256, 69, 50])\n",
      "shape after lstm torch.Size([256, 69, 100])\n",
      "shape after flattening torch.Size([256, 6900])\n",
      "Train on 33984 samples, validate on 8520 samples\n",
      "***************************************\n",
      "Epoch 1: training loss 0.6945885285399014, training acc 0.45184249686716793\n",
      "Time: 8.944575309753418 \n",
      "\n",
      "[Validation loss 0.6917566727189457, validation acc 0.5013148488562091] \n",
      "\n",
      "***************************************\n",
      "Epoch 2: training loss 0.6919588666213187, training acc 0.46284656954887216\n",
      "Time: 8.870245218276978 \n",
      "\n",
      "[Validation loss 0.6917154613663169, validation acc 0.5055147058823529] \n",
      "\n",
      "***************************************\n",
      "Epoch 3: training loss 0.6914251841100535, training acc 0.46656680764411024\n",
      "Time: 8.873063564300537 \n",
      "\n",
      "[Validation loss 0.6928302733337178, validation acc 0.4980596405228758] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "_, C, L = train_x.shape\n",
    "pesudo_input = torch.rand(batch_size, C, L, dtype=train_x.dtype)\n",
    "hybrid_net = HybridNet(pesudo_input,\n",
    "                       num_filters=50, \n",
    "                       filter_size=10, \n",
    "                       rnn_size=50, \n",
    "                       fc_out=20, \n",
    "                       dp1=0.8, dp2=0.8).to(device)\n",
    "\n",
    "optimizers = {'adam': torch.optim.Adam(hybrid_net.parameters(), lr=1e-3, weight_decay=1e-4),\n",
    "              'rmsprop': torch.optim.RMSprop(hybrid_net.parameters(), lr=1e-3, weight_decay=1e-4)}\n",
    "config = {'epochs':250, 'device':device, \n",
    "          'opt': optimizers['adam'],\n",
    "          'criterion':nn.BCELoss(),\n",
    "          'batch_size': batch_size,\n",
    "          'log_interval':1}\n",
    "\n",
    "hybrid_net, train_loss_list, val_loss_list, train_acc_list, val_acc_list = train(hybrid_net, train_dataset, val_dataset, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_interval = 1\n",
    "dianostic_plots(train_acc_list[::log_interval], train_loss_list[::log_interval], val_acc_list, val_loss_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
