{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "import math\n",
    "import torch\n",
    "from torch.utils import model_zoo\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from utilities import sampling, one_hot_encoding, curtail, get_training_data, load_data, data_split, dianostic_plots, pad_for_detector\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "if use_cuda:\n",
    "    print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subset sampling: save to me_samples; \"me\" for \"mutually exclusive\"\n",
    "output_folder_path = \"../../../../temp/buffers/me_samples\"\n",
    "\n",
    "data_dir = \"/home/ubuntu/group_volume/team_neural_network/data/input/3.24_species_only\"\n",
    "\n",
    "len(os.listdir(data_dir)) # total number of regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the following code chunk to resample training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -r /home/ubuntu/data/temp/train\n",
    "# !mkdir /home/ubuntu/data/temp/train\n",
    "# !rm -r /home/ubuntu/data/temp/val\n",
    "# !mkdir /home/ubuntu/data/temp/val\n",
    "\n",
    "# ###############################################################################\n",
    "# # Sample training and validation data\n",
    "# # IMPORTANT: Make sure that training and validation don't have intersection!!!\n",
    "# ###############################################################################\n",
    "# all_data_lst = np.array(os.listdir(data_dir))\n",
    "# n = len(all_data_lst)\n",
    "# num_trained_regions = int(n * 0.8)\n",
    "# train_files = all_data_lst[:num_trained_regions]\n",
    "# num_val = n - num_trained_regions\n",
    "# val_indices = np.random.choice(np.arange(num_trained_regions, n), num_val, replace = False)\n",
    "# val_files = all_data_lst[val_indices]\n",
    "\n",
    "# train_dest = '/home/ubuntu/data/temp/train/'\n",
    "# for file in train_files:\n",
    "#     shutil.copy(os.path.join(data_dir, file),\n",
    "#                           train_dest)\n",
    "# print('copied training samples to {}'.format(train_dest))\n",
    "\n",
    "# val_dest = '/home/ubuntu/data/temp/val/'\n",
    "# for file in val_files:\n",
    "#     shutil.copy(os.path.join(data_dir, file),\n",
    "#                           val_dest)\n",
    "# print('copied validation samples to {}'.format(val_dest))\n",
    "\n",
    "# # Preprocess train and val data so that they are ready to be fed to models\n",
    "# train_output_path = os.path.join(output_folder_path, 'train.data')\n",
    "# val_output_path = os.path.join(output_folder_path, 'val.data')\n",
    "\n",
    "# train_regions = one_hot_encoding(train_dest, train_output_path)\n",
    "# val_regions = one_hot_encoding(val_dest, val_output_path)\n",
    "# train_x, train_y = get_training_data(train_regions, output_folder_path,\n",
    "#                                    max_len = 1000, \n",
    "#                                    train_x_name = 'train_x.data', \n",
    "#                                    train_y_name = 'train_y.data')\n",
    "# val_x, val_y = get_training_data(val_regions, output_folder_path,\n",
    "#                                    max_len = 1000, \n",
    "#                                    train_x_name = 'val_x.data', \n",
    "#                                    train_y_name = 'val_y.data')\n",
    "# # Pad for motif detectors\n",
    "# train_x, val_x = pad_for_detector(train_x, 15), pad_for_detector(val_x, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_x = pickle.load(open('../../../../temp/buffers/ss_samples/train_x.data', 'rb'))\n",
    "# data_y = pickle.load(open('../../../../temp/buffers/ss_samples/train_y.data', 'rb'))\n",
    "# train_x, train_y, val_x, val_y = data_split(data_x, data_y, seed = 157)\n",
    "# train_x, val_x = pad_for_detector(train_x, 10), pad_for_detector(val_x, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = pickle.load(open(os.path.join(output_folder_path, 'train_x.data'), 'rb'))\n",
    "train_y = pickle.load(open(os.path.join(output_folder_path, 'train_y.data'), 'rb'))\n",
    "val_x = pickle.load(open(os.path.join(output_folder_path, 'val_x.data'), 'rb'))\n",
    "val_y = pickle.load(open(os.path.join(output_folder_path, 'val_y.data'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 30 # number of filters\n",
    "m = 10 # filter size\n",
    "train_x, val_x = pad_for_detector(train_x, m), pad_for_detector(val_x, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, val_x = torch.from_numpy(train_x).float(), torch.from_numpy(val_x).float()\n",
    "train_y, val_y = torch.from_numpy(train_y).float(), torch.from_numpy(val_y).float()\n",
    "\n",
    "# Convert data format from channel_last to channer_first\n",
    "N, L, C = train_x.shape\n",
    "n, l, _ = val_x.shape\n",
    "train_x = train_x.reshape(N, C, L)\n",
    "val_x = val_x.reshape(n, C, l)\n",
    "\n",
    "# Generate dataset for data loader\n",
    "train_dataset = data.TensorDataset(train_x, train_y)\n",
    "val_dataset = data.TensorDataset(val_x, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference for connecting Conv1D and LSTM: https://mxnet.incubator.apache.org/versions/master/tutorials/basic/reshape_transpose.html\n",
    "class HybridNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, pesudo_input, num_filters, filter_size, rnn_size, fc_out, dp1, dp2, \n",
    "                 num_rnn_layers=1, rnn_dropout=0):\n",
    "        super(HybridNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=4, out_channels=num_filters, kernel_size=filter_size)\n",
    "        out = self.conv1(pesudo_input)\n",
    "        out = nn.MaxPool1d(kernel_size=5, stride=5)(out)\n",
    "        ####################################################\n",
    "        print('shape after conv1d {}'.format(out.shape))\n",
    "        N, C, T = out.shape\n",
    "        out = torch.transpose(out, 1, 2)\n",
    "        print('shape before lstm {}'.format(out.shape))\n",
    "        ####################################################\n",
    "        # or input_size*seq_len\n",
    "        self.bi_lstm = nn.LSTM(input_size=C, hidden_size=rnn_size, num_layers=num_rnn_layers,\n",
    "                              batch_first=True, dropout=rnn_dropout, bidirectional=True)\n",
    "        out, _ = self.bi_lstm(out)\n",
    "        print('shape after lstm {}'.format(out.shape))\n",
    "        N, T, C = out.shape\n",
    "        out = torch.transpose(out, 1, 2)\n",
    "        out = out.reshape(N, -1)\n",
    "        print('shape after flattening {}'.format(out.shape))\n",
    "        self.fc1 = nn.Linear(T*C, fc_out, bias=True)\n",
    "        self.fc2 = nn.Linear(fc_out, 1)\n",
    "        self.p1 = dp1\n",
    "        self.p2 = dp2\n",
    "        \n",
    "    def forward(self, seq):\n",
    "        self.activation_seq = F.relu(self.conv1(seq))\n",
    "        out = nn.MaxPool1d(kernel_size=5, stride=5)(self.activation_seq)\n",
    "        out = nn.Dropout(p=self.p1)(out)\n",
    "        \n",
    "        #################################################################################\n",
    "        # Input of LSTM layer should have shape (sequence_length, batch_size, input_size)\n",
    "        #     - Sequence length here should be the length of activation after downsampling\n",
    "        #     - Input size should be the number of filters\n",
    "        #################################################################################\n",
    "        N, C, T = out.shape\n",
    "#         out = out.view(bs, 1, -1)\n",
    "        out = torch.transpose(out, 1, 2)\n",
    "        out, _ = self.bi_lstm(out)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        #################################################################################\n",
    "        # Need to flatten the sequence before feeding them into fully connected layer\n",
    "        #################################################################################\n",
    "        N, T, C = out.shape\n",
    "        out = torch.transpose(out, 1, 2)\n",
    "        out = out.reshape(N, -1)\n",
    "        out = nn.Dropout(p=self.p2)(out)\n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = torch.squeeze(out)\n",
    "        return nn.Sigmoid()(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "pesudo_input = torch.rand(batch_size, C, L, dtype=train_x.dtype)\n",
    "hybrid_net = HybridNet(pesudo_input,\n",
    "                       num_filters=n, \n",
    "                       filter_size=m, \n",
    "                       rnn_size=10, \n",
    "                       fc_out=20, \n",
    "                       dp1=0.6, dp2=0.7).to(device)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
