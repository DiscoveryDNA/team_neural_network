{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, shutil, pickle, shelve\n",
    "from Bio import SeqIO\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model, Model\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model, Sequential\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, MaxPooling1D, Flatten, Conv1D, LSTM, CuDNNLSTM, Bidirectional\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.initializers import glorot_normal\n",
    "import keras\n",
    "from utilities import sampling, one_hot_encoding, curtail, get_training_data, load_data, data_split, dianostic_plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample data from:\n",
    "data_dir = \"/home/ubuntu/group_volume/team_neural_network/data/input/3.24_species_only\"\n",
    "output_folder_path = \"../../../../temp/buffers/me_samples\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the following code chunk to resample training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# !rm -r /home/ubuntu/data/temp/train\n",
    "# !mkdir /home/ubuntu/data/temp/train\n",
    "# !rm -r /home/ubuntu/data/temp/val\n",
    "# !mkdir /home/ubuntu/data/temp/val\n",
    "\n",
    "# # Sample training and validation data\n",
    "# # Make sure that they don't have intersection.\n",
    "# all_data_lst = np.array(os.listdir(data_dir))\n",
    "# n = len(all_data_lst)\n",
    "# train_files = all_data_lst[:500]\n",
    "# num_val = 100\n",
    "# val_indices = np.random.choice(np.arange(500, n), num_val, replace = False)\n",
    "# val_files = all_data_lst[val_indices]\n",
    "\n",
    "# train_dest = '/home/ubuntu/data/temp/train/'\n",
    "# for file in train_files:\n",
    "#     shutil.copy(os.path.join(data_dir, file),\n",
    "#                           train_dest)\n",
    "# print('copied training samples to {}'.format(train_dest))\n",
    "\n",
    "# val_dest = '/home/ubuntu/data/temp/val/'\n",
    "# for file in val_files:\n",
    "#     shutil.copy(os.path.join(data_dir, file),\n",
    "#                           val_dest)\n",
    "# print('copied validation samples to {}'.format(val_dest))\n",
    "\n",
    "# # Preprocess train and val data so that they are ready to be fed to models\n",
    "# train_output_path = os.path.join(output_folder_path, 'train.data')\n",
    "# val_output_path = os.path.join(output_folder_path, 'val.data')\n",
    "\n",
    "# train_regions = one_hot_encoding(train_dest, train_output_path)\n",
    "# val_regions = one_hot_encoding(val_dest, val_output_path)\n",
    "# train_x, train_y = get_training_data(train_regions, output_folder_path,\n",
    "#                                    max_len = 1000, \n",
    "#                                    train_x_name = 'train_x.data', \n",
    "#                                    train_y_name = 'train_y.data')\n",
    "# val_x, val_y = get_training_data(val_regions, output_folder_path,\n",
    "#                                    max_len = 1000, \n",
    "#                                    train_x_name = 'val_x.data', \n",
    "#                                    train_y_name = 'val_y.data')\n",
    "# # Pad for motif detectors\n",
    "# train_x, val_x = pad_for_detector(train_x, 15), pad_for_detector(val_x, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = pickle.load(open('../../../../temp/buffers/me_samples/train_x.data', 'rb'))\n",
    "train_y = pickle.load(open('../../../../temp/buffers/me_samples/train_y.data', 'rb'))\n",
    "train_x, val_x = pad_for_detector(train_x, 15), pad_for_detector(val_x, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Define model:\n",
    "class HybridModel:\n",
    "    def __init__(self, K, M, input_length, rnn_size, config):\n",
    "        # Extract configaration of the model:\n",
    "        pool_size, strides = config['pool_size'], config['strides']\n",
    "        dr1, dr2 = config['dr1'], config['dr2'] # dropout rates\n",
    "        d = config['d'] # size of dense layers\n",
    "        optimizer = config['opt']\n",
    "        learning_rate = config['learning_rate']\n",
    "        is_training = config['is_training'] # to control the dropout layers\n",
    "        \n",
    "        # Create the placeholders for the inputs:\n",
    "        self.input = tf.placeholder(tf.float32, shape=[None, input_length, 4])\n",
    "        self.targets = tf.placeholder(tf.int32, shape=[None, ])\n",
    "        \n",
    "        # Define layers for the model:\n",
    "        self.K = K # number of filters\n",
    "        \n",
    "        self.conv = tf.layers.Conv1D(K, M,\n",
    "                                     strides=1, padding='valid',\n",
    "                                     use_bias=True, name='conv')\n",
    "        self.lm_cell_fw = tf.nn.rnn_cell.LSTMCell(num_units = rnn_size, dtype = tf.float32, name='lm_cell_fw')\n",
    "        self.lm_cell_bw = tf.nn.rnn_cell.LSTMCell(num_units = rnn_size, dtype = tf.float32, name='lm_cell_bw')\n",
    "        \n",
    "        # Feed in input\n",
    "        #print(self.input.shape)\n",
    "        self.activations = tf.nn.relu(self.conv(self.input))\n",
    "        #print(self.activations.shape)\n",
    "        outputs = tf.layers.max_pooling1d(self.activations, \n",
    "                                          pool_size=pool_size,\n",
    "                                          strides=strides)\n",
    "        outputs = tf.layers.dropout(outputs,\n",
    "                                    rate=dr1,\n",
    "                                    training=is_training)\n",
    "        #print(outputs.shape)\n",
    "        \n",
    "        outputs, states = tf.nn.bidirectional_dynamic_rnn(self.lm_cell_fw,\n",
    "                                                          self.lm_cell_bw,\n",
    "                                                          outputs, dtype = tf.float32)\n",
    "        outputs = tf.concat(outputs, axis=2)\n",
    "        #print(outputs.shape)\n",
    "        outputs = tf.layers.dropout(outputs,\n",
    "                                    rate=dr2,\n",
    "                                    training=is_training)\n",
    "        \n",
    "        outputs = tf.nn.relu(tf.layers.dense(outputs, d, name='dense1'))\n",
    "        #print(outputs.shape)\n",
    "        output_logits = tf.layers.dense(outputs, 1, name='dense2')\n",
    "        #print(output_logits.shape)\n",
    "        \n",
    "        self.loss = tf.losses.sparse_softmax_cross_entropy(self.targets, output_logits)\n",
    "        #print(self.loss.shape)\n",
    "        self.global_step = tf.train.get_or_create_global_step()\n",
    "        self.train_op = optimizer.minimize(self.loss)\n",
    "        self.saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-6-f19474ae39f1>:22: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From <ipython-input-6-f19474ae39f1>:31: max_pooling1d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.max_pooling1d instead.\n",
      "WARNING:tensorflow:From <ipython-input-6-f19474ae39f1>:34: dropout (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dropout instead.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From <ipython-input-6-f19474ae39f1>:39: bidirectional_dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.Bidirectional(keras.layers.RNN(cell))`, which is equivalent to this API\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/rnn.py:443: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `keras.layers.RNN(cell)`, which is equivalent to this API\n",
      "WARNING:tensorflow:From <ipython-input-6-f19474ae39f1>:46: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n"
     ]
    }
   ],
   "source": [
    "tf.reset_default_graph() # Reset the computational graph before defining a new model.\n",
    "\n",
    "optimizers = {'adam': tf.train.AdamOptimizer(learning_rate=1e-3),\n",
    "              'rmsprop': tf.train.RMSPropOptimizer(learning_rate=1e-3)}\n",
    "opt = optimizers['rmsprop']\n",
    "model_config = {'pool_size': 5, 'strides': 5, 'dr1': 0.6, 'dr2': 0.7, 'd': 20, \n",
    "          'opt': opt, 'learning_rate': 1e-2, 'is_training': True}\n",
    "model = HybridModel(K=30, M=15, input_length=1028, rnn_size=15, config=model_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# Define training function:\n",
    "def train(model, train_x, train_y, val_x, val_y, config, verbose=True, print_every=10):\n",
    "    epochs, iteration, output_path = config['epochs'], config['iteration'], config['output_path']\n",
    "    train_loss_record, val_loss_record = [], []\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for epoch in range(epochs):\n",
    "            print(\"epoch {}\".format(epoch))\n",
    "            for iters in range(iteration):\n",
    "                # Here is how you obtain a batch:\n",
    "                batch_size = train_x.shape[0] // iteration\n",
    "                #print(batch_size)\n",
    "                train_indices = np.random.choice(np.arange(train_x.shape[0]), batch_size, replace=False)\n",
    "                sub_train_x, sub_train_y = train_x[train_indices, :, :], train_y[train_indices]\n",
    "                feed = {model.input: sub_train_x, model.targets: sub_train_y}\n",
    "                model.is_training = True\n",
    "                step, train_loss, _ = sess.run([model.global_step, model.loss, model.train_op], feed_dict=feed)\n",
    "                if verbose:\n",
    "                    if iters % print_every == 0:\n",
    "                        print(\"    iteration {}, train_loss: {}\".format(iters, train_loss))\n",
    "            val_indices = np.random.choice(np.arange(val_x.shape[0]), 2400, replace = False)\n",
    "            sub_val_x, sub_val_y = val_x[val_indices, :, :], val_y[val_indices]\n",
    "            feed = {model.input: sub_val_x, model.targets: sub_val_y}\n",
    "            model.is_training = False\n",
    "            val_loss = sess.run([model.loss], feed_dict=feed)\n",
    "            val_loss_record.append(val_loss)\n",
    "            train_loss_record.append(train_loss)\n",
    "            print(\"validation loss: {}\".format(val_loss))\n",
    "        # Here is how you save the model weights\n",
    "        model.saver.save(sess, output_path)\n",
    "    return train_loss_record, val_loss_record"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "    iteration 0, train_loss: 5.384913444519043\n",
      "    iteration 10, train_loss: 5.3469696044921875\n",
      "    iteration 20, train_loss: 5.3420610427856445\n",
      "    iteration 30, train_loss: 5.293630123138428\n",
      "    iteration 40, train_loss: 5.216133117675781\n",
      "    iteration 50, train_loss: 5.183137893676758\n",
      "    iteration 60, train_loss: 5.069476127624512\n",
      "    iteration 70, train_loss: 4.925942897796631\n",
      "    iteration 80, train_loss: 4.655019283294678\n",
      "    iteration 90, train_loss: 4.373633861541748\n",
      "validation loss: [3.8718624]\n",
      "epoch 1\n",
      "    iteration 0, train_loss: 3.8972346782684326\n",
      "    iteration 10, train_loss: 3.3315398693084717\n",
      "    iteration 20, train_loss: 2.8374128341674805\n",
      "    iteration 30, train_loss: 2.416781187057495\n",
      "    iteration 40, train_loss: 2.0785772800445557\n",
      "    iteration 50, train_loss: 1.8875325918197632\n",
      "    iteration 60, train_loss: 1.6729018688201904\n",
      "    iteration 70, train_loss: 1.489064335823059\n",
      "    iteration 80, train_loss: 1.3816629648208618\n",
      "    iteration 90, train_loss: 1.3112367391586304\n",
      "validation loss: [1.2091615]\n",
      "epoch 2\n",
      "    iteration 0, train_loss: 1.189104676246643\n",
      "    iteration 10, train_loss: 1.187303900718689\n",
      "    iteration 20, train_loss: 1.0569789409637451\n",
      "    iteration 30, train_loss: 1.0168702602386475\n",
      "    iteration 40, train_loss: 1.0738561153411865\n",
      "    iteration 50, train_loss: 0.9723456501960754\n",
      "    iteration 60, train_loss: 0.9590398073196411\n",
      "    iteration 70, train_loss: 0.9160206317901611\n",
      "    iteration 80, train_loss: 0.8648242950439453\n",
      "    iteration 90, train_loss: 0.9334395527839661\n",
      "validation loss: [0.8841727]\n",
      "epoch 3\n",
      "    iteration 0, train_loss: 0.8682888150215149\n",
      "    iteration 10, train_loss: 0.9178756475448608\n",
      "    iteration 20, train_loss: 0.8419879674911499\n",
      "    iteration 30, train_loss: 0.9086621403694153\n",
      "    iteration 40, train_loss: 0.8119657635688782\n",
      "    iteration 50, train_loss: 0.7969421148300171\n",
      "    iteration 60, train_loss: 0.826080322265625\n",
      "    iteration 70, train_loss: 0.7667222619056702\n",
      "    iteration 80, train_loss: 0.7852030992507935\n",
      "    iteration 90, train_loss: 0.8087716698646545\n",
      "validation loss: [0.81420106]\n",
      "epoch 4\n",
      "    iteration 0, train_loss: 0.67057204246521\n",
      "    iteration 10, train_loss: 0.7455673217773438\n",
      "    iteration 20, train_loss: 0.7565248012542725\n",
      "    iteration 30, train_loss: 0.7033039331436157\n",
      "    iteration 40, train_loss: 0.7939820885658264\n",
      "    iteration 50, train_loss: 0.7247970104217529\n",
      "    iteration 60, train_loss: 0.7518579959869385\n",
      "    iteration 70, train_loss: 0.8088996410369873\n",
      "    iteration 80, train_loss: 0.7267428040504456\n",
      "    iteration 90, train_loss: 0.7522933483123779\n",
      "validation loss: [0.7937199]\n",
      "epoch 5\n",
      "    iteration 0, train_loss: 0.7148252129554749\n",
      "    iteration 10, train_loss: 0.7565866708755493\n",
      "    iteration 20, train_loss: 0.7479637861251831\n",
      "    iteration 30, train_loss: 0.711361289024353\n",
      "    iteration 40, train_loss: 0.7010375261306763\n",
      "    iteration 50, train_loss: 0.7202349305152893\n",
      "    iteration 60, train_loss: 0.754822313785553\n",
      "    iteration 70, train_loss: 0.7006828784942627\n",
      "    iteration 80, train_loss: 0.7097647786140442\n",
      "    iteration 90, train_loss: 0.7083045840263367\n",
      "validation loss: [0.7844338]\n",
      "epoch 6\n",
      "    iteration 0, train_loss: 0.6997833847999573\n",
      "    iteration 10, train_loss: 0.6822892427444458\n",
      "    iteration 20, train_loss: 0.7001545429229736\n",
      "    iteration 30, train_loss: 0.7140955328941345\n",
      "    iteration 40, train_loss: 0.6978777647018433\n",
      "    iteration 50, train_loss: 0.7219420671463013\n",
      "    iteration 60, train_loss: 0.6535475850105286\n",
      "    iteration 70, train_loss: 0.6868911981582642\n",
      "    iteration 80, train_loss: 0.6538006067276001\n",
      "    iteration 90, train_loss: 0.6900765299797058\n",
      "validation loss: [0.77141625]\n",
      "epoch 7\n",
      "    iteration 0, train_loss: 0.6979676485061646\n",
      "    iteration 10, train_loss: 0.6739867925643921\n",
      "    iteration 20, train_loss: 0.6522279381752014\n",
      "    iteration 30, train_loss: 0.6065131425857544\n",
      "    iteration 40, train_loss: 0.6891442537307739\n",
      "    iteration 50, train_loss: 0.6766058802604675\n",
      "    iteration 60, train_loss: 0.6585487127304077\n",
      "    iteration 70, train_loss: 0.6899906396865845\n",
      "    iteration 80, train_loss: 0.6551496982574463\n",
      "    iteration 90, train_loss: 0.7123029828071594\n",
      "validation loss: [0.7712092]\n",
      "epoch 8\n",
      "    iteration 0, train_loss: 0.623697817325592\n",
      "    iteration 10, train_loss: 0.6684205532073975\n",
      "    iteration 20, train_loss: 0.643196702003479\n",
      "    iteration 30, train_loss: 0.6100083589553833\n",
      "    iteration 40, train_loss: 0.6946870684623718\n",
      "    iteration 50, train_loss: 0.6915982961654663\n",
      "    iteration 60, train_loss: 0.6260103583335876\n",
      "    iteration 70, train_loss: 0.6546862125396729\n",
      "    iteration 80, train_loss: 0.5375314354896545\n",
      "    iteration 90, train_loss: 0.636745274066925\n",
      "validation loss: [0.7637263]\n",
      "epoch 9\n",
      "    iteration 0, train_loss: 0.6369746327400208\n",
      "    iteration 10, train_loss: 0.6453412771224976\n",
      "    iteration 20, train_loss: 0.6777020692825317\n",
      "    iteration 30, train_loss: 0.6372974514961243\n",
      "    iteration 40, train_loss: 0.6900885105133057\n",
      "    iteration 50, train_loss: 0.6844781637191772\n",
      "    iteration 60, train_loss: 0.6227697730064392\n",
      "    iteration 70, train_loss: 0.6442716121673584\n",
      "    iteration 80, train_loss: 0.6799829006195068\n",
      "    iteration 90, train_loss: 0.5883854031562805\n",
      "validation loss: [0.7505984]\n",
      "epoch 10\n",
      "    iteration 0, train_loss: 0.6847540140151978\n",
      "    iteration 10, train_loss: 0.6853830814361572\n",
      "    iteration 20, train_loss: 0.706989049911499\n",
      "    iteration 30, train_loss: 0.6243597269058228\n",
      "    iteration 40, train_loss: 0.715399444103241\n",
      "    iteration 50, train_loss: 0.649185299873352\n",
      "    iteration 60, train_loss: 0.653105616569519\n",
      "    iteration 70, train_loss: 0.6048487424850464\n",
      "    iteration 80, train_loss: 0.6260097622871399\n",
      "    iteration 90, train_loss: 0.6364218592643738\n",
      "validation loss: [0.77152884]\n",
      "epoch 11\n",
      "    iteration 0, train_loss: 0.686553418636322\n",
      "    iteration 10, train_loss: 0.6290112733840942\n",
      "    iteration 20, train_loss: 0.6161044836044312\n",
      "    iteration 30, train_loss: 0.6121203303337097\n",
      "    iteration 40, train_loss: 0.5920085906982422\n",
      "    iteration 50, train_loss: 0.6765459775924683\n",
      "    iteration 60, train_loss: 0.627962052822113\n",
      "    iteration 70, train_loss: 0.6114975214004517\n",
      "    iteration 80, train_loss: 0.6560240387916565\n",
      "    iteration 90, train_loss: 0.6023269891738892\n",
      "validation loss: [0.8053223]\n",
      "epoch 12\n",
      "    iteration 0, train_loss: 0.7009367346763611\n",
      "    iteration 10, train_loss: 0.6020672917366028\n",
      "    iteration 20, train_loss: 0.6959941983222961\n",
      "    iteration 30, train_loss: 0.639481246471405\n",
      "    iteration 40, train_loss: 0.5941796898841858\n",
      "    iteration 50, train_loss: 0.6241311430931091\n",
      "    iteration 60, train_loss: 0.6491528153419495\n",
      "    iteration 70, train_loss: 0.6387894749641418\n",
      "    iteration 80, train_loss: 0.5888305902481079\n",
      "    iteration 90, train_loss: 0.6346427202224731\n",
      "validation loss: [0.78934747]\n",
      "epoch 13\n",
      "    iteration 0, train_loss: 0.6607500910758972\n",
      "    iteration 10, train_loss: 0.5887959599494934\n",
      "    iteration 20, train_loss: 0.7398881912231445\n",
      "    iteration 30, train_loss: 0.645557165145874\n",
      "    iteration 40, train_loss: 0.6337299346923828\n",
      "    iteration 50, train_loss: 0.5828609466552734\n",
      "    iteration 60, train_loss: 0.6742976903915405\n",
      "    iteration 70, train_loss: 0.6204246878623962\n",
      "    iteration 80, train_loss: 0.563949704170227\n",
      "    iteration 90, train_loss: 0.6222310662269592\n",
      "validation loss: [0.81202996]\n",
      "epoch 14\n",
      "    iteration 0, train_loss: 0.6003189086914062\n",
      "    iteration 10, train_loss: 0.631194531917572\n",
      "    iteration 20, train_loss: 0.6918896436691284\n",
      "    iteration 30, train_loss: 0.6141666173934937\n",
      "    iteration 40, train_loss: 0.6112698912620544\n",
      "    iteration 50, train_loss: 0.5773686766624451\n",
      "    iteration 60, train_loss: 0.6800310015678406\n",
      "    iteration 70, train_loss: 0.6186085343360901\n",
      "    iteration 80, train_loss: 0.6084950566291809\n",
      "    iteration 90, train_loss: 0.6621578931808472\n",
      "validation loss: [0.81341535]\n",
      "epoch 15\n",
      "    iteration 0, train_loss: 0.6262983679771423\n",
      "    iteration 10, train_loss: 0.6483369469642639\n",
      "    iteration 20, train_loss: 0.5601909160614014\n",
      "    iteration 30, train_loss: 0.6034853458404541\n",
      "    iteration 40, train_loss: 0.6844936609268188\n",
      "    iteration 50, train_loss: 0.5675345063209534\n",
      "    iteration 60, train_loss: 0.6142112612724304\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    iteration 70, train_loss: 0.5537064671516418\n",
      "    iteration 80, train_loss: 0.5736018419265747\n",
      "    iteration 90, train_loss: 0.6402178406715393\n",
      "validation loss: [0.77980113]\n",
      "epoch 16\n",
      "    iteration 0, train_loss: 0.6257760524749756\n",
      "    iteration 10, train_loss: 0.6706918478012085\n",
      "    iteration 20, train_loss: 0.6542856693267822\n",
      "    iteration 30, train_loss: 0.5871003270149231\n",
      "    iteration 40, train_loss: 0.5867918133735657\n",
      "    iteration 50, train_loss: 0.6684929132461548\n",
      "    iteration 60, train_loss: 0.6947860717773438\n",
      "    iteration 70, train_loss: 0.5800827741622925\n",
      "    iteration 80, train_loss: 0.598261296749115\n",
      "    iteration 90, train_loss: 0.5985063910484314\n",
      "validation loss: [0.8066593]\n",
      "epoch 17\n",
      "    iteration 0, train_loss: 0.6457403302192688\n",
      "    iteration 10, train_loss: 0.587816596031189\n",
      "    iteration 20, train_loss: 0.5977725982666016\n",
      "    iteration 30, train_loss: 0.6719723343849182\n",
      "    iteration 40, train_loss: 0.6201974153518677\n",
      "    iteration 50, train_loss: 0.5890728235244751\n",
      "    iteration 60, train_loss: 0.6170507073402405\n",
      "    iteration 70, train_loss: 0.6498939990997314\n",
      "    iteration 80, train_loss: 0.6026124358177185\n",
      "    iteration 90, train_loss: 0.6360862851142883\n",
      "validation loss: [0.8077399]\n",
      "epoch 18\n",
      "    iteration 0, train_loss: 0.5949480533599854\n",
      "    iteration 10, train_loss: 0.6053863763809204\n",
      "    iteration 20, train_loss: 0.7220935821533203\n",
      "    iteration 30, train_loss: 0.6407840847969055\n",
      "    iteration 40, train_loss: 0.7661393880844116\n",
      "    iteration 50, train_loss: 0.6418744325637817\n",
      "    iteration 60, train_loss: 0.5379511117935181\n",
      "    iteration 70, train_loss: 0.6612094640731812\n",
      "    iteration 80, train_loss: 0.6640321016311646\n",
      "    iteration 90, train_loss: 0.6160911321640015\n",
      "validation loss: [0.81731987]\n",
      "epoch 19\n",
      "    iteration 0, train_loss: 0.5429344773292542\n",
      "    iteration 10, train_loss: 0.5801674127578735\n",
      "    iteration 20, train_loss: 0.6095364689826965\n",
      "    iteration 30, train_loss: 0.6139780879020691\n",
      "    iteration 40, train_loss: 0.5160444378852844\n",
      "    iteration 50, train_loss: 0.5953366756439209\n",
      "    iteration 60, train_loss: 0.680265486240387\n",
      "    iteration 70, train_loss: 0.6286529302597046\n",
      "    iteration 80, train_loss: 0.6400582790374756\n",
      "    iteration 90, train_loss: 0.5950971841812134\n",
      "validation loss: [0.7788266]\n",
      "epoch 20\n",
      "    iteration 0, train_loss: 0.5168529748916626\n",
      "    iteration 10, train_loss: 0.6632670760154724\n",
      "    iteration 20, train_loss: 0.5953077077865601\n",
      "    iteration 30, train_loss: 0.6408243179321289\n",
      "    iteration 40, train_loss: 0.6038848161697388\n",
      "    iteration 50, train_loss: 0.6726909875869751\n",
      "    iteration 60, train_loss: 0.594568133354187\n",
      "    iteration 70, train_loss: 0.6148432493209839\n",
      "    iteration 80, train_loss: 0.6087379455566406\n",
      "    iteration 90, train_loss: 0.5763755440711975\n",
      "validation loss: [0.7745741]\n",
      "epoch 21\n",
      "    iteration 0, train_loss: 0.6731277704238892\n",
      "    iteration 10, train_loss: 0.6007675528526306\n",
      "    iteration 20, train_loss: 0.5761823058128357\n",
      "    iteration 30, train_loss: 0.5372899174690247\n",
      "    iteration 40, train_loss: 0.5070953965187073\n",
      "    iteration 50, train_loss: 0.6193762421607971\n",
      "    iteration 60, train_loss: 0.5562960505485535\n",
      "    iteration 70, train_loss: 0.5506182312965393\n",
      "    iteration 80, train_loss: 0.538034200668335\n",
      "    iteration 90, train_loss: 0.5442304015159607\n",
      "validation loss: [0.80049145]\n",
      "epoch 22\n",
      "    iteration 0, train_loss: 0.5797887444496155\n",
      "    iteration 10, train_loss: 0.536064088344574\n",
      "    iteration 20, train_loss: 0.5775331854820251\n",
      "    iteration 30, train_loss: 0.6185882687568665\n",
      "    iteration 40, train_loss: 0.6152282953262329\n",
      "    iteration 50, train_loss: 0.6961833238601685\n",
      "    iteration 60, train_loss: 0.5998715758323669\n",
      "    iteration 70, train_loss: 0.5949710607528687\n",
      "    iteration 80, train_loss: 0.5528843998908997\n",
      "    iteration 90, train_loss: 0.6588795781135559\n",
      "validation loss: [0.80428225]\n",
      "epoch 23\n",
      "    iteration 0, train_loss: 0.5007963180541992\n",
      "    iteration 10, train_loss: 0.6279250979423523\n",
      "    iteration 20, train_loss: 0.5585644245147705\n",
      "    iteration 30, train_loss: 0.5020020604133606\n",
      "    iteration 40, train_loss: 0.5555019378662109\n",
      "    iteration 50, train_loss: 0.6340946555137634\n",
      "    iteration 60, train_loss: 0.5699825882911682\n",
      "    iteration 70, train_loss: 0.5539911389350891\n",
      "    iteration 80, train_loss: 0.5574991703033447\n",
      "    iteration 90, train_loss: 0.5552628636360168\n",
      "validation loss: [0.783874]\n",
      "epoch 24\n",
      "    iteration 0, train_loss: 0.5619344711303711\n",
      "    iteration 10, train_loss: 0.6488648056983948\n",
      "    iteration 20, train_loss: 0.5248566269874573\n",
      "    iteration 30, train_loss: 0.5408430695533752\n",
      "    iteration 40, train_loss: 0.537613570690155\n",
      "    iteration 50, train_loss: 0.5651022791862488\n",
      "    iteration 60, train_loss: 0.7228679656982422\n",
      "    iteration 70, train_loss: 0.5622217655181885\n",
      "    iteration 80, train_loss: 0.5516258478164673\n",
      "    iteration 90, train_loss: 0.5818261504173279\n",
      "validation loss: [0.80094427]\n",
      "epoch 25\n",
      "    iteration 0, train_loss: 0.6336637139320374\n",
      "    iteration 10, train_loss: 0.5577242374420166\n",
      "    iteration 20, train_loss: 0.5605897307395935\n",
      "    iteration 30, train_loss: 0.6655815243721008\n",
      "    iteration 40, train_loss: 0.6003865003585815\n",
      "    iteration 50, train_loss: 0.508352518081665\n",
      "    iteration 60, train_loss: 0.5451562404632568\n",
      "    iteration 70, train_loss: 0.5842899084091187\n",
      "    iteration 80, train_loss: 0.5701961517333984\n",
      "    iteration 90, train_loss: 0.5445976257324219\n",
      "validation loss: [0.84688383]\n",
      "epoch 26\n",
      "    iteration 0, train_loss: 0.6007002592086792\n",
      "    iteration 10, train_loss: 0.6400064826011658\n",
      "    iteration 20, train_loss: 0.5272683501243591\n",
      "    iteration 30, train_loss: 0.5635196566581726\n",
      "    iteration 40, train_loss: 0.5317898392677307\n",
      "    iteration 50, train_loss: 0.5989381074905396\n",
      "    iteration 60, train_loss: 0.518127977848053\n",
      "    iteration 70, train_loss: 0.5267627239227295\n",
      "    iteration 80, train_loss: 0.582828164100647\n",
      "    iteration 90, train_loss: 0.5185012221336365\n",
      "validation loss: [0.81658363]\n",
      "epoch 27\n",
      "    iteration 0, train_loss: 0.5333389043807983\n",
      "    iteration 10, train_loss: 0.5923976302146912\n",
      "    iteration 20, train_loss: 0.5367463827133179\n",
      "    iteration 30, train_loss: 0.5681604743003845\n",
      "    iteration 40, train_loss: 0.529262363910675\n",
      "    iteration 50, train_loss: 0.5190137624740601\n",
      "    iteration 60, train_loss: 0.5356376767158508\n",
      "    iteration 70, train_loss: 0.5920529961585999\n",
      "    iteration 80, train_loss: 0.5771170258522034\n",
      "    iteration 90, train_loss: 0.6211540102958679\n",
      "validation loss: [0.80922943]\n",
      "epoch 28\n",
      "    iteration 0, train_loss: 0.5695828795433044\n",
      "    iteration 10, train_loss: 0.5376795530319214\n",
      "    iteration 20, train_loss: 0.5783432126045227\n",
      "    iteration 30, train_loss: 0.5479401350021362\n",
      "    iteration 40, train_loss: 0.5806492567062378\n",
      "    iteration 50, train_loss: 0.5352548360824585\n",
      "    iteration 60, train_loss: 0.6286544799804688\n",
      "    iteration 70, train_loss: 0.5910107493400574\n",
      "    iteration 80, train_loss: 0.5948083400726318\n",
      "    iteration 90, train_loss: 0.511177122592926\n",
      "validation loss: [0.8167378]\n",
      "epoch 29\n",
      "    iteration 0, train_loss: 0.5150323510169983\n",
      "    iteration 10, train_loss: 0.5546072721481323\n",
      "    iteration 20, train_loss: 0.5713704228401184\n",
      "    iteration 30, train_loss: 0.5323261022567749\n",
      "    iteration 40, train_loss: 0.5736832022666931\n",
      "    iteration 50, train_loss: 0.5782067775726318\n",
      "    iteration 60, train_loss: 0.6364333629608154\n",
      "    iteration 70, train_loss: 0.6847353577613831\n",
      "    iteration 80, train_loss: 0.5576099157333374\n",
      "    iteration 90, train_loss: 0.5874115228652954\n",
      "validation loss: [0.79749143]\n",
      "epoch 30\n",
      "    iteration 0, train_loss: 0.5214760303497314\n",
      "    iteration 10, train_loss: 0.5299416184425354\n",
      "    iteration 20, train_loss: 0.608900785446167\n",
      "    iteration 30, train_loss: 0.5829212665557861\n",
      "    iteration 40, train_loss: 0.5409019589424133\n",
      "    iteration 50, train_loss: 0.532228410243988\n",
      "    iteration 60, train_loss: 0.6193523406982422\n",
      "    iteration 70, train_loss: 0.577786386013031\n",
      "    iteration 80, train_loss: 0.5557548403739929\n",
      "    iteration 90, train_loss: 0.5514127016067505\n",
      "validation loss: [0.83020884]\n",
      "epoch 31\n",
      "    iteration 0, train_loss: 0.5984188914299011\n",
      "    iteration 10, train_loss: 0.5917147397994995\n",
      "    iteration 20, train_loss: 0.5129348635673523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    iteration 30, train_loss: 0.5881920456886292\n",
      "    iteration 40, train_loss: 0.5240142941474915\n",
      "    iteration 50, train_loss: 0.5670867562294006\n",
      "    iteration 60, train_loss: 0.5613515973091125\n",
      "    iteration 70, train_loss: 0.6174558997154236\n",
      "    iteration 80, train_loss: 0.49555256962776184\n",
      "    iteration 90, train_loss: 0.5704793334007263\n",
      "validation loss: [0.866627]\n",
      "epoch 32\n",
      "    iteration 0, train_loss: 0.5823479890823364\n",
      "    iteration 10, train_loss: 0.573551595211029\n",
      "    iteration 20, train_loss: 0.5214524269104004\n",
      "    iteration 30, train_loss: 0.5281431674957275\n",
      "    iteration 40, train_loss: 0.6403011679649353\n",
      "    iteration 50, train_loss: 0.5447624325752258\n",
      "    iteration 60, train_loss: 0.5400736927986145\n",
      "    iteration 70, train_loss: 0.5236027240753174\n",
      "    iteration 80, train_loss: 0.5556281208992004\n",
      "    iteration 90, train_loss: 0.5692905187606812\n",
      "validation loss: [0.80847055]\n",
      "epoch 33\n",
      "    iteration 0, train_loss: 0.5919811129570007\n",
      "    iteration 10, train_loss: 0.5422562956809998\n",
      "    iteration 20, train_loss: 0.659501314163208\n",
      "    iteration 30, train_loss: 0.5587654113769531\n",
      "    iteration 40, train_loss: 0.5564271211624146\n",
      "    iteration 50, train_loss: 0.517782986164093\n",
      "    iteration 60, train_loss: 0.5575990676879883\n",
      "    iteration 70, train_loss: 0.5807541012763977\n",
      "    iteration 80, train_loss: 0.6428607106208801\n",
      "    iteration 90, train_loss: 0.6029078960418701\n",
      "validation loss: [0.8122151]\n",
      "epoch 34\n",
      "    iteration 0, train_loss: 0.4790448546409607\n",
      "    iteration 10, train_loss: 0.5924816131591797\n",
      "    iteration 20, train_loss: 0.6427393555641174\n",
      "    iteration 30, train_loss: 0.6788415312767029\n",
      "    iteration 40, train_loss: 0.546880841255188\n",
      "    iteration 50, train_loss: 0.5686028599739075\n",
      "    iteration 60, train_loss: 0.5982839465141296\n",
      "    iteration 70, train_loss: 0.5104853510856628\n",
      "    iteration 80, train_loss: 0.7041603922843933\n",
      "    iteration 90, train_loss: 0.5900986790657043\n",
      "validation loss: [0.8476991]\n"
     ]
    }
   ],
   "source": [
    "# Save the model for later analysis\n",
    "save_model_path = '/home/ubuntu/data/team_neural_network/code/models'\n",
    "model_name = 'hybrid_net-tensorflow.h5'\n",
    "output_path = os.path.join(save_model_path, model_name)\n",
    "training_config = {'epochs': 35, 'iteration': 100, 'output_path': output_path}\n",
    "\n",
    "train_loss_record, val_loss_record = train(model, train_x, train_y, val_x, val_y, training_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f7608d86b38>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = range(1, len(val_loss_record) + 1)\n",
    "\n",
    "plt.plot(epochs, val_loss_record, '-', label='Validation Loss')\n",
    "plt.plot(epochs, train_loss_record, '-', label='Training Loss')\n",
    "plt.title('Training Loss vs Validation Loss')\n",
    "plt.xlabel('epoches')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subset sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3543"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_folder_path = \"../../../../temp/samples/\"\n",
    "output_folder_path = \"../../../../temp/buffers/ss_samples\"\n",
    "\n",
    "# sample data from:\n",
    "data_dir = \"/home/ubuntu/group_volume/team_neural_network/data/input/3.24_species_only\"\n",
    "\n",
    "len(os.listdir(data_dir)) # total number of regions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -r /home/ubuntu/data/temp/samples\n",
    "# !mkdir /home/ubuntu/data/temp/samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_data_lst = np.array(os.listdir(data_dir))\n",
    "# num_samples = 209\n",
    "\n",
    "# sampling(data_dir, input_folder_path, num_samples, seed = 189)\n",
    "\n",
    "# output_file_path = os.path.join(output_folder_path, 'train.data')\n",
    "# train_regions = one_hot_encoding(input_folder_path, output_file_path)\n",
    "\n",
    "# data_x, data_y = get_training_data(train_regions, output_folder_path,\n",
    "#                                    max_len = 1000, \n",
    "#                                    train_x_name = 'train_x.data', \n",
    "#                                    train_y_name = 'train_y.data')\n",
    "\n",
    "# train_x, train_y, val_x, val_y = data_split(data_x, data_y, seed = 157)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x = pickle.load(open('../../../../temp/buffers/train_x.data', 'rb'))\n",
    "data_y = pickle.load(open('../../../../temp/buffers/train_y.data', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12000 (9600, 1000, 4) (9600,) (2400, 1000, 4) (2400,)\n"
     ]
    }
   ],
   "source": [
    "train_x, train_y, val_x, val_y = data_split(data_x, data_y, seed = 157)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, val_x = pad_for_detector(train_x, 15), pad_for_detector(val_x, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0\n",
      "    iteration 0, train_loss: 5.400801181793213\n",
      "    iteration 10, train_loss: 5.384999752044678\n",
      "    iteration 20, train_loss: 5.350027561187744\n",
      "    iteration 30, train_loss: 5.353002071380615\n",
      "    iteration 40, train_loss: 5.269787311553955\n",
      "    iteration 50, train_loss: 5.124022006988525\n",
      "    iteration 60, train_loss: 5.06173849105835\n",
      "    iteration 70, train_loss: 4.9452362060546875\n",
      "    iteration 80, train_loss: 4.690897464752197\n",
      "    iteration 90, train_loss: 4.239868640899658\n",
      "validation loss: [3.8546667]\n",
      "epoch 1\n",
      "    iteration 0, train_loss: 3.8864567279815674\n",
      "    iteration 10, train_loss: 3.368736982345581\n",
      "    iteration 20, train_loss: 2.750802993774414\n",
      "    iteration 30, train_loss: 2.4254209995269775\n",
      "    iteration 40, train_loss: 2.101635694503784\n",
      "    iteration 50, train_loss: 1.6022752523422241\n",
      "    iteration 60, train_loss: 1.5020135641098022\n",
      "    iteration 70, train_loss: 1.5331519842147827\n",
      "    iteration 80, train_loss: 1.4036635160446167\n",
      "    iteration 90, train_loss: 1.213472604751587\n",
      "validation loss: [1.209825]\n",
      "epoch 2\n",
      "    iteration 0, train_loss: 1.216079831123352\n",
      "    iteration 10, train_loss: 1.2652502059936523\n",
      "    iteration 20, train_loss: 1.061010479927063\n",
      "    iteration 30, train_loss: 0.9798846244812012\n",
      "    iteration 40, train_loss: 0.9527210593223572\n",
      "    iteration 50, train_loss: 1.0577175617218018\n",
      "    iteration 60, train_loss: 0.9899581074714661\n",
      "    iteration 70, train_loss: 0.8895781636238098\n",
      "    iteration 80, train_loss: 0.9664099216461182\n",
      "    iteration 90, train_loss: 0.9138054847717285\n",
      "validation loss: [0.8769973]\n",
      "epoch 3\n",
      "    iteration 0, train_loss: 0.8377950191497803\n",
      "    iteration 10, train_loss: 0.906867265701294\n",
      "    iteration 20, train_loss: 0.8912754058837891\n",
      "    iteration 30, train_loss: 0.9353402256965637\n",
      "    iteration 40, train_loss: 0.8202336430549622\n",
      "    iteration 50, train_loss: 0.8709067702293396\n",
      "    iteration 60, train_loss: 0.8160790801048279\n",
      "    iteration 70, train_loss: 0.8232748508453369\n",
      "    iteration 80, train_loss: 0.7348940968513489\n",
      "    iteration 90, train_loss: 0.8278658986091614\n",
      "validation loss: [0.8022499]\n",
      "epoch 4\n",
      "    iteration 0, train_loss: 0.770943820476532\n",
      "    iteration 10, train_loss: 0.7817864418029785\n",
      "    iteration 20, train_loss: 0.883913516998291\n",
      "    iteration 30, train_loss: 0.8836656212806702\n",
      "    iteration 40, train_loss: 0.8574451804161072\n",
      "    iteration 50, train_loss: 0.7345148921012878\n",
      "    iteration 60, train_loss: 0.7914530634880066\n",
      "    iteration 70, train_loss: 0.8375077247619629\n",
      "    iteration 80, train_loss: 0.786175549030304\n",
      "    iteration 90, train_loss: 0.7453777194023132\n",
      "validation loss: [0.7725447]\n",
      "epoch 5\n",
      "    iteration 0, train_loss: 0.7254684567451477\n",
      "    iteration 10, train_loss: 0.7655753493309021\n",
      "    iteration 20, train_loss: 0.7784361839294434\n",
      "    iteration 30, train_loss: 0.7835471630096436\n",
      "    iteration 40, train_loss: 0.6963695883750916\n",
      "    iteration 50, train_loss: 0.6970458030700684\n",
      "    iteration 60, train_loss: 0.766289234161377\n",
      "    iteration 70, train_loss: 0.7885163426399231\n",
      "    iteration 80, train_loss: 0.7761654853820801\n",
      "    iteration 90, train_loss: 0.7308874130249023\n",
      "validation loss: [0.72842073]\n",
      "epoch 6\n",
      "    iteration 0, train_loss: 0.7905817031860352\n",
      "    iteration 10, train_loss: 0.7221236824989319\n",
      "    iteration 20, train_loss: 0.686898410320282\n",
      "    iteration 30, train_loss: 0.7239474654197693\n",
      "    iteration 40, train_loss: 0.7236786484718323\n",
      "    iteration 50, train_loss: 0.703441321849823\n",
      "    iteration 60, train_loss: 0.6725345253944397\n",
      "    iteration 70, train_loss: 0.7606777548789978\n",
      "    iteration 80, train_loss: 0.7205864787101746\n",
      "    iteration 90, train_loss: 0.716352641582489\n",
      "validation loss: [0.7330248]\n",
      "epoch 7\n",
      "    iteration 0, train_loss: 0.7672010064125061\n",
      "    iteration 10, train_loss: 0.803565502166748\n",
      "    iteration 20, train_loss: 0.7070481777191162\n",
      "    iteration 30, train_loss: 0.7435680031776428\n",
      "    iteration 40, train_loss: 0.6762301921844482\n",
      "    iteration 50, train_loss: 0.7078177332878113\n",
      "    iteration 60, train_loss: 0.7365903854370117\n",
      "    iteration 70, train_loss: 0.7375614047050476\n",
      "    iteration 80, train_loss: 0.711175262928009\n",
      "    iteration 90, train_loss: 0.7239055633544922\n",
      "validation loss: [0.70100075]\n",
      "epoch 8\n",
      "    iteration 0, train_loss: 0.716001033782959\n",
      "    iteration 10, train_loss: 0.7004895806312561\n",
      "    iteration 20, train_loss: 0.7300453186035156\n",
      "    iteration 30, train_loss: 0.6571288704872131\n",
      "    iteration 40, train_loss: 0.6616174578666687\n",
      "    iteration 50, train_loss: 0.6545304656028748\n",
      "    iteration 60, train_loss: 0.6633771061897278\n",
      "    iteration 70, train_loss: 0.7438628077507019\n",
      "    iteration 80, train_loss: 0.7584118843078613\n",
      "    iteration 90, train_loss: 0.6534485220909119\n",
      "validation loss: [0.68290347]\n",
      "epoch 9\n",
      "    iteration 0, train_loss: 0.6253754496574402\n",
      "    iteration 10, train_loss: 0.6808490753173828\n",
      "    iteration 20, train_loss: 0.5968311429023743\n",
      "    iteration 30, train_loss: 0.6831075549125671\n",
      "    iteration 40, train_loss: 0.6339715123176575\n",
      "    iteration 50, train_loss: 0.7467823028564453\n",
      "    iteration 60, train_loss: 0.6450605988502502\n",
      "    iteration 70, train_loss: 0.6982245445251465\n",
      "    iteration 80, train_loss: 0.6269367337226868\n",
      "    iteration 90, train_loss: 0.710076630115509\n",
      "validation loss: [0.6748328]\n",
      "epoch 10\n",
      "    iteration 0, train_loss: 0.6792883276939392\n",
      "    iteration 10, train_loss: 0.6763865947723389\n",
      "    iteration 20, train_loss: 0.6166736483573914\n",
      "    iteration 30, train_loss: 0.6002528071403503\n",
      "    iteration 40, train_loss: 0.6792371869087219\n",
      "    iteration 50, train_loss: 0.5814383625984192\n",
      "    iteration 60, train_loss: 0.6404262185096741\n",
      "    iteration 70, train_loss: 0.6607449054718018\n",
      "    iteration 80, train_loss: 0.654286801815033\n",
      "    iteration 90, train_loss: 0.5484581589698792\n",
      "validation loss: [0.6620371]\n",
      "epoch 11\n",
      "    iteration 0, train_loss: 0.6378708481788635\n",
      "    iteration 10, train_loss: 0.6513016819953918\n",
      "    iteration 20, train_loss: 0.6904824376106262\n",
      "    iteration 30, train_loss: 0.60246342420578\n",
      "    iteration 40, train_loss: 0.6429687142372131\n",
      "    iteration 50, train_loss: 0.6137354373931885\n",
      "    iteration 60, train_loss: 0.6413954496383667\n",
      "    iteration 70, train_loss: 0.6279309988021851\n",
      "    iteration 80, train_loss: 0.7178795337677002\n",
      "    iteration 90, train_loss: 0.6697096824645996\n",
      "validation loss: [0.6506665]\n",
      "epoch 12\n",
      "    iteration 0, train_loss: 0.6528084874153137\n",
      "    iteration 10, train_loss: 0.6042836308479309\n",
      "    iteration 20, train_loss: 0.6353196501731873\n",
      "    iteration 30, train_loss: 0.682501494884491\n",
      "    iteration 40, train_loss: 0.7257752418518066\n",
      "    iteration 50, train_loss: 0.6219534873962402\n",
      "    iteration 60, train_loss: 0.6713712811470032\n",
      "    iteration 70, train_loss: 0.6364044547080994\n",
      "    iteration 80, train_loss: 0.6523651480674744\n",
      "    iteration 90, train_loss: 0.5945385098457336\n",
      "validation loss: [0.64747536]\n",
      "epoch 13\n",
      "    iteration 0, train_loss: 0.6822488903999329\n",
      "    iteration 10, train_loss: 0.5450248122215271\n",
      "    iteration 20, train_loss: 0.7662776112556458\n",
      "    iteration 30, train_loss: 0.573570191860199\n",
      "    iteration 40, train_loss: 0.6538071036338806\n",
      "    iteration 50, train_loss: 0.6061643362045288\n",
      "    iteration 60, train_loss: 0.6156781315803528\n",
      "    iteration 70, train_loss: 0.6438466906547546\n",
      "    iteration 80, train_loss: 0.5892584919929504\n",
      "    iteration 90, train_loss: 0.5830536484718323\n",
      "validation loss: [0.64379746]\n",
      "epoch 14\n",
      "    iteration 0, train_loss: 0.6899001002311707\n",
      "    iteration 10, train_loss: 0.6035284399986267\n",
      "    iteration 20, train_loss: 0.6489235758781433\n",
      "    iteration 30, train_loss: 0.6165439486503601\n",
      "    iteration 40, train_loss: 0.5927132368087769\n",
      "    iteration 50, train_loss: 0.6188762784004211\n",
      "    iteration 60, train_loss: 0.6125946044921875\n",
      "    iteration 70, train_loss: 0.6515617966651917\n",
      "    iteration 80, train_loss: 0.6126043200492859\n",
      "    iteration 90, train_loss: 0.6912687420845032\n",
      "validation loss: [0.63605523]\n",
      "epoch 15\n",
      "    iteration 0, train_loss: 0.6148970127105713\n",
      "    iteration 10, train_loss: 0.6260021328926086\n",
      "    iteration 20, train_loss: 0.6330572962760925\n",
      "    iteration 30, train_loss: 0.6253430247306824\n",
      "    iteration 40, train_loss: 0.6749655604362488\n",
      "    iteration 50, train_loss: 0.5734081864356995\n",
      "    iteration 60, train_loss: 0.635384738445282\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    iteration 70, train_loss: 0.5773077607154846\n",
      "    iteration 80, train_loss: 0.6421653628349304\n",
      "    iteration 90, train_loss: 0.6068955063819885\n",
      "validation loss: [0.6381568]\n",
      "epoch 16\n",
      "    iteration 0, train_loss: 0.5747350454330444\n",
      "    iteration 10, train_loss: 0.617926299571991\n",
      "    iteration 20, train_loss: 0.6130749583244324\n",
      "    iteration 30, train_loss: 0.5373334288597107\n",
      "    iteration 40, train_loss: 0.5630791783332825\n",
      "    iteration 50, train_loss: 0.6024407744407654\n",
      "    iteration 60, train_loss: 0.5914209485054016\n",
      "    iteration 70, train_loss: 0.631920337677002\n",
      "    iteration 80, train_loss: 0.5883446931838989\n",
      "    iteration 90, train_loss: 0.6240007281303406\n",
      "validation loss: [0.6492068]\n",
      "epoch 17\n",
      "    iteration 0, train_loss: 0.6115298271179199\n",
      "    iteration 10, train_loss: 0.592290461063385\n",
      "    iteration 20, train_loss: 0.5560094714164734\n",
      "    iteration 30, train_loss: 0.61726313829422\n",
      "    iteration 40, train_loss: 0.6182331442832947\n",
      "    iteration 50, train_loss: 0.6115777492523193\n",
      "    iteration 60, train_loss: 0.6005866527557373\n",
      "    iteration 70, train_loss: 0.5819190144538879\n",
      "    iteration 80, train_loss: 0.6251696944236755\n",
      "    iteration 90, train_loss: 0.5542395114898682\n",
      "validation loss: [0.6317607]\n",
      "epoch 18\n",
      "    iteration 0, train_loss: 0.5786653161048889\n",
      "    iteration 10, train_loss: 0.6575778126716614\n",
      "    iteration 20, train_loss: 0.49833014607429504\n",
      "    iteration 30, train_loss: 0.6220687031745911\n",
      "    iteration 40, train_loss: 0.6268169283866882\n",
      "    iteration 50, train_loss: 0.5948818325996399\n",
      "    iteration 60, train_loss: 0.6289600729942322\n",
      "    iteration 70, train_loss: 0.6147362589836121\n",
      "    iteration 80, train_loss: 0.5420631766319275\n",
      "    iteration 90, train_loss: 0.5774337649345398\n",
      "validation loss: [0.62521845]\n",
      "epoch 19\n",
      "    iteration 0, train_loss: 0.6135474443435669\n",
      "    iteration 10, train_loss: 0.5279227495193481\n",
      "    iteration 20, train_loss: 0.6347782015800476\n",
      "    iteration 30, train_loss: 0.6797633767127991\n",
      "    iteration 40, train_loss: 0.6419655680656433\n",
      "    iteration 50, train_loss: 0.7265288233757019\n",
      "    iteration 60, train_loss: 0.5793009400367737\n",
      "    iteration 70, train_loss: 0.5513734221458435\n",
      "    iteration 80, train_loss: 0.6195129752159119\n",
      "    iteration 90, train_loss: 0.6025456786155701\n",
      "validation loss: [0.6163579]\n",
      "epoch 20\n",
      "    iteration 0, train_loss: 0.6473850607872009\n",
      "    iteration 10, train_loss: 0.6987042427062988\n",
      "    iteration 20, train_loss: 0.5685246586799622\n",
      "    iteration 30, train_loss: 0.5800878405570984\n",
      "    iteration 40, train_loss: 0.6000846028327942\n",
      "    iteration 50, train_loss: 0.6383368968963623\n",
      "    iteration 60, train_loss: 0.6005756855010986\n",
      "    iteration 70, train_loss: 0.6122643947601318\n",
      "    iteration 80, train_loss: 0.5480388402938843\n",
      "    iteration 90, train_loss: 0.6524867415428162\n",
      "validation loss: [0.6186705]\n",
      "epoch 21\n",
      "    iteration 0, train_loss: 0.5443618297576904\n",
      "    iteration 10, train_loss: 0.5009046792984009\n",
      "    iteration 20, train_loss: 0.5496649742126465\n",
      "    iteration 30, train_loss: 0.5992000699043274\n",
      "    iteration 40, train_loss: 0.6587652564048767\n",
      "    iteration 50, train_loss: 0.6103527545928955\n",
      "    iteration 60, train_loss: 0.5927308201789856\n",
      "    iteration 70, train_loss: 0.6238536834716797\n",
      "    iteration 80, train_loss: 0.5927934646606445\n",
      "    iteration 90, train_loss: 0.6127648949623108\n",
      "validation loss: [0.6073127]\n",
      "epoch 22\n",
      "    iteration 0, train_loss: 0.5794652700424194\n",
      "    iteration 10, train_loss: 0.6277619004249573\n",
      "    iteration 20, train_loss: 0.6220241189002991\n",
      "    iteration 30, train_loss: 0.6233122944831848\n",
      "    iteration 40, train_loss: 0.6345288157463074\n",
      "    iteration 50, train_loss: 0.5643845200538635\n",
      "    iteration 60, train_loss: 0.5240238308906555\n",
      "    iteration 70, train_loss: 0.5599433779716492\n",
      "    iteration 80, train_loss: 0.6011409759521484\n",
      "    iteration 90, train_loss: 0.7361769676208496\n",
      "validation loss: [0.59862345]\n",
      "epoch 23\n",
      "    iteration 0, train_loss: 0.5337636470794678\n",
      "    iteration 10, train_loss: 0.6182594895362854\n",
      "    iteration 20, train_loss: 0.515590250492096\n",
      "    iteration 30, train_loss: 0.6035959720611572\n",
      "    iteration 40, train_loss: 0.5758967399597168\n",
      "    iteration 50, train_loss: 0.578769862651825\n",
      "    iteration 60, train_loss: 0.5675089955329895\n",
      "    iteration 70, train_loss: 0.5776456594467163\n",
      "    iteration 80, train_loss: 0.5706970691680908\n",
      "    iteration 90, train_loss: 0.6909710764884949\n",
      "validation loss: [0.63032967]\n",
      "epoch 24\n",
      "    iteration 0, train_loss: 0.5526170134544373\n",
      "    iteration 10, train_loss: 0.5831202864646912\n",
      "    iteration 20, train_loss: 0.5880508422851562\n",
      "    iteration 30, train_loss: 0.6503950357437134\n",
      "    iteration 40, train_loss: 0.5470032691955566\n",
      "    iteration 50, train_loss: 0.5854251384735107\n",
      "    iteration 60, train_loss: 0.6528026461601257\n",
      "    iteration 70, train_loss: 0.5381849408149719\n",
      "    iteration 80, train_loss: 0.547444760799408\n",
      "    iteration 90, train_loss: 0.6753284931182861\n",
      "validation loss: [0.6170746]\n",
      "epoch 25\n",
      "    iteration 0, train_loss: 0.5626130700111389\n",
      "    iteration 10, train_loss: 0.6567205786705017\n",
      "    iteration 20, train_loss: 0.5884453058242798\n",
      "    iteration 30, train_loss: 0.6068069338798523\n",
      "    iteration 40, train_loss: 0.5905681252479553\n",
      "    iteration 50, train_loss: 0.6342962384223938\n",
      "    iteration 60, train_loss: 0.6116963028907776\n",
      "    iteration 70, train_loss: 0.5347902178764343\n",
      "    iteration 80, train_loss: 0.6118190288543701\n",
      "    iteration 90, train_loss: 0.7050269246101379\n",
      "validation loss: [0.5991037]\n",
      "epoch 26\n",
      "    iteration 0, train_loss: 0.5503358840942383\n",
      "    iteration 10, train_loss: 0.6155617833137512\n",
      "    iteration 20, train_loss: 0.608533501625061\n",
      "    iteration 30, train_loss: 0.5460649132728577\n",
      "    iteration 40, train_loss: 0.6498380899429321\n",
      "    iteration 50, train_loss: 0.5767564177513123\n",
      "    iteration 60, train_loss: 0.7290468215942383\n",
      "    iteration 70, train_loss: 0.5341250896453857\n",
      "    iteration 80, train_loss: 0.5589146018028259\n",
      "    iteration 90, train_loss: 0.5510988831520081\n",
      "validation loss: [0.6049748]\n",
      "epoch 27\n",
      "    iteration 0, train_loss: 0.54671311378479\n",
      "    iteration 10, train_loss: 0.5766981840133667\n",
      "    iteration 20, train_loss: 0.6203790307044983\n",
      "    iteration 30, train_loss: 0.5666971802711487\n",
      "    iteration 40, train_loss: 0.487860769033432\n",
      "    iteration 50, train_loss: 0.5604708194732666\n",
      "    iteration 60, train_loss: 0.6487987637519836\n",
      "    iteration 70, train_loss: 0.6100136637687683\n",
      "    iteration 80, train_loss: 0.5894802212715149\n",
      "    iteration 90, train_loss: 0.6149644255638123\n",
      "validation loss: [0.61800534]\n",
      "epoch 28\n",
      "    iteration 0, train_loss: 0.4449720084667206\n",
      "    iteration 10, train_loss: 0.6017694473266602\n",
      "    iteration 20, train_loss: 0.6201440691947937\n",
      "    iteration 30, train_loss: 0.6255103945732117\n",
      "    iteration 40, train_loss: 0.5853615999221802\n",
      "    iteration 50, train_loss: 0.7124180793762207\n",
      "    iteration 60, train_loss: 0.5823971033096313\n",
      "    iteration 70, train_loss: 0.5316436886787415\n",
      "    iteration 80, train_loss: 0.6170653104782104\n",
      "    iteration 90, train_loss: 0.4689757525920868\n",
      "validation loss: [0.6029254]\n",
      "epoch 29\n",
      "    iteration 0, train_loss: 0.5574279427528381\n",
      "    iteration 10, train_loss: 0.6339234709739685\n",
      "    iteration 20, train_loss: 0.563955545425415\n",
      "    iteration 30, train_loss: 0.6673445105552673\n",
      "    iteration 40, train_loss: 0.5665391087532043\n",
      "    iteration 50, train_loss: 0.5745492577552795\n",
      "    iteration 60, train_loss: 0.626520574092865\n",
      "    iteration 70, train_loss: 0.6227853298187256\n",
      "    iteration 80, train_loss: 0.5624840259552002\n",
      "    iteration 90, train_loss: 0.6301413774490356\n",
      "validation loss: [0.6032046]\n",
      "epoch 30\n",
      "    iteration 0, train_loss: 0.5888518691062927\n",
      "    iteration 10, train_loss: 0.6097488403320312\n",
      "    iteration 20, train_loss: 0.5845968127250671\n",
      "    iteration 30, train_loss: 0.5735548734664917\n",
      "    iteration 40, train_loss: 0.5324313044548035\n",
      "    iteration 50, train_loss: 0.6230562329292297\n",
      "    iteration 60, train_loss: 0.5611454844474792\n",
      "    iteration 70, train_loss: 0.5630456805229187\n",
      "    iteration 80, train_loss: 0.5756888389587402\n",
      "    iteration 90, train_loss: 0.6684949398040771\n",
      "validation loss: [0.6041738]\n",
      "epoch 31\n",
      "    iteration 0, train_loss: 0.49768903851509094\n",
      "    iteration 10, train_loss: 0.47512221336364746\n",
      "    iteration 20, train_loss: 0.5917752385139465\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    iteration 30, train_loss: 0.5537970662117004\n",
      "    iteration 40, train_loss: 0.5200377106666565\n",
      "    iteration 50, train_loss: 0.5912787914276123\n",
      "    iteration 60, train_loss: 0.5829278826713562\n",
      "    iteration 70, train_loss: 0.5247385501861572\n",
      "    iteration 80, train_loss: 0.5041388869285583\n",
      "    iteration 90, train_loss: 0.5240468382835388\n",
      "validation loss: [0.60263497]\n",
      "epoch 32\n",
      "    iteration 0, train_loss: 0.6192811131477356\n",
      "    iteration 10, train_loss: 0.5141210556030273\n",
      "    iteration 20, train_loss: 0.5038297176361084\n",
      "    iteration 30, train_loss: 0.6479779481887817\n",
      "    iteration 40, train_loss: 0.6874573826789856\n",
      "    iteration 50, train_loss: 0.5809447169303894\n",
      "    iteration 60, train_loss: 0.5053843855857849\n",
      "    iteration 70, train_loss: 0.5780931711196899\n",
      "    iteration 80, train_loss: 0.5233991742134094\n",
      "    iteration 90, train_loss: 0.5976720452308655\n",
      "validation loss: [0.5898661]\n",
      "epoch 33\n",
      "    iteration 0, train_loss: 0.5498242974281311\n",
      "    iteration 10, train_loss: 0.6476632952690125\n",
      "    iteration 20, train_loss: 0.4957752525806427\n",
      "    iteration 30, train_loss: 0.5666400194168091\n",
      "    iteration 40, train_loss: 0.5919061899185181\n",
      "    iteration 50, train_loss: 0.5341144800186157\n",
      "    iteration 60, train_loss: 0.5897400975227356\n",
      "    iteration 70, train_loss: 0.5628926753997803\n",
      "    iteration 80, train_loss: 0.488674134016037\n",
      "    iteration 90, train_loss: 0.4999893009662628\n",
      "validation loss: [0.60483325]\n",
      "epoch 34\n",
      "    iteration 0, train_loss: 0.5666974782943726\n",
      "    iteration 10, train_loss: 0.48361504077911377\n",
      "    iteration 20, train_loss: 0.6512014269828796\n",
      "    iteration 30, train_loss: 0.5784574151039124\n",
      "    iteration 40, train_loss: 0.5611777305603027\n",
      "    iteration 50, train_loss: 0.7497148513793945\n",
      "    iteration 60, train_loss: 0.5658080577850342\n",
      "    iteration 70, train_loss: 0.49868273735046387\n",
      "    iteration 80, train_loss: 0.5417532920837402\n",
      "    iteration 90, train_loss: 0.5749392509460449\n",
      "validation loss: [0.6044359]\n"
     ]
    }
   ],
   "source": [
    "# Save the model for later analysis\n",
    "save_model_path = '/home/ubuntu/data/team_neural_network/code/models'\n",
    "model_name = 'hybrid_net-tensorflow-2.h5'\n",
    "output_path = os.path.join(save_model_path, model_name)\n",
    "training_config = {'epochs': 35, 'iteration': 100, 'output_path': output_path}\n",
    "\n",
    "train_loss_record, val_loss_record = train(model, train_x, train_y, val_x, val_y, training_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f7646f14d68>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "epochs = range(1, len(val_loss_record) + 1)\n",
    "\n",
    "plt.plot(epochs, val_loss_record, '-', label='Validation Loss')\n",
    "plt.plot(epochs, train_loss_record, '-', label='Training Loss')\n",
    "plt.title('Training Loss vs Validation Loss')\n",
    "plt.xlabel('epoches')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
