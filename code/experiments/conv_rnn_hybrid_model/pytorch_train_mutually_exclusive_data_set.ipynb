{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tesla K80\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "import math\n",
    "import torch\n",
    "from torch.utils import model_zoo\n",
    "import os\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from utilities import sampling, one_hot_encoding, curtail, get_training_data, load_data, data_split, dianostic_plots, pad_for_detector\n",
    "use_cuda = torch.cuda.is_available()\n",
    "device = torch.device(\"cuda:0\" if use_cuda else \"cpu\")\n",
    "if use_cuda:\n",
    "    print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3543"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subset sampling: save to me_samples; \"me\" for \"mutually exclusive\"\n",
    "output_folder_path = \"../../../../temp/buffers/me_samples\"\n",
    "\n",
    "data_dir = \"/home/ubuntu/group_volume/team_neural_network/data/input/3.24_species_only\"\n",
    "\n",
    "len(os.listdir(data_dir)) # total number of regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the following code chunk to resample training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -r /home/ubuntu/data/temp/train\n",
    "# !mkdir /home/ubuntu/data/temp/train\n",
    "# !rm -r /home/ubuntu/data/temp/val\n",
    "# !mkdir /home/ubuntu/data/temp/val\n",
    "\n",
    "# ###############################################################################\n",
    "# # Sample training and validation data\n",
    "# # IMPORTANT: Make sure that training and validation don't have intersection!!!\n",
    "# ###############################################################################\n",
    "# all_data_lst = np.array(os.listdir(data_dir))\n",
    "# n = len(all_data_lst)\n",
    "# num_trained_regions = int(n * 0.8)\n",
    "# train_files = all_data_lst[:num_trained_regions]\n",
    "# num_val = n - num_trained_regions\n",
    "# val_indices = np.random.choice(np.arange(num_trained_regions, n), num_val, replace = False)\n",
    "# val_files = all_data_lst[val_indices]\n",
    "\n",
    "# train_dest = '/home/ubuntu/data/temp/train/'\n",
    "# for file in train_files:\n",
    "#     shutil.copy(os.path.join(data_dir, file),\n",
    "#                           train_dest)\n",
    "# print('copied training samples to {}'.format(train_dest))\n",
    "\n",
    "# val_dest = '/home/ubuntu/data/temp/val/'\n",
    "# for file in val_files:\n",
    "#     shutil.copy(os.path.join(data_dir, file),\n",
    "#                           val_dest)\n",
    "# print('copied validation samples to {}'.format(val_dest))\n",
    "\n",
    "# # Preprocess train and val data so that they are ready to be fed to models\n",
    "# train_output_path = os.path.join(output_folder_path, 'train.data')\n",
    "# val_output_path = os.path.join(output_folder_path, 'val.data')\n",
    "\n",
    "# train_regions = one_hot_encoding(train_dest, train_output_path)\n",
    "# val_regions = one_hot_encoding(val_dest, val_output_path)\n",
    "# train_x, train_y = get_training_data(train_regions, output_folder_path,\n",
    "#                                    max_len = 1000, \n",
    "#                                    train_x_name = 'train_x.data', \n",
    "#                                    train_y_name = 'train_y.data')\n",
    "# val_x, val_y = get_training_data(val_regions, output_folder_path,\n",
    "#                                    max_len = 1000, \n",
    "#                                    train_x_name = 'val_x.data', \n",
    "#                                    train_y_name = 'val_y.data')\n",
    "# # Pad for motif detectors\n",
    "# train_x, val_x = pad_for_detector(train_x, 15), pad_for_detector(val_x, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_x = pickle.load(open('../../../../temp/buffers/ss_samples/train_x.data', 'rb'))\n",
    "# data_y = pickle.load(open('../../../../temp/buffers/ss_samples/train_y.data', 'rb'))\n",
    "# train_x, train_y, val_x, val_y = data_split(data_x, data_y, seed = 157)\n",
    "# train_x, val_x = pad_for_detector(train_x, 10), pad_for_detector(val_x, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = pickle.load(open(os.path.join(output_folder_path, 'train_x.data'), 'rb'))\n",
    "train_y = pickle.load(open(os.path.join(output_folder_path, 'train_y.data'), 'rb'))\n",
    "val_x = pickle.load(open(os.path.join(output_folder_path, 'val_x.data'), 'rb'))\n",
    "val_y = pickle.load(open(os.path.join(output_folder_path, 'val_y.data'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 15 # number of filters\n",
    "m = 30 # filter size\n",
    "train_x, val_x = pad_for_detector(train_x, m), pad_for_detector(val_x, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x, val_x = torch.from_numpy(train_x).float(), torch.from_numpy(val_x).float()\n",
    "train_y, val_y = torch.from_numpy(train_y).float(), torch.from_numpy(val_y).float()\n",
    "\n",
    "# Convert data format from channel_last to channer_first\n",
    "N, L, C = train_x.shape\n",
    "n, l, _ = val_x.shape\n",
    "train_x = train_x.reshape(N, C, L)\n",
    "val_x = val_x.reshape(n, C, l)\n",
    "\n",
    "# Generate dataset for data loader\n",
    "train_dataset = data.TensorDataset(train_x, train_y)\n",
    "val_dataset = data.TensorDataset(val_x, val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reference for connecting Conv1D and LSTM: https://mxnet.incubator.apache.org/versions/master/tutorials/basic/reshape_transpose.html\n",
    "class HybridNet(nn.Module):\n",
    "    \n",
    "    def __init__(self, pesudo_input, num_filters, filter_size, rnn_size, fc_out, dp1, dp2, \n",
    "                 num_rnn_layers=1, rnn_dropout=0):\n",
    "        super(HybridNet, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(in_channels=4, out_channels=num_filters, kernel_size=filter_size)\n",
    "        out = self.conv1(pesudo_input)\n",
    "        out = nn.MaxPool1d(kernel_size=5, stride=5)(out)\n",
    "        ####################################################\n",
    "        print('shape after conv1d {}'.format(out.shape))\n",
    "        N, C, T = out.shape\n",
    "        out = torch.transpose(out, 1, 2)\n",
    "        print('shape before lstm {}'.format(out.shape))\n",
    "        ####################################################\n",
    "        # or input_size*seq_len\n",
    "        self.bi_lstm = nn.LSTM(input_size=C, hidden_size=rnn_size, num_layers=num_rnn_layers,\n",
    "                              batch_first=True, dropout=rnn_dropout, bidirectional=True)\n",
    "        out, _ = self.bi_lstm(out)\n",
    "        print('shape after lstm {}'.format(out.shape))\n",
    "        N, T, C = out.shape\n",
    "        out = torch.transpose(out, 1, 2)\n",
    "        out = out.reshape(N, -1)\n",
    "        print('shape after flattening {}'.format(out.shape))\n",
    "        self.fc1 = nn.Linear(T*C, fc_out, bias=True)\n",
    "        self.fc2 = nn.Linear(fc_out, 1)\n",
    "        self.p1 = dp1\n",
    "        self.p2 = dp2\n",
    "        \n",
    "    def forward(self, seq):\n",
    "        self.activation_seq = F.relu(self.conv1(seq))\n",
    "        out = nn.MaxPool1d(kernel_size=5, stride=5)(self.activation_seq)\n",
    "        out = nn.Dropout(p=self.p1)(out)\n",
    "        \n",
    "        #################################################################################\n",
    "        # Input of LSTM layer should have shape (sequence_length, batch_size, input_size)\n",
    "        #     - Sequence length here should be the length of activation after downsampling\n",
    "        #     - Input size should be the number of filters\n",
    "        #################################################################################\n",
    "        N, C, T = out.shape\n",
    "#         out = out.view(bs, 1, -1)\n",
    "        out = torch.transpose(out, 1, 2)\n",
    "        out, _ = self.bi_lstm(out)\n",
    "        out = F.relu(out)\n",
    "        \n",
    "        #################################################################################\n",
    "        # Need to flatten the sequence before feeding them into fully connected layer\n",
    "        #################################################################################\n",
    "        N, T, C = out.shape\n",
    "        out = torch.transpose(out, 1, 2)\n",
    "        out = out.reshape(N, -1)\n",
    "        out = nn.Dropout(p=self.p2)(out)\n",
    "        out = self.fc1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = torch.squeeze(out)\n",
    "        return nn.Sigmoid()(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape after conv1d torch.Size([32, 17016, 205])\n",
      "shape before lstm torch.Size([32, 205, 17016])\n",
      "shape after lstm torch.Size([32, 205, 20])\n",
      "shape after flattening torch.Size([32, 4100])\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "pesudo_input = torch.rand(batch_size, C, L, dtype=train_x.dtype)\n",
    "hybrid_net = HybridNet(pesudo_input,\n",
    "                       num_filters=n, \n",
    "                       filter_size=m, \n",
    "                       rnn_size=10, \n",
    "                       fc_out=20, \n",
    "                       dp1=0.6, dp2=0.7).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_dataset, val_dataset, config):\n",
    "    # Unpack config\n",
    "    epochs = config['epochs']\n",
    "    device = config['device']\n",
    "    optimizer = config['opt']\n",
    "    criterion = config['criterion']\n",
    "    log_interval = config['log_interval']\n",
    "    batch_size = config['batch_size']\n",
    "    \n",
    "    def get_acc(y_hat, y):\n",
    "        y_pred = np.where(y_hat >=0.5, 1, 0)\n",
    "        return np.mean(y_pred == y)\n",
    "    \n",
    "    # Generate data loaders\n",
    "    val_loader = None\n",
    "    train_loader = data.DataLoader(train_dataset, batch_size=batch_size)\n",
    "    if val_dataset is not None:\n",
    "        val_loader = data.DataLoader(val_dataset, batch_size=batch_size)\n",
    "    total_train_steps = len(train_loader)\n",
    "    total_val_steps = len(val_loader)\n",
    "    \n",
    "    train_loss_list, val_loss_list = [], []\n",
    "    train_acc_list, val_acc_list = [], []\n",
    "    print(\"Train on {} samples, validate on {} samples\".format(len(train_dataset), len(val_dataset)))\n",
    "    # Start training\n",
    "    for epoch in range(1, epochs+1):\n",
    "        train_loss_sum, train_acc_sum = 0, 0\n",
    "        tic = time.time()\n",
    "        for i, (batch, labels) in enumerate(train_loader):\n",
    "            # Forward pass and calculating loss\n",
    "            batch, labels = batch.to(device), labels.to(device)\n",
    "            y_hat = model(batch)\n",
    "            loss = criterion(y_hat, labels)\n",
    "            \n",
    "            # Backward pass and updating weights\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss_sum += loss.item()\n",
    "            train_acc_sum += get_acc(y_hat.cpu().detach().numpy(), labels.cpu().detach().numpy())\n",
    "        tac = time.time()\n",
    "        avg_train_loss = train_loss_sum/total_train_steps\n",
    "        avg_train_acc = train_acc_sum/total_train_steps\n",
    "        train_loss_list.append(avg_train_loss)\n",
    "        train_acc_list.append(avg_train_acc)\n",
    "        print('***************************************')\n",
    "        print('Epoch {}: training loss {}, training acc {}'.format(epoch, avg_train_loss, avg_train_acc))\n",
    "        print('Time: {} \\n'.format(tac-tic))\n",
    "        \n",
    "        # Validation\n",
    "        if val_loader is not None:\n",
    "            if epoch % log_interval == 0 or epoch == epochs:\n",
    "                with torch.no_grad():\n",
    "                    val_loss_sum, val_acc_sum = 0, 0\n",
    "                    for j, (batch, labels) in enumerate(val_loader):\n",
    "                        batch, labels = batch.to(device), labels.to(device)\n",
    "                        y_hat = model(batch)\n",
    "                        loss = criterion(y_hat, labels)\n",
    "                        val_loss_sum += loss.item()\n",
    "                        val_acc_sum += get_acc(y_hat.cpu().detach().numpy(), labels.cpu().detach().numpy())\n",
    "                    avg_val_loss = val_loss_sum/total_val_steps\n",
    "                    avg_val_acc = val_acc_sum/total_val_steps\n",
    "                    val_loss_list.append(avg_val_loss)\n",
    "                    val_acc_list.append(avg_val_acc)\n",
    "                    print('[Validation loss {}, validation acc {}] \\n'.format(avg_val_loss, avg_val_acc))\n",
    "    return model, train_loss_list, val_loss_list, train_acc_list, val_acc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = {'adam': torch.optim.Adam(hybrid_net.parameters(), lr=1e-3),\n",
    "              'rmsprop': torch.optim.RMSprop(hybrid_net.parameters(), lr=1e-3, weight_decay=1e-4)}\n",
    "config = {'epochs':200, 'device':device, \n",
    "          'opt': optimizers['adam'],\n",
    "          'criterion':nn.BCELoss(),\n",
    "          'batch_size': batch_size,\n",
    "          'log_interval':1}\n",
    "C, L = train_x[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 68016 samples, validate on 17016 samples\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-751e6ff3c37a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhybrid_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_loss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_acc_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhybrid_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-11-c54c845836ae>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_dataset, val_dataset, config)\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m             \u001b[0mtrain_loss_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m             \u001b[0mtrain_acc_sum\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mget_acc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_hat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mtac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hybrid_net, train_loss_list, val_loss_list, train_acc_list, val_acc_list = train(hybrid_net, train_dataset, val_dataset, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
