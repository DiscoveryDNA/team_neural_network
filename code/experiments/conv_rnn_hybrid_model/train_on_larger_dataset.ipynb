{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os, shutil, pickle, shelve\n",
    "from Bio import SeqIO\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import load_model, Model\n",
    "from keras.utils import plot_model\n",
    "from keras.models import Model, Sequential\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, MaxPooling1D, Flatten, Conv1D, LSTM, CuDNNLSTM, Bidirectional\n",
    "from keras.optimizers import RMSprop, Adam\n",
    "from keras.initializers import glorot_normal\n",
    "from utilities import sampling, one_hot_encoding, curtail, get_training_data, load_data, data_split, dianostic_plots, pad_for_detector\n",
    "from utilities import get_char_list, get_freqs, get_candidates, get_motif\n",
    "import keras\n",
    "import utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3543"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Subset sampling: save to me_samples; \"me\" for \"mutually exclusive\"\n",
    "output_folder_path = \"../../../../temp/buffers/me_samples\"\n",
    "\n",
    "data_dir = \"/home/ubuntu/group_volume/team_neural_network/data/input/3.24_species_only\"\n",
    "\n",
    "len(os.listdir(data_dir)) # total number of regions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uncomment the following code chunk to resample training and validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "copied training samples to /home/ubuntu/data/temp/train/\n",
      "copied validation samples to /home/ubuntu/data/temp/val/\n",
      "save to ../../../../temp/buffers/me_samples/train.data\n",
      "save to ../../../../temp/buffers/me_samples/val.data\n",
      "(68016, 1000, 4) (68016,)\n",
      "save to ../../../../temp/buffers/me_samples/train_x.data\n",
      "save to ../../../../temp/buffers/me_samples/train_y.data\n",
      "(17016, 1000, 4) (17016,)\n",
      "save to ../../../../temp/buffers/me_samples/val_x.data\n",
      "save to ../../../../temp/buffers/me_samples/val_y.data\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'pad_for_detector' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-8889bfe91816>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     43\u001b[0m                                    train_y_name = 'val_y.data')\n\u001b[1;32m     44\u001b[0m \u001b[0;31m# Pad for motif detectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_for_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpad_for_detector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'pad_for_detector' is not defined"
     ]
    }
   ],
   "source": [
    "# !rm -r /home/ubuntu/data/temp/train\n",
    "# !mkdir /home/ubuntu/data/temp/train\n",
    "# !rm -r /home/ubuntu/data/temp/val\n",
    "# !mkdir /home/ubuntu/data/temp/val\n",
    "\n",
    "# ###############################################################################\n",
    "# # Sample training and validation data\n",
    "# # IMPORTANT: Make sure that training and validation don't have intersection!!!\n",
    "# ###############################################################################\n",
    "# all_data_lst = np.array(os.listdir(data_dir))\n",
    "# n = len(all_data_lst)\n",
    "# num_trained_regions = int(n * 0.8)\n",
    "# train_files = all_data_lst[:num_trained_regions]\n",
    "# num_val = n - num_trained_regions\n",
    "# val_indices = np.random.choice(np.arange(num_trained_regions, n), num_val, replace = False)\n",
    "# val_files = all_data_lst[val_indices]\n",
    "\n",
    "# train_dest = '/home/ubuntu/data/temp/train/'\n",
    "# for file in train_files:\n",
    "#     shutil.copy(os.path.join(data_dir, file),\n",
    "#                           train_dest)\n",
    "# print('copied training samples to {}'.format(train_dest))\n",
    "\n",
    "# val_dest = '/home/ubuntu/data/temp/val/'\n",
    "# for file in val_files:\n",
    "#     shutil.copy(os.path.join(data_dir, file),\n",
    "#                           val_dest)\n",
    "# print('copied validation samples to {}'.format(val_dest))\n",
    "\n",
    "# # Preprocess train and val data so that they are ready to be fed to models\n",
    "# train_output_path = os.path.join(output_folder_path, 'train.data')\n",
    "# val_output_path = os.path.join(output_folder_path, 'val.data')\n",
    "\n",
    "# train_regions = one_hot_encoding(train_dest, train_output_path)\n",
    "# val_regions = one_hot_encoding(val_dest, val_output_path)\n",
    "# train_x, train_y = get_training_data(train_regions, output_folder_path,\n",
    "#                                    max_len = 1000, \n",
    "#                                    train_x_name = 'train_x.data', \n",
    "#                                    train_y_name = 'train_y.data')\n",
    "# val_x, val_y = get_training_data(val_regions, output_folder_path,\n",
    "#                                    max_len = 1000, \n",
    "#                                    train_x_name = 'val_x.data', \n",
    "#                                    train_y_name = 'val_y.data')\n",
    "# # Pad for motif detectors\n",
    "# train_x, val_x = pad_for_detector(train_x, 15), pad_for_detector(val_x, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_x = pickle.load(open('../../../../temp/buffers/ss_samples/train_x.data', 'rb'))\n",
    "# data_y = pickle.load(open('../../../../temp/buffers/ss_samples/train_y.data', 'rb'))\n",
    "# train_x, train_y, val_x, val_y = data_split(data_x, data_y, seed = 157)\n",
    "# train_x, val_x = pad_for_detector(train_x, 10), pad_for_detector(val_x, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = pickle.load(open(os.path.join(output_folder_path, 'train_x.data'), 'rb'))\n",
    "train_y = pickle.load(open(os.path.join(output_folder_path, 'train_y.data'), 'rb'))\n",
    "val_x = pickle.load(open(os.path.join(output_folder_path, 'val_x.data'), 'rb'))\n",
    "val_y = pickle.load(open(os.path.join(output_folder_path, 'val_y.data'), 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 15 # number of filters\n",
    "m = 10 # filter size\n",
    "train_x, val_x = pad_for_detector(train_x, m), pad_for_detector(val_x, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hybrid(opt, num_filters, kernel_size):\n",
    "    \"\"\"  Return a hybrid network given a optimizer\n",
    "    \"\"\"\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(filters = num_filters, \n",
    "                     kernel_size = kernel_size, \n",
    "                     padding = 'valid',\n",
    "                     data_format = 'channels_last',\n",
    "                     activation = 'relu'))\n",
    "    model.add(MaxPooling1D(pool_size = 5, strides = 5))\n",
    "    model.add(Dropout(0.6))\n",
    "    #model.add(Bidirectional(LSTM(20)))\n",
    "    model.add(Bidirectional(CuDNNLSTM(10)))\n",
    "    model.add(Dropout(0.7))\n",
    "    model.add(Dense(50, activation = keras.layers.LeakyReLU(alpha=0.3)))\n",
    "    model.add(Dense(20, activation = keras.layers.LeakyReLU(alpha=0.3)))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['acc'])\n",
    "    return model\n",
    "\n",
    "def train(model, train_x, train_y, val_data, config = {'epochs': 35, 'batch_size': 256}):\n",
    "    \"\"\"  Train model for a given config, training data, and validation data\n",
    "    \"\"\"\n",
    "    epochs, batch_size = config['epochs'], config['batch_size']\n",
    "    return model.fit(train_x, train_y, epochs=epochs, batch_size=batch_size, validation_data=val_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/keras/activations.py:211: UserWarning: Do not pass a layer instance (such as LeakyReLU) as the activation argument of another layer. Instead, advanced activation layers should be used just like any other layer in a model.\n",
      "  identifier=identifier.__class__.__name__))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 68016 samples, validate on 17016 samples\n",
      "Epoch 1/500\n",
      "68016/68016 [==============================] - 10s 154us/step - loss: 0.6808 - acc: 0.5492 - val_loss: 0.6804 - val_acc: 0.5275\n",
      "Epoch 2/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6763 - acc: 0.5521 - val_loss: 0.6786 - val_acc: 0.5275\n",
      "Epoch 3/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6752 - acc: 0.5526 - val_loss: 0.6765 - val_acc: 0.5433\n",
      "Epoch 4/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6735 - acc: 0.5555 - val_loss: 0.6834 - val_acc: 0.5275\n",
      "Epoch 5/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6719 - acc: 0.5624 - val_loss: 0.6771 - val_acc: 0.5440\n",
      "Epoch 6/500\n",
      "68016/68016 [==============================] - 9s 130us/step - loss: 0.6713 - acc: 0.5614 - val_loss: 0.6787 - val_acc: 0.5356\n",
      "Epoch 7/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6695 - acc: 0.5676 - val_loss: 0.6789 - val_acc: 0.5424\n",
      "Epoch 8/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6684 - acc: 0.5696 - val_loss: 0.6784 - val_acc: 0.5514\n",
      "Epoch 9/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6689 - acc: 0.5701 - val_loss: 0.6772 - val_acc: 0.5539\n",
      "Epoch 10/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6677 - acc: 0.5724 - val_loss: 0.6769 - val_acc: 0.5551\n",
      "Epoch 11/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6666 - acc: 0.5753 - val_loss: 0.6784 - val_acc: 0.5562\n",
      "Epoch 12/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6668 - acc: 0.5748 - val_loss: 0.6785 - val_acc: 0.5530\n",
      "Epoch 13/500\n",
      "68016/68016 [==============================] - 9s 130us/step - loss: 0.6662 - acc: 0.5778 - val_loss: 0.6790 - val_acc: 0.5579\n",
      "Epoch 14/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6666 - acc: 0.5762 - val_loss: 0.6813 - val_acc: 0.5401\n",
      "Epoch 15/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6651 - acc: 0.5793 - val_loss: 0.6778 - val_acc: 0.5585\n",
      "Epoch 16/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6660 - acc: 0.5801 - val_loss: 0.6784 - val_acc: 0.5562\n",
      "Epoch 17/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6646 - acc: 0.5825 - val_loss: 0.6801 - val_acc: 0.5588\n",
      "Epoch 18/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6651 - acc: 0.5795 - val_loss: 0.6780 - val_acc: 0.5600\n",
      "Epoch 19/500\n",
      "68016/68016 [==============================] - 9s 130us/step - loss: 0.6644 - acc: 0.5818 - val_loss: 0.6819 - val_acc: 0.5544\n",
      "Epoch 20/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6642 - acc: 0.5836 - val_loss: 0.6794 - val_acc: 0.5551\n",
      "Epoch 21/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6636 - acc: 0.5850 - val_loss: 0.6794 - val_acc: 0.5578\n",
      "Epoch 22/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6641 - acc: 0.5826 - val_loss: 0.6799 - val_acc: 0.5569\n",
      "Epoch 23/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6642 - acc: 0.5818 - val_loss: 0.6810 - val_acc: 0.5505\n",
      "Epoch 24/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6647 - acc: 0.5811 - val_loss: 0.6807 - val_acc: 0.5516\n",
      "Epoch 25/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6643 - acc: 0.5848 - val_loss: 0.6803 - val_acc: 0.5559\n",
      "Epoch 26/500\n",
      "68016/68016 [==============================] - 9s 130us/step - loss: 0.6629 - acc: 0.5863 - val_loss: 0.6802 - val_acc: 0.5531\n",
      "Epoch 27/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6637 - acc: 0.5818 - val_loss: 0.6800 - val_acc: 0.5517\n",
      "Epoch 28/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6631 - acc: 0.5854 - val_loss: 0.6807 - val_acc: 0.5582\n",
      "Epoch 29/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6636 - acc: 0.5841 - val_loss: 0.6808 - val_acc: 0.5546\n",
      "Epoch 30/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6628 - acc: 0.5879 - val_loss: 0.6805 - val_acc: 0.5551\n",
      "Epoch 31/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6630 - acc: 0.5845 - val_loss: 0.6801 - val_acc: 0.5551\n",
      "Epoch 32/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6625 - acc: 0.5865 - val_loss: 0.6810 - val_acc: 0.5574\n",
      "Epoch 33/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6625 - acc: 0.5883 - val_loss: 0.6809 - val_acc: 0.5568\n",
      "Epoch 34/500\n",
      "68016/68016 [==============================] - 9s 130us/step - loss: 0.6630 - acc: 0.5858 - val_loss: 0.6809 - val_acc: 0.5562\n",
      "Epoch 35/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6620 - acc: 0.5880 - val_loss: 0.6821 - val_acc: 0.5564\n",
      "Epoch 36/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6628 - acc: 0.5862 - val_loss: 0.6811 - val_acc: 0.5565\n",
      "Epoch 37/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6629 - acc: 0.5852 - val_loss: 0.6818 - val_acc: 0.5551\n",
      "Epoch 38/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6621 - acc: 0.5876 - val_loss: 0.6813 - val_acc: 0.5558\n",
      "Epoch 39/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6618 - acc: 0.5894 - val_loss: 0.6818 - val_acc: 0.5528\n",
      "Epoch 40/500\n",
      "68016/68016 [==============================] - 9s 130us/step - loss: 0.6623 - acc: 0.5863 - val_loss: 0.6823 - val_acc: 0.5558\n",
      "Epoch 41/500\n",
      "68016/68016 [==============================] - 9s 130us/step - loss: 0.6631 - acc: 0.5839 - val_loss: 0.6821 - val_acc: 0.5571\n",
      "Epoch 42/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6622 - acc: 0.5859 - val_loss: 0.6817 - val_acc: 0.5542\n",
      "Epoch 43/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6612 - acc: 0.5898 - val_loss: 0.6822 - val_acc: 0.5494\n",
      "Epoch 44/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6611 - acc: 0.5910 - val_loss: 0.6816 - val_acc: 0.5518\n",
      "Epoch 45/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6620 - acc: 0.5893 - val_loss: 0.6826 - val_acc: 0.5469\n",
      "Epoch 46/500\n",
      "68016/68016 [==============================] - 9s 130us/step - loss: 0.6617 - acc: 0.5867 - val_loss: 0.6811 - val_acc: 0.5544\n",
      "Epoch 47/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6612 - acc: 0.5902 - val_loss: 0.6816 - val_acc: 0.5520\n",
      "Epoch 48/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6614 - acc: 0.5898 - val_loss: 0.6810 - val_acc: 0.5546\n",
      "Epoch 49/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6613 - acc: 0.5875 - val_loss: 0.6812 - val_acc: 0.5525\n",
      "Epoch 50/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6622 - acc: 0.5872 - val_loss: 0.6817 - val_acc: 0.5524\n",
      "Epoch 51/500\n",
      "68016/68016 [==============================] - 9s 130us/step - loss: 0.6612 - acc: 0.5893 - val_loss: 0.6821 - val_acc: 0.5557\n",
      "Epoch 52/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6609 - acc: 0.5892 - val_loss: 0.6822 - val_acc: 0.5518\n",
      "Epoch 53/500\n",
      "68016/68016 [==============================] - 9s 130us/step - loss: 0.6611 - acc: 0.5882 - val_loss: 0.6818 - val_acc: 0.5551\n",
      "Epoch 54/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6610 - acc: 0.5914 - val_loss: 0.6819 - val_acc: 0.5541\n",
      "Epoch 55/500\n",
      "68016/68016 [==============================] - 9s 130us/step - loss: 0.6617 - acc: 0.5889 - val_loss: 0.6829 - val_acc: 0.5441\n",
      "Epoch 56/500\n",
      "68016/68016 [==============================] - 9s 130us/step - loss: 0.6611 - acc: 0.5881 - val_loss: 0.6813 - val_acc: 0.5534\n",
      "Epoch 57/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6604 - acc: 0.5930 - val_loss: 0.6820 - val_acc: 0.5520\n",
      "Epoch 58/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6608 - acc: 0.5918 - val_loss: 0.6818 - val_acc: 0.5526\n",
      "Epoch 59/500\n",
      "68016/68016 [==============================] - 9s 130us/step - loss: 0.6616 - acc: 0.5897 - val_loss: 0.6826 - val_acc: 0.5437\n",
      "Epoch 60/500\n",
      "68016/68016 [==============================] - 9s 130us/step - loss: 0.6601 - acc: 0.5929 - val_loss: 0.6820 - val_acc: 0.5535\n",
      "Epoch 61/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6614 - acc: 0.5914 - val_loss: 0.6824 - val_acc: 0.5525\n",
      "Epoch 62/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6612 - acc: 0.5887 - val_loss: 0.6816 - val_acc: 0.5533\n",
      "Epoch 63/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6611 - acc: 0.5913 - val_loss: 0.6824 - val_acc: 0.5507\n",
      "Epoch 64/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6605 - acc: 0.5918 - val_loss: 0.6825 - val_acc: 0.5521\n",
      "Epoch 65/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6609 - acc: 0.5918 - val_loss: 0.6820 - val_acc: 0.5509\n",
      "Epoch 66/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6613 - acc: 0.5923 - val_loss: 0.6821 - val_acc: 0.5487\n",
      "Epoch 67/500\n",
      "68016/68016 [==============================] - 9s 130us/step - loss: 0.6602 - acc: 0.5889 - val_loss: 0.6813 - val_acc: 0.5538\n",
      "Epoch 68/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6599 - acc: 0.5932 - val_loss: 0.6828 - val_acc: 0.5488\n",
      "Epoch 69/500\n",
      "68016/68016 [==============================] - 9s 130us/step - loss: 0.6611 - acc: 0.5906 - val_loss: 0.6824 - val_acc: 0.5498\n",
      "Epoch 70/500\n",
      "68016/68016 [==============================] - 9s 132us/step - loss: 0.6600 - acc: 0.5931 - val_loss: 0.6822 - val_acc: 0.5528\n",
      "Epoch 71/500\n",
      "68016/68016 [==============================] - 9s 130us/step - loss: 0.6601 - acc: 0.5920 - val_loss: 0.6818 - val_acc: 0.5518\n",
      "Epoch 72/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6603 - acc: 0.5909 - val_loss: 0.6825 - val_acc: 0.5484\n",
      "Epoch 73/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6602 - acc: 0.5923 - val_loss: 0.6823 - val_acc: 0.5515\n",
      "Epoch 74/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6603 - acc: 0.5922 - val_loss: 0.6819 - val_acc: 0.5504\n",
      "Epoch 75/500\n",
      "68016/68016 [==============================] - 9s 130us/step - loss: 0.6611 - acc: 0.5912 - val_loss: 0.6822 - val_acc: 0.5525\n",
      "Epoch 76/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6602 - acc: 0.5928 - val_loss: 0.6822 - val_acc: 0.5521\n",
      "Epoch 77/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6601 - acc: 0.5924 - val_loss: 0.6828 - val_acc: 0.5465\n",
      "Epoch 78/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6606 - acc: 0.5934 - val_loss: 0.6829 - val_acc: 0.5482\n",
      "Epoch 79/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6599 - acc: 0.5917 - val_loss: 0.6821 - val_acc: 0.5522\n",
      "Epoch 80/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6609 - acc: 0.5930 - val_loss: 0.6824 - val_acc: 0.5494\n",
      "Epoch 81/500\n",
      "68016/68016 [==============================] - 9s 130us/step - loss: 0.6604 - acc: 0.5931 - val_loss: 0.6827 - val_acc: 0.5514\n",
      "Epoch 82/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6600 - acc: 0.5935 - val_loss: 0.6829 - val_acc: 0.5488\n",
      "Epoch 83/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6607 - acc: 0.5903 - val_loss: 0.6819 - val_acc: 0.5501\n",
      "Epoch 84/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6593 - acc: 0.5933 - val_loss: 0.6825 - val_acc: 0.5501\n",
      "Epoch 85/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6596 - acc: 0.5958 - val_loss: 0.6824 - val_acc: 0.5507\n",
      "Epoch 86/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6598 - acc: 0.5929 - val_loss: 0.6825 - val_acc: 0.5498\n",
      "Epoch 87/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6595 - acc: 0.5927 - val_loss: 0.6824 - val_acc: 0.5497\n",
      "Epoch 88/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6600 - acc: 0.5928 - val_loss: 0.6826 - val_acc: 0.5465\n",
      "Epoch 89/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6607 - acc: 0.5914 - val_loss: 0.6824 - val_acc: 0.5514\n",
      "Epoch 90/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6605 - acc: 0.5903 - val_loss: 0.6821 - val_acc: 0.5505\n",
      "Epoch 91/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6600 - acc: 0.5935 - val_loss: 0.6822 - val_acc: 0.5490\n",
      "Epoch 92/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6608 - acc: 0.5930 - val_loss: 0.6826 - val_acc: 0.5495\n",
      "Epoch 93/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6606 - acc: 0.5911 - val_loss: 0.6825 - val_acc: 0.5532\n",
      "Epoch 94/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6590 - acc: 0.5967 - val_loss: 0.6822 - val_acc: 0.5526\n",
      "Epoch 95/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6602 - acc: 0.5925 - val_loss: 0.6825 - val_acc: 0.5505\n",
      "Epoch 96/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6603 - acc: 0.5905 - val_loss: 0.6821 - val_acc: 0.5485\n",
      "Epoch 97/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6602 - acc: 0.5924 - val_loss: 0.6825 - val_acc: 0.5482\n",
      "Epoch 98/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6602 - acc: 0.5913 - val_loss: 0.6826 - val_acc: 0.5495\n",
      "Epoch 99/500\n",
      "68016/68016 [==============================] - 9s 130us/step - loss: 0.6592 - acc: 0.5946 - val_loss: 0.6830 - val_acc: 0.5498\n",
      "Epoch 100/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6603 - acc: 0.5910 - val_loss: 0.6828 - val_acc: 0.5494\n",
      "Epoch 101/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6603 - acc: 0.5910 - val_loss: 0.6822 - val_acc: 0.5495\n",
      "Epoch 102/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6602 - acc: 0.5891 - val_loss: 0.6827 - val_acc: 0.5497\n",
      "Epoch 103/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6593 - acc: 0.5939 - val_loss: 0.6827 - val_acc: 0.5494\n",
      "Epoch 104/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6599 - acc: 0.5908 - val_loss: 0.6827 - val_acc: 0.5498\n",
      "Epoch 105/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6605 - acc: 0.5922 - val_loss: 0.6826 - val_acc: 0.5496\n",
      "Epoch 106/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6594 - acc: 0.5927 - val_loss: 0.6829 - val_acc: 0.5469\n",
      "Epoch 107/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6591 - acc: 0.5945 - val_loss: 0.6822 - val_acc: 0.5506\n",
      "Epoch 108/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6596 - acc: 0.5926 - val_loss: 0.6824 - val_acc: 0.5505\n",
      "Epoch 109/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6593 - acc: 0.5944 - val_loss: 0.6830 - val_acc: 0.5498\n",
      "Epoch 110/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6603 - acc: 0.5928 - val_loss: 0.6833 - val_acc: 0.5460\n",
      "Epoch 111/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6605 - acc: 0.5928 - val_loss: 0.6833 - val_acc: 0.5470\n",
      "Epoch 112/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6600 - acc: 0.5927 - val_loss: 0.6827 - val_acc: 0.5488\n",
      "Epoch 113/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6599 - acc: 0.5958 - val_loss: 0.6826 - val_acc: 0.5518\n",
      "Epoch 114/500\n",
      "68016/68016 [==============================] - 9s 130us/step - loss: 0.6592 - acc: 0.5923 - val_loss: 0.6828 - val_acc: 0.5487\n",
      "Epoch 115/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6585 - acc: 0.5962 - val_loss: 0.6824 - val_acc: 0.5527\n",
      "Epoch 116/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6599 - acc: 0.5929 - val_loss: 0.6828 - val_acc: 0.5464\n",
      "Epoch 117/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6594 - acc: 0.5942 - val_loss: 0.6831 - val_acc: 0.5450\n",
      "Epoch 118/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6589 - acc: 0.5951 - val_loss: 0.6830 - val_acc: 0.5477\n",
      "Epoch 119/500\n",
      "68016/68016 [==============================] - 9s 130us/step - loss: 0.6593 - acc: 0.5936 - val_loss: 0.6835 - val_acc: 0.5453\n",
      "Epoch 120/500\n",
      "68016/68016 [==============================] - 9s 130us/step - loss: 0.6604 - acc: 0.5925 - val_loss: 0.6829 - val_acc: 0.5480\n",
      "Epoch 121/500\n",
      "68016/68016 [==============================] - 9s 130us/step - loss: 0.6594 - acc: 0.5943 - val_loss: 0.6830 - val_acc: 0.5501\n",
      "Epoch 122/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6590 - acc: 0.5965 - val_loss: 0.6829 - val_acc: 0.5500\n",
      "Epoch 123/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6595 - acc: 0.5920 - val_loss: 0.6827 - val_acc: 0.5507\n",
      "Epoch 124/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6593 - acc: 0.5953 - val_loss: 0.6827 - val_acc: 0.5504\n",
      "Epoch 125/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6588 - acc: 0.5943 - val_loss: 0.6835 - val_acc: 0.5478\n",
      "Epoch 126/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6584 - acc: 0.5959 - val_loss: 0.6835 - val_acc: 0.5496\n",
      "Epoch 127/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6590 - acc: 0.5941 - val_loss: 0.6836 - val_acc: 0.5479\n",
      "Epoch 128/500\n",
      "68016/68016 [==============================] - 9s 130us/step - loss: 0.6590 - acc: 0.5956 - val_loss: 0.6832 - val_acc: 0.5471\n",
      "Epoch 129/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6599 - acc: 0.5913 - val_loss: 0.6828 - val_acc: 0.5481\n",
      "Epoch 130/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6597 - acc: 0.5954 - val_loss: 0.6826 - val_acc: 0.5501\n",
      "Epoch 131/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6595 - acc: 0.5947 - val_loss: 0.6829 - val_acc: 0.5489\n",
      "Epoch 132/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6593 - acc: 0.5953 - val_loss: 0.6831 - val_acc: 0.5500\n",
      "Epoch 133/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6595 - acc: 0.5922 - val_loss: 0.6831 - val_acc: 0.5489\n",
      "Epoch 134/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6594 - acc: 0.5934 - val_loss: 0.6829 - val_acc: 0.5501\n",
      "Epoch 135/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6589 - acc: 0.5955 - val_loss: 0.6833 - val_acc: 0.5507\n",
      "Epoch 136/500\n",
      "68016/68016 [==============================] - 9s 130us/step - loss: 0.6589 - acc: 0.5947 - val_loss: 0.6831 - val_acc: 0.5501\n",
      "Epoch 137/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6589 - acc: 0.5954 - val_loss: 0.6830 - val_acc: 0.5511\n",
      "Epoch 138/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6590 - acc: 0.5957 - val_loss: 0.6834 - val_acc: 0.5489\n",
      "Epoch 139/500\n",
      "68016/68016 [==============================] - 9s 130us/step - loss: 0.6576 - acc: 0.5983 - val_loss: 0.6841 - val_acc: 0.5470\n",
      "Epoch 140/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6579 - acc: 0.5971 - val_loss: 0.6835 - val_acc: 0.5556\n",
      "Epoch 141/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6595 - acc: 0.5931 - val_loss: 0.6835 - val_acc: 0.5494\n",
      "Epoch 142/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6586 - acc: 0.5962 - val_loss: 0.6835 - val_acc: 0.5490\n",
      "Epoch 143/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6600 - acc: 0.5935 - val_loss: 0.6832 - val_acc: 0.5445\n",
      "Epoch 144/500\n",
      "68016/68016 [==============================] - 9s 130us/step - loss: 0.6598 - acc: 0.5924 - val_loss: 0.6835 - val_acc: 0.5427\n",
      "Epoch 145/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6587 - acc: 0.5956 - val_loss: 0.6829 - val_acc: 0.5476\n",
      "Epoch 146/500\n",
      "68016/68016 [==============================] - 9s 130us/step - loss: 0.6592 - acc: 0.5938 - val_loss: 0.6829 - val_acc: 0.5507\n",
      "Epoch 147/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6592 - acc: 0.5945 - val_loss: 0.6831 - val_acc: 0.5533\n",
      "Epoch 148/500\n",
      "68016/68016 [==============================] - 9s 130us/step - loss: 0.6592 - acc: 0.5933 - val_loss: 0.6834 - val_acc: 0.5459\n",
      "Epoch 149/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6586 - acc: 0.5939 - val_loss: 0.6832 - val_acc: 0.5489\n",
      "Epoch 150/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6587 - acc: 0.5958 - val_loss: 0.6832 - val_acc: 0.5495\n",
      "Epoch 151/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6583 - acc: 0.5956 - val_loss: 0.6834 - val_acc: 0.5487\n",
      "Epoch 152/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6595 - acc: 0.5953 - val_loss: 0.6831 - val_acc: 0.5467\n",
      "Epoch 153/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6582 - acc: 0.5945 - val_loss: 0.6829 - val_acc: 0.5510\n",
      "Epoch 154/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6580 - acc: 0.5981 - val_loss: 0.6832 - val_acc: 0.5436\n",
      "Epoch 155/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6586 - acc: 0.5954 - val_loss: 0.6836 - val_acc: 0.5484\n",
      "Epoch 156/500\n",
      "68016/68016 [==============================] - 9s 130us/step - loss: 0.6591 - acc: 0.5933 - val_loss: 0.6834 - val_acc: 0.5488\n",
      "Epoch 157/500\n",
      "68016/68016 [==============================] - 9s 130us/step - loss: 0.6593 - acc: 0.5953 - val_loss: 0.6834 - val_acc: 0.5472\n",
      "Epoch 158/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6580 - acc: 0.5985 - val_loss: 0.6833 - val_acc: 0.5492\n",
      "Epoch 159/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6591 - acc: 0.5944 - val_loss: 0.6831 - val_acc: 0.5476\n",
      "Epoch 160/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6598 - acc: 0.5931 - val_loss: 0.6832 - val_acc: 0.5496\n",
      "Epoch 161/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6594 - acc: 0.5945 - val_loss: 0.6834 - val_acc: 0.5492\n",
      "Epoch 162/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6592 - acc: 0.5923 - val_loss: 0.6838 - val_acc: 0.5447\n",
      "Epoch 163/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6591 - acc: 0.5957 - val_loss: 0.6831 - val_acc: 0.5488\n",
      "Epoch 164/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6589 - acc: 0.5954 - val_loss: 0.6834 - val_acc: 0.5454\n",
      "Epoch 165/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6583 - acc: 0.5976 - val_loss: 0.6833 - val_acc: 0.5481\n",
      "Epoch 166/500\n",
      "68016/68016 [==============================] - 9s 130us/step - loss: 0.6589 - acc: 0.5960 - val_loss: 0.6833 - val_acc: 0.5490\n",
      "Epoch 167/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6580 - acc: 0.5972 - val_loss: 0.6829 - val_acc: 0.5507\n",
      "Epoch 168/500\n",
      "68016/68016 [==============================] - 9s 130us/step - loss: 0.6585 - acc: 0.5977 - val_loss: 0.6837 - val_acc: 0.5429\n",
      "Epoch 169/500\n",
      "68016/68016 [==============================] - 9s 130us/step - loss: 0.6590 - acc: 0.5966 - val_loss: 0.6837 - val_acc: 0.5457\n",
      "Epoch 170/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6587 - acc: 0.5938 - val_loss: 0.6836 - val_acc: 0.5462\n",
      "Epoch 171/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6580 - acc: 0.5980 - val_loss: 0.6829 - val_acc: 0.5504\n",
      "Epoch 172/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6588 - acc: 0.5930 - val_loss: 0.6834 - val_acc: 0.5435\n",
      "Epoch 173/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6582 - acc: 0.5958 - val_loss: 0.6839 - val_acc: 0.5433\n",
      "Epoch 174/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6593 - acc: 0.5947 - val_loss: 0.6837 - val_acc: 0.5441\n",
      "Epoch 175/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6585 - acc: 0.5950 - val_loss: 0.6832 - val_acc: 0.5476\n",
      "Epoch 176/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6592 - acc: 0.5954 - val_loss: 0.6836 - val_acc: 0.5428\n",
      "Epoch 177/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6590 - acc: 0.5936 - val_loss: 0.6836 - val_acc: 0.5444\n",
      "Epoch 178/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6584 - acc: 0.5949 - val_loss: 0.6834 - val_acc: 0.5440\n",
      "Epoch 179/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6592 - acc: 0.5953 - val_loss: 0.6833 - val_acc: 0.5425\n",
      "Epoch 180/500\n",
      "68016/68016 [==============================] - 9s 130us/step - loss: 0.6588 - acc: 0.5961 - val_loss: 0.6833 - val_acc: 0.5453\n",
      "Epoch 181/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6584 - acc: 0.5949 - val_loss: 0.6836 - val_acc: 0.5431\n",
      "Epoch 182/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6579 - acc: 0.5966 - val_loss: 0.6835 - val_acc: 0.5430\n",
      "Epoch 183/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6586 - acc: 0.5957 - val_loss: 0.6836 - val_acc: 0.5450\n",
      "Epoch 184/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6589 - acc: 0.5951 - val_loss: 0.6837 - val_acc: 0.5434\n",
      "Epoch 185/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6586 - acc: 0.5971 - val_loss: 0.6832 - val_acc: 0.5495\n",
      "Epoch 186/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6585 - acc: 0.5943 - val_loss: 0.6835 - val_acc: 0.5501\n",
      "Epoch 187/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6587 - acc: 0.5957 - val_loss: 0.6836 - val_acc: 0.5430\n",
      "Epoch 188/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6584 - acc: 0.5952 - val_loss: 0.6837 - val_acc: 0.5448\n",
      "Epoch 189/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6590 - acc: 0.5948 - val_loss: 0.6837 - val_acc: 0.5454\n",
      "Epoch 190/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6589 - acc: 0.5947 - val_loss: 0.6837 - val_acc: 0.5472\n",
      "Epoch 191/500\n",
      "68016/68016 [==============================] - 9s 130us/step - loss: 0.6584 - acc: 0.5955 - val_loss: 0.6837 - val_acc: 0.5475\n",
      "Epoch 192/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6582 - acc: 0.5994 - val_loss: 0.6841 - val_acc: 0.5430\n",
      "Epoch 193/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6583 - acc: 0.5953 - val_loss: 0.6837 - val_acc: 0.5428\n",
      "Epoch 194/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6596 - acc: 0.5950 - val_loss: 0.6832 - val_acc: 0.5460\n",
      "Epoch 195/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6586 - acc: 0.5970 - val_loss: 0.6832 - val_acc: 0.5448\n",
      "Epoch 196/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6587 - acc: 0.5941 - val_loss: 0.6840 - val_acc: 0.5427\n",
      "Epoch 197/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6582 - acc: 0.5977 - val_loss: 0.6840 - val_acc: 0.5427\n",
      "Epoch 198/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6594 - acc: 0.5943 - val_loss: 0.6836 - val_acc: 0.5471\n",
      "Epoch 199/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6585 - acc: 0.5963 - val_loss: 0.6840 - val_acc: 0.5432\n",
      "Epoch 200/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6575 - acc: 0.5959 - val_loss: 0.6836 - val_acc: 0.5485\n",
      "Epoch 201/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6585 - acc: 0.5955 - val_loss: 0.6835 - val_acc: 0.5497\n",
      "Epoch 202/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6582 - acc: 0.5981 - val_loss: 0.6840 - val_acc: 0.5433\n",
      "Epoch 203/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6585 - acc: 0.5963 - val_loss: 0.6833 - val_acc: 0.5480\n",
      "Epoch 204/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6576 - acc: 0.5972 - val_loss: 0.6837 - val_acc: 0.5444\n",
      "Epoch 205/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6583 - acc: 0.5977 - val_loss: 0.6841 - val_acc: 0.5452\n",
      "Epoch 206/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6590 - acc: 0.5953 - val_loss: 0.6837 - val_acc: 0.5471\n",
      "Epoch 207/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6585 - acc: 0.5943 - val_loss: 0.6842 - val_acc: 0.5434\n",
      "Epoch 208/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6586 - acc: 0.5979 - val_loss: 0.6841 - val_acc: 0.5434\n",
      "Epoch 209/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6581 - acc: 0.5962 - val_loss: 0.6841 - val_acc: 0.5438\n",
      "Epoch 210/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6590 - acc: 0.5962 - val_loss: 0.6835 - val_acc: 0.5504\n",
      "Epoch 211/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6583 - acc: 0.5970 - val_loss: 0.6838 - val_acc: 0.5430\n",
      "Epoch 212/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6585 - acc: 0.5938 - val_loss: 0.6835 - val_acc: 0.5492\n",
      "Epoch 213/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6583 - acc: 0.5968 - val_loss: 0.6835 - val_acc: 0.5488\n",
      "Epoch 214/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6583 - acc: 0.5966 - val_loss: 0.6837 - val_acc: 0.5447\n",
      "Epoch 215/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6583 - acc: 0.5967 - val_loss: 0.6837 - val_acc: 0.5485\n",
      "Epoch 216/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6591 - acc: 0.5974 - val_loss: 0.6837 - val_acc: 0.5438\n",
      "Epoch 217/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6592 - acc: 0.5944 - val_loss: 0.6836 - val_acc: 0.5447\n",
      "Epoch 218/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6579 - acc: 0.5950 - val_loss: 0.6835 - val_acc: 0.5441\n",
      "Epoch 219/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6580 - acc: 0.5963 - val_loss: 0.6837 - val_acc: 0.5433\n",
      "Epoch 220/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6594 - acc: 0.5938 - val_loss: 0.6834 - val_acc: 0.5485\n",
      "Epoch 221/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6581 - acc: 0.5948 - val_loss: 0.6837 - val_acc: 0.5470\n",
      "Epoch 222/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6581 - acc: 0.5971 - val_loss: 0.6837 - val_acc: 0.5443\n",
      "Epoch 223/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6585 - acc: 0.5963 - val_loss: 0.6836 - val_acc: 0.5440\n",
      "Epoch 224/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6580 - acc: 0.5969 - val_loss: 0.6841 - val_acc: 0.5431\n",
      "Epoch 225/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6593 - acc: 0.5948 - val_loss: 0.6835 - val_acc: 0.5492\n",
      "Epoch 226/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6577 - acc: 0.5987 - val_loss: 0.6838 - val_acc: 0.5435\n",
      "Epoch 227/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6577 - acc: 0.5963 - val_loss: 0.6838 - val_acc: 0.5453\n",
      "Epoch 228/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6585 - acc: 0.5941 - val_loss: 0.6841 - val_acc: 0.5446\n",
      "Epoch 229/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6572 - acc: 0.5996 - val_loss: 0.6843 - val_acc: 0.5465\n",
      "Epoch 230/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6575 - acc: 0.5975 - val_loss: 0.6845 - val_acc: 0.5431\n",
      "Epoch 231/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6575 - acc: 0.5980 - val_loss: 0.6841 - val_acc: 0.5445\n",
      "Epoch 232/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6581 - acc: 0.5970 - val_loss: 0.6840 - val_acc: 0.5453\n",
      "Epoch 233/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6586 - acc: 0.5956 - val_loss: 0.6840 - val_acc: 0.5482\n",
      "Epoch 234/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6586 - acc: 0.5945 - val_loss: 0.6843 - val_acc: 0.5434\n",
      "Epoch 235/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6579 - acc: 0.5975 - val_loss: 0.6843 - val_acc: 0.5427\n",
      "Epoch 236/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6574 - acc: 0.5976 - val_loss: 0.6840 - val_acc: 0.5467\n",
      "Epoch 237/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6584 - acc: 0.5971 - val_loss: 0.6838 - val_acc: 0.5494\n",
      "Epoch 238/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6580 - acc: 0.5963 - val_loss: 0.6841 - val_acc: 0.5453\n",
      "Epoch 239/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6578 - acc: 0.5960 - val_loss: 0.6839 - val_acc: 0.5507\n",
      "Epoch 240/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6581 - acc: 0.5955 - val_loss: 0.6838 - val_acc: 0.5440\n",
      "Epoch 241/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6576 - acc: 0.5987 - val_loss: 0.6843 - val_acc: 0.5442\n",
      "Epoch 242/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6567 - acc: 0.5989 - val_loss: 0.6842 - val_acc: 0.5447\n",
      "Epoch 243/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6581 - acc: 0.5948 - val_loss: 0.6840 - val_acc: 0.5437\n",
      "Epoch 244/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6593 - acc: 0.5930 - val_loss: 0.6835 - val_acc: 0.5494\n",
      "Epoch 245/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6568 - acc: 0.5961 - val_loss: 0.6841 - val_acc: 0.5448\n",
      "Epoch 246/500\n",
      "68016/68016 [==============================] - 9s 132us/step - loss: 0.6584 - acc: 0.5956 - val_loss: 0.6842 - val_acc: 0.5446\n",
      "Epoch 247/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6582 - acc: 0.5929 - val_loss: 0.6840 - val_acc: 0.5477\n",
      "Epoch 248/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6585 - acc: 0.5949 - val_loss: 0.6837 - val_acc: 0.5481\n",
      "Epoch 249/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6578 - acc: 0.5970 - val_loss: 0.6836 - val_acc: 0.5492\n",
      "Epoch 250/500\n",
      "68016/68016 [==============================] - 9s 130us/step - loss: 0.6581 - acc: 0.5962 - val_loss: 0.6839 - val_acc: 0.5454\n",
      "Epoch 251/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6588 - acc: 0.5969 - val_loss: 0.6839 - val_acc: 0.5471\n",
      "Epoch 252/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6578 - acc: 0.5962 - val_loss: 0.6842 - val_acc: 0.5421\n",
      "Epoch 253/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6579 - acc: 0.5955 - val_loss: 0.6837 - val_acc: 0.5491\n",
      "Epoch 254/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6584 - acc: 0.5977 - val_loss: 0.6842 - val_acc: 0.5421\n",
      "Epoch 255/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6576 - acc: 0.5978 - val_loss: 0.6835 - val_acc: 0.5502\n",
      "Epoch 256/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6575 - acc: 0.5970 - val_loss: 0.6842 - val_acc: 0.5434\n",
      "Epoch 257/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6582 - acc: 0.5965 - val_loss: 0.6840 - val_acc: 0.5442\n",
      "Epoch 258/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6580 - acc: 0.5948 - val_loss: 0.6839 - val_acc: 0.5490\n",
      "Epoch 259/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6579 - acc: 0.5995 - val_loss: 0.6838 - val_acc: 0.5470\n",
      "Epoch 260/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6587 - acc: 0.5961 - val_loss: 0.6841 - val_acc: 0.5482\n",
      "Epoch 261/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6575 - acc: 0.5991 - val_loss: 0.6841 - val_acc: 0.5475\n",
      "Epoch 262/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6590 - acc: 0.5952 - val_loss: 0.6840 - val_acc: 0.5472\n",
      "Epoch 263/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6582 - acc: 0.5972 - val_loss: 0.6841 - val_acc: 0.5477\n",
      "Epoch 264/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6585 - acc: 0.5957 - val_loss: 0.6843 - val_acc: 0.5428\n",
      "Epoch 265/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6589 - acc: 0.5962 - val_loss: 0.6842 - val_acc: 0.5445\n",
      "Epoch 266/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6572 - acc: 0.5967 - val_loss: 0.6840 - val_acc: 0.5457\n",
      "Epoch 267/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6577 - acc: 0.5970 - val_loss: 0.6839 - val_acc: 0.5481\n",
      "Epoch 268/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6575 - acc: 0.5971 - val_loss: 0.6840 - val_acc: 0.5444\n",
      "Epoch 269/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6580 - acc: 0.5960 - val_loss: 0.6840 - val_acc: 0.5460\n",
      "Epoch 270/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6574 - acc: 0.5960 - val_loss: 0.6839 - val_acc: 0.5466\n",
      "Epoch 271/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6577 - acc: 0.5976 - val_loss: 0.6838 - val_acc: 0.5481\n",
      "Epoch 272/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6577 - acc: 0.5967 - val_loss: 0.6839 - val_acc: 0.5487\n",
      "Epoch 273/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6584 - acc: 0.5958 - val_loss: 0.6842 - val_acc: 0.5451\n",
      "Epoch 274/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6587 - acc: 0.5974 - val_loss: 0.6842 - val_acc: 0.5428\n",
      "Epoch 275/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6575 - acc: 0.5992 - val_loss: 0.6846 - val_acc: 0.5428\n",
      "Epoch 276/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6586 - acc: 0.5963 - val_loss: 0.6839 - val_acc: 0.5462\n",
      "Epoch 277/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6576 - acc: 0.5985 - val_loss: 0.6844 - val_acc: 0.5427\n",
      "Epoch 278/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6578 - acc: 0.5966 - val_loss: 0.6843 - val_acc: 0.5421\n",
      "Epoch 279/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6578 - acc: 0.5986 - val_loss: 0.6842 - val_acc: 0.5461\n",
      "Epoch 280/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6573 - acc: 0.5998 - val_loss: 0.6842 - val_acc: 0.5466\n",
      "Epoch 281/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6589 - acc: 0.5954 - val_loss: 0.6842 - val_acc: 0.5464\n",
      "Epoch 282/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6580 - acc: 0.5976 - val_loss: 0.6840 - val_acc: 0.5484\n",
      "Epoch 283/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6573 - acc: 0.5985 - val_loss: 0.6844 - val_acc: 0.5425\n",
      "Epoch 284/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6589 - acc: 0.5952 - val_loss: 0.6841 - val_acc: 0.5458\n",
      "Epoch 285/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6576 - acc: 0.5966 - val_loss: 0.6842 - val_acc: 0.5490\n",
      "Epoch 286/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6579 - acc: 0.5952 - val_loss: 0.6843 - val_acc: 0.5428\n",
      "Epoch 287/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6580 - acc: 0.5960 - val_loss: 0.6841 - val_acc: 0.5461\n",
      "Epoch 288/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6570 - acc: 0.5989 - val_loss: 0.6844 - val_acc: 0.5438\n",
      "Epoch 289/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6572 - acc: 0.5972 - val_loss: 0.6840 - val_acc: 0.5491\n",
      "Epoch 290/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6581 - acc: 0.5967 - val_loss: 0.6840 - val_acc: 0.5501\n",
      "Epoch 291/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6584 - acc: 0.5952 - val_loss: 0.6843 - val_acc: 0.5461\n",
      "Epoch 292/500\n",
      "68016/68016 [==============================] - 9s 132us/step - loss: 0.6588 - acc: 0.5943 - val_loss: 0.6839 - val_acc: 0.5478\n",
      "Epoch 293/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6573 - acc: 0.5984 - val_loss: 0.6844 - val_acc: 0.5438\n",
      "Epoch 294/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6570 - acc: 0.5987 - val_loss: 0.6847 - val_acc: 0.5418\n",
      "Epoch 295/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6573 - acc: 0.5977 - val_loss: 0.6844 - val_acc: 0.5444\n",
      "Epoch 296/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6567 - acc: 0.5969 - val_loss: 0.6846 - val_acc: 0.5431\n",
      "Epoch 297/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6583 - acc: 0.5951 - val_loss: 0.6843 - val_acc: 0.5445\n",
      "Epoch 298/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6578 - acc: 0.5965 - val_loss: 0.6842 - val_acc: 0.5467\n",
      "Epoch 299/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6576 - acc: 0.5971 - val_loss: 0.6840 - val_acc: 0.5475\n",
      "Epoch 300/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6574 - acc: 0.5983 - val_loss: 0.6844 - val_acc: 0.5453\n",
      "Epoch 301/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6571 - acc: 0.5971 - val_loss: 0.6845 - val_acc: 0.5447\n",
      "Epoch 302/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6590 - acc: 0.5930 - val_loss: 0.6843 - val_acc: 0.5458\n",
      "Epoch 303/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6564 - acc: 0.5991 - val_loss: 0.6845 - val_acc: 0.5434\n",
      "Epoch 304/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6589 - acc: 0.5950 - val_loss: 0.6842 - val_acc: 0.5457\n",
      "Epoch 305/500\n",
      "68016/68016 [==============================] - 9s 132us/step - loss: 0.6581 - acc: 0.5963 - val_loss: 0.6843 - val_acc: 0.5444\n",
      "Epoch 306/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6571 - acc: 0.5978 - val_loss: 0.6844 - val_acc: 0.5467\n",
      "Epoch 307/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6574 - acc: 0.5984 - val_loss: 0.6842 - val_acc: 0.5464\n",
      "Epoch 308/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6574 - acc: 0.5955 - val_loss: 0.6841 - val_acc: 0.5480\n",
      "Epoch 309/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6570 - acc: 0.5983 - val_loss: 0.6843 - val_acc: 0.5514\n",
      "Epoch 310/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6580 - acc: 0.5962 - val_loss: 0.6846 - val_acc: 0.5463\n",
      "Epoch 311/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6576 - acc: 0.5982 - val_loss: 0.6847 - val_acc: 0.5448\n",
      "Epoch 312/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6577 - acc: 0.5956 - val_loss: 0.6845 - val_acc: 0.5461\n",
      "Epoch 313/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6579 - acc: 0.5966 - val_loss: 0.6843 - val_acc: 0.5458\n",
      "Epoch 314/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6580 - acc: 0.5960 - val_loss: 0.6846 - val_acc: 0.5441\n",
      "Epoch 315/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6569 - acc: 0.5974 - val_loss: 0.6845 - val_acc: 0.5442\n",
      "Epoch 316/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6584 - acc: 0.5948 - val_loss: 0.6846 - val_acc: 0.5455\n",
      "Epoch 317/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6575 - acc: 0.5991 - val_loss: 0.6846 - val_acc: 0.5422\n",
      "Epoch 318/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6585 - acc: 0.5959 - val_loss: 0.6845 - val_acc: 0.5448\n",
      "Epoch 319/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6583 - acc: 0.5974 - val_loss: 0.6847 - val_acc: 0.5420\n",
      "Epoch 320/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6579 - acc: 0.5961 - val_loss: 0.6842 - val_acc: 0.5462\n",
      "Epoch 321/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6569 - acc: 0.6001 - val_loss: 0.6845 - val_acc: 0.5434\n",
      "Epoch 322/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6583 - acc: 0.5960 - val_loss: 0.6843 - val_acc: 0.5461\n",
      "Epoch 323/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6580 - acc: 0.5952 - val_loss: 0.6843 - val_acc: 0.5455\n",
      "Epoch 324/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6577 - acc: 0.5968 - val_loss: 0.6843 - val_acc: 0.5449\n",
      "Epoch 325/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6576 - acc: 0.5964 - val_loss: 0.6843 - val_acc: 0.5457\n",
      "Epoch 326/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6583 - acc: 0.5979 - val_loss: 0.6843 - val_acc: 0.5458\n",
      "Epoch 327/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6571 - acc: 0.5974 - val_loss: 0.6845 - val_acc: 0.5454\n",
      "Epoch 328/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6569 - acc: 0.5974 - val_loss: 0.6846 - val_acc: 0.5431\n",
      "Epoch 329/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6560 - acc: 0.5993 - val_loss: 0.6845 - val_acc: 0.5462\n",
      "Epoch 330/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6571 - acc: 0.5965 - val_loss: 0.6848 - val_acc: 0.5425\n",
      "Epoch 331/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6574 - acc: 0.5984 - val_loss: 0.6844 - val_acc: 0.5465\n",
      "Epoch 332/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6579 - acc: 0.5978 - val_loss: 0.6850 - val_acc: 0.5414\n",
      "Epoch 333/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6586 - acc: 0.5950 - val_loss: 0.6848 - val_acc: 0.5410\n",
      "Epoch 334/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6572 - acc: 0.5991 - val_loss: 0.6844 - val_acc: 0.5456\n",
      "Epoch 335/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6577 - acc: 0.5982 - val_loss: 0.6843 - val_acc: 0.5464\n",
      "Epoch 336/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6575 - acc: 0.5964 - val_loss: 0.6845 - val_acc: 0.5447\n",
      "Epoch 337/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6562 - acc: 0.5995 - val_loss: 0.6845 - val_acc: 0.5469\n",
      "Epoch 338/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6574 - acc: 0.5973 - val_loss: 0.6847 - val_acc: 0.5437\n",
      "Epoch 339/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6571 - acc: 0.5981 - val_loss: 0.6845 - val_acc: 0.5464\n",
      "Epoch 340/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6572 - acc: 0.5977 - val_loss: 0.6846 - val_acc: 0.5434\n",
      "Epoch 341/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6575 - acc: 0.5979 - val_loss: 0.6845 - val_acc: 0.5467\n",
      "Epoch 342/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6577 - acc: 0.5978 - val_loss: 0.6850 - val_acc: 0.5440\n",
      "Epoch 343/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6568 - acc: 0.5987 - val_loss: 0.6851 - val_acc: 0.5427\n",
      "Epoch 344/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6578 - acc: 0.5980 - val_loss: 0.6848 - val_acc: 0.5460\n",
      "Epoch 345/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6566 - acc: 0.5977 - val_loss: 0.6850 - val_acc: 0.5430\n",
      "Epoch 346/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6581 - acc: 0.5974 - val_loss: 0.6848 - val_acc: 0.5447\n",
      "Epoch 347/500\n",
      "68016/68016 [==============================] - 9s 132us/step - loss: 0.6580 - acc: 0.5958 - val_loss: 0.6848 - val_acc: 0.5463\n",
      "Epoch 348/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6577 - acc: 0.5962 - val_loss: 0.6849 - val_acc: 0.5455\n",
      "Epoch 349/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6580 - acc: 0.5974 - val_loss: 0.6850 - val_acc: 0.5443\n",
      "Epoch 350/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6569 - acc: 0.5982 - val_loss: 0.6849 - val_acc: 0.5445\n",
      "Epoch 351/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6567 - acc: 0.5986 - val_loss: 0.6849 - val_acc: 0.5455\n",
      "Epoch 352/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6572 - acc: 0.5969 - val_loss: 0.6847 - val_acc: 0.5457\n",
      "Epoch 353/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6574 - acc: 0.5968 - val_loss: 0.6849 - val_acc: 0.5447\n",
      "Epoch 354/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6571 - acc: 0.5968 - val_loss: 0.6848 - val_acc: 0.5448\n",
      "Epoch 355/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6574 - acc: 0.5979 - val_loss: 0.6846 - val_acc: 0.5463\n",
      "Epoch 356/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6581 - acc: 0.5979 - val_loss: 0.6848 - val_acc: 0.5443\n",
      "Epoch 357/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6584 - acc: 0.5965 - val_loss: 0.6846 - val_acc: 0.5461\n",
      "Epoch 358/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6569 - acc: 0.6013 - val_loss: 0.6846 - val_acc: 0.5451\n",
      "Epoch 359/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6578 - acc: 0.5968 - val_loss: 0.6845 - val_acc: 0.5456\n",
      "Epoch 360/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6575 - acc: 0.5967 - val_loss: 0.6845 - val_acc: 0.5443\n",
      "Epoch 361/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6572 - acc: 0.5969 - val_loss: 0.6846 - val_acc: 0.5457\n",
      "Epoch 362/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6569 - acc: 0.6000 - val_loss: 0.6846 - val_acc: 0.5440\n",
      "Epoch 363/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6571 - acc: 0.5985 - val_loss: 0.6848 - val_acc: 0.5440\n",
      "Epoch 364/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6571 - acc: 0.5993 - val_loss: 0.6848 - val_acc: 0.5450\n",
      "Epoch 365/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6578 - acc: 0.5962 - val_loss: 0.6846 - val_acc: 0.5474\n",
      "Epoch 366/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6576 - acc: 0.5983 - val_loss: 0.6849 - val_acc: 0.5453\n",
      "Epoch 367/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6575 - acc: 0.5980 - val_loss: 0.6848 - val_acc: 0.5454\n",
      "Epoch 368/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6583 - acc: 0.5976 - val_loss: 0.6848 - val_acc: 0.5447\n",
      "Epoch 369/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6579 - acc: 0.5959 - val_loss: 0.6845 - val_acc: 0.5459\n",
      "Epoch 370/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6580 - acc: 0.5972 - val_loss: 0.6847 - val_acc: 0.5431\n",
      "Epoch 371/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6585 - acc: 0.5975 - val_loss: 0.6843 - val_acc: 0.5470\n",
      "Epoch 372/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6576 - acc: 0.5992 - val_loss: 0.6845 - val_acc: 0.5464\n",
      "Epoch 373/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6568 - acc: 0.5991 - val_loss: 0.6847 - val_acc: 0.5439\n",
      "Epoch 374/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6581 - acc: 0.5970 - val_loss: 0.6847 - val_acc: 0.5443\n",
      "Epoch 375/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6577 - acc: 0.5967 - val_loss: 0.6849 - val_acc: 0.5466\n",
      "Epoch 376/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6573 - acc: 0.5966 - val_loss: 0.6851 - val_acc: 0.5431\n",
      "Epoch 377/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6572 - acc: 0.5976 - val_loss: 0.6846 - val_acc: 0.5465\n",
      "Epoch 378/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6569 - acc: 0.5979 - val_loss: 0.6848 - val_acc: 0.5435\n",
      "Epoch 379/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6572 - acc: 0.5989 - val_loss: 0.6845 - val_acc: 0.5462\n",
      "Epoch 380/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6580 - acc: 0.5946 - val_loss: 0.6847 - val_acc: 0.5443\n",
      "Epoch 381/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6576 - acc: 0.5985 - val_loss: 0.6848 - val_acc: 0.5444\n",
      "Epoch 382/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6570 - acc: 0.5990 - val_loss: 0.6849 - val_acc: 0.5475\n",
      "Epoch 383/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6573 - acc: 0.5962 - val_loss: 0.6850 - val_acc: 0.5443\n",
      "Epoch 384/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6574 - acc: 0.6000 - val_loss: 0.6850 - val_acc: 0.5459\n",
      "Epoch 385/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6578 - acc: 0.5981 - val_loss: 0.6848 - val_acc: 0.5448\n",
      "Epoch 386/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6573 - acc: 0.5983 - val_loss: 0.6850 - val_acc: 0.5433\n",
      "Epoch 387/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6580 - acc: 0.5976 - val_loss: 0.6849 - val_acc: 0.5450\n",
      "Epoch 388/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6564 - acc: 0.5984 - val_loss: 0.6850 - val_acc: 0.5434\n",
      "Epoch 389/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6567 - acc: 0.5983 - val_loss: 0.6847 - val_acc: 0.5452\n",
      "Epoch 390/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6578 - acc: 0.5974 - val_loss: 0.6847 - val_acc: 0.5449\n",
      "Epoch 391/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6570 - acc: 0.5964 - val_loss: 0.6849 - val_acc: 0.5439\n",
      "Epoch 392/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6573 - acc: 0.5965 - val_loss: 0.6848 - val_acc: 0.5444\n",
      "Epoch 393/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6568 - acc: 0.5981 - val_loss: 0.6847 - val_acc: 0.5467\n",
      "Epoch 394/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6567 - acc: 0.5982 - val_loss: 0.6849 - val_acc: 0.5455\n",
      "Epoch 395/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6574 - acc: 0.5976 - val_loss: 0.6852 - val_acc: 0.5439\n",
      "Epoch 396/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6568 - acc: 0.6003 - val_loss: 0.6851 - val_acc: 0.5449\n",
      "Epoch 397/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6572 - acc: 0.6005 - val_loss: 0.6847 - val_acc: 0.5472\n",
      "Epoch 398/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6583 - acc: 0.5967 - val_loss: 0.6846 - val_acc: 0.5478\n",
      "Epoch 399/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6566 - acc: 0.5972 - val_loss: 0.6847 - val_acc: 0.5473\n",
      "Epoch 400/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6572 - acc: 0.5970 - val_loss: 0.6850 - val_acc: 0.5454\n",
      "Epoch 401/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6571 - acc: 0.5982 - val_loss: 0.6850 - val_acc: 0.5444\n",
      "Epoch 402/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6571 - acc: 0.5976 - val_loss: 0.6849 - val_acc: 0.5451\n",
      "Epoch 403/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6567 - acc: 0.5985 - val_loss: 0.6848 - val_acc: 0.5453\n",
      "Epoch 404/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6569 - acc: 0.5994 - val_loss: 0.6849 - val_acc: 0.5443\n",
      "Epoch 405/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6568 - acc: 0.5992 - val_loss: 0.6849 - val_acc: 0.5442\n",
      "Epoch 406/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6578 - acc: 0.5971 - val_loss: 0.6847 - val_acc: 0.5454\n",
      "Epoch 407/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6575 - acc: 0.5972 - val_loss: 0.6850 - val_acc: 0.5426\n",
      "Epoch 408/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6571 - acc: 0.5976 - val_loss: 0.6847 - val_acc: 0.5460\n",
      "Epoch 409/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6579 - acc: 0.5975 - val_loss: 0.6848 - val_acc: 0.5447\n",
      "Epoch 410/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6581 - acc: 0.5943 - val_loss: 0.6846 - val_acc: 0.5436\n",
      "Epoch 411/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6577 - acc: 0.5968 - val_loss: 0.6847 - val_acc: 0.5453\n",
      "Epoch 412/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6583 - acc: 0.5950 - val_loss: 0.6847 - val_acc: 0.5455\n",
      "Epoch 413/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6570 - acc: 0.5981 - val_loss: 0.6847 - val_acc: 0.5443\n",
      "Epoch 414/500\n",
      "68016/68016 [==============================] - 9s 132us/step - loss: 0.6568 - acc: 0.5984 - val_loss: 0.6847 - val_acc: 0.5444\n",
      "Epoch 415/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6579 - acc: 0.5964 - val_loss: 0.6846 - val_acc: 0.5443\n",
      "Epoch 416/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6579 - acc: 0.5972 - val_loss: 0.6847 - val_acc: 0.5429\n",
      "Epoch 417/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6567 - acc: 0.6003 - val_loss: 0.6848 - val_acc: 0.5443\n",
      "Epoch 418/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6566 - acc: 0.6007 - val_loss: 0.6847 - val_acc: 0.5463\n",
      "Epoch 419/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6579 - acc: 0.5969 - val_loss: 0.6847 - val_acc: 0.5437\n",
      "Epoch 420/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6575 - acc: 0.5979 - val_loss: 0.6846 - val_acc: 0.5463\n",
      "Epoch 421/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6572 - acc: 0.5987 - val_loss: 0.6849 - val_acc: 0.5434\n",
      "Epoch 422/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6562 - acc: 0.5972 - val_loss: 0.6850 - val_acc: 0.5440\n",
      "Epoch 423/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6579 - acc: 0.5985 - val_loss: 0.6849 - val_acc: 0.5463\n",
      "Epoch 424/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6565 - acc: 0.5991 - val_loss: 0.6847 - val_acc: 0.5477\n",
      "Epoch 425/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6582 - acc: 0.5961 - val_loss: 0.6849 - val_acc: 0.5435\n",
      "Epoch 426/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6574 - acc: 0.5979 - val_loss: 0.6848 - val_acc: 0.5460\n",
      "Epoch 427/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6575 - acc: 0.5993 - val_loss: 0.6848 - val_acc: 0.5447\n",
      "Epoch 428/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6568 - acc: 0.5976 - val_loss: 0.6849 - val_acc: 0.5434\n",
      "Epoch 429/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6569 - acc: 0.5986 - val_loss: 0.6850 - val_acc: 0.5438\n",
      "Epoch 430/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6572 - acc: 0.5985 - val_loss: 0.6850 - val_acc: 0.5444\n",
      "Epoch 431/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6577 - acc: 0.5950 - val_loss: 0.6851 - val_acc: 0.5449\n",
      "Epoch 432/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6577 - acc: 0.5957 - val_loss: 0.6851 - val_acc: 0.5452\n",
      "Epoch 433/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6571 - acc: 0.5989 - val_loss: 0.6850 - val_acc: 0.5439\n",
      "Epoch 434/500\n",
      "68016/68016 [==============================] - 9s 132us/step - loss: 0.6569 - acc: 0.5959 - val_loss: 0.6850 - val_acc: 0.5440\n",
      "Epoch 435/500\n",
      "68016/68016 [==============================] - 9s 132us/step - loss: 0.6567 - acc: 0.6002 - val_loss: 0.6850 - val_acc: 0.5460\n",
      "Epoch 436/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6569 - acc: 0.5992 - val_loss: 0.6847 - val_acc: 0.5475\n",
      "Epoch 437/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6565 - acc: 0.5994 - val_loss: 0.6851 - val_acc: 0.5443\n",
      "Epoch 438/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6571 - acc: 0.5970 - val_loss: 0.6849 - val_acc: 0.5475\n",
      "Epoch 439/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6577 - acc: 0.5967 - val_loss: 0.6848 - val_acc: 0.5480\n",
      "Epoch 440/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6575 - acc: 0.5958 - val_loss: 0.6849 - val_acc: 0.5434\n",
      "Epoch 441/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6564 - acc: 0.5991 - val_loss: 0.6852 - val_acc: 0.5434\n",
      "Epoch 442/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6571 - acc: 0.5967 - val_loss: 0.6851 - val_acc: 0.5428\n",
      "Epoch 443/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6566 - acc: 0.5987 - val_loss: 0.6852 - val_acc: 0.5430\n",
      "Epoch 444/500\n",
      "68016/68016 [==============================] - 9s 132us/step - loss: 0.6580 - acc: 0.5956 - val_loss: 0.6849 - val_acc: 0.5477\n",
      "Epoch 445/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6567 - acc: 0.5985 - val_loss: 0.6849 - val_acc: 0.5479\n",
      "Epoch 446/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6577 - acc: 0.5950 - val_loss: 0.6850 - val_acc: 0.5435\n",
      "Epoch 447/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6578 - acc: 0.5969 - val_loss: 0.6848 - val_acc: 0.5448\n",
      "Epoch 448/500\n",
      "68016/68016 [==============================] - 9s 132us/step - loss: 0.6565 - acc: 0.5982 - val_loss: 0.6853 - val_acc: 0.5427\n",
      "Epoch 449/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6572 - acc: 0.5986 - val_loss: 0.6851 - val_acc: 0.5439\n",
      "Epoch 450/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6565 - acc: 0.5990 - val_loss: 0.6851 - val_acc: 0.5454\n",
      "Epoch 451/500\n",
      "68016/68016 [==============================] - 9s 132us/step - loss: 0.6567 - acc: 0.5996 - val_loss: 0.6850 - val_acc: 0.5461\n",
      "Epoch 452/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6558 - acc: 0.5998 - val_loss: 0.6850 - val_acc: 0.5463\n",
      "Epoch 453/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6575 - acc: 0.5987 - val_loss: 0.6848 - val_acc: 0.5478\n",
      "Epoch 454/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6569 - acc: 0.5981 - val_loss: 0.6850 - val_acc: 0.5454\n",
      "Epoch 455/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6574 - acc: 0.5990 - val_loss: 0.6852 - val_acc: 0.5447\n",
      "Epoch 456/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6577 - acc: 0.5958 - val_loss: 0.6851 - val_acc: 0.5459\n",
      "Epoch 457/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6574 - acc: 0.5977 - val_loss: 0.6852 - val_acc: 0.5454\n",
      "Epoch 458/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6565 - acc: 0.5973 - val_loss: 0.6854 - val_acc: 0.5450\n",
      "Epoch 459/500\n",
      "68016/68016 [==============================] - 9s 130us/step - loss: 0.6572 - acc: 0.5967 - val_loss: 0.6853 - val_acc: 0.5453\n",
      "Epoch 460/500\n",
      "68016/68016 [==============================] - 9s 130us/step - loss: 0.6568 - acc: 0.5973 - val_loss: 0.6854 - val_acc: 0.5439\n",
      "Epoch 461/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6562 - acc: 0.5997 - val_loss: 0.6854 - val_acc: 0.5433\n",
      "Epoch 462/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6562 - acc: 0.5991 - val_loss: 0.6852 - val_acc: 0.5465\n",
      "Epoch 463/500\n",
      "68016/68016 [==============================] - 9s 130us/step - loss: 0.6563 - acc: 0.5993 - val_loss: 0.6853 - val_acc: 0.5454\n",
      "Epoch 464/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6567 - acc: 0.5988 - val_loss: 0.6853 - val_acc: 0.5442\n",
      "Epoch 465/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6562 - acc: 0.5998 - val_loss: 0.6854 - val_acc: 0.5441\n",
      "Epoch 466/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6563 - acc: 0.6005 - val_loss: 0.6851 - val_acc: 0.5470\n",
      "Epoch 467/500\n",
      "68016/68016 [==============================] - 9s 132us/step - loss: 0.6567 - acc: 0.5999 - val_loss: 0.6851 - val_acc: 0.5472\n",
      "Epoch 468/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6572 - acc: 0.5977 - val_loss: 0.6853 - val_acc: 0.5460\n",
      "Epoch 469/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6574 - acc: 0.5969 - val_loss: 0.6850 - val_acc: 0.5459\n",
      "Epoch 470/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6569 - acc: 0.5991 - val_loss: 0.6849 - val_acc: 0.5469\n",
      "Epoch 471/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6570 - acc: 0.5972 - val_loss: 0.6848 - val_acc: 0.5461\n",
      "Epoch 472/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6562 - acc: 0.6003 - val_loss: 0.6850 - val_acc: 0.5454\n",
      "Epoch 473/500\n",
      "68016/68016 [==============================] - 9s 132us/step - loss: 0.6575 - acc: 0.5984 - val_loss: 0.6851 - val_acc: 0.5452\n",
      "Epoch 474/500\n",
      "68016/68016 [==============================] - 9s 132us/step - loss: 0.6575 - acc: 0.6002 - val_loss: 0.6850 - val_acc: 0.5459\n",
      "Epoch 475/500\n",
      "68016/68016 [==============================] - 9s 132us/step - loss: 0.6567 - acc: 0.5993 - val_loss: 0.6852 - val_acc: 0.5430\n",
      "Epoch 476/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6566 - acc: 0.5977 - val_loss: 0.6853 - val_acc: 0.5422\n",
      "Epoch 477/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6568 - acc: 0.5980 - val_loss: 0.6853 - val_acc: 0.5442\n",
      "Epoch 478/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6575 - acc: 0.5975 - val_loss: 0.6849 - val_acc: 0.5477\n",
      "Epoch 479/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6567 - acc: 0.5988 - val_loss: 0.6850 - val_acc: 0.5466\n",
      "Epoch 480/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6575 - acc: 0.5972 - val_loss: 0.6850 - val_acc: 0.5459\n",
      "Epoch 481/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6572 - acc: 0.5967 - val_loss: 0.6851 - val_acc: 0.5444\n",
      "Epoch 482/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6571 - acc: 0.5986 - val_loss: 0.6850 - val_acc: 0.5448\n",
      "Epoch 483/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6576 - acc: 0.5974 - val_loss: 0.6850 - val_acc: 0.5451\n",
      "Epoch 484/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6566 - acc: 0.5978 - val_loss: 0.6850 - val_acc: 0.5467\n",
      "Epoch 485/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6564 - acc: 0.5986 - val_loss: 0.6850 - val_acc: 0.5464\n",
      "Epoch 486/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6575 - acc: 0.5974 - val_loss: 0.6852 - val_acc: 0.5438\n",
      "Epoch 487/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6569 - acc: 0.5997 - val_loss: 0.6852 - val_acc: 0.5458\n",
      "Epoch 488/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6568 - acc: 0.5983 - val_loss: 0.6854 - val_acc: 0.5423\n",
      "Epoch 489/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6568 - acc: 0.5970 - val_loss: 0.6857 - val_acc: 0.5427\n",
      "Epoch 490/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6569 - acc: 0.5999 - val_loss: 0.6852 - val_acc: 0.5455\n",
      "Epoch 491/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6567 - acc: 0.5971 - val_loss: 0.6849 - val_acc: 0.5492\n",
      "Epoch 492/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6573 - acc: 0.5965 - val_loss: 0.6850 - val_acc: 0.5461\n",
      "Epoch 493/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6580 - acc: 0.5949 - val_loss: 0.6848 - val_acc: 0.5476\n",
      "Epoch 494/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6571 - acc: 0.5974 - val_loss: 0.6850 - val_acc: 0.5465\n",
      "Epoch 495/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6570 - acc: 0.5996 - val_loss: 0.6850 - val_acc: 0.5444\n",
      "Epoch 496/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6571 - acc: 0.5976 - val_loss: 0.6851 - val_acc: 0.5457\n",
      "Epoch 497/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6567 - acc: 0.5995 - val_loss: 0.6848 - val_acc: 0.5466\n",
      "Epoch 498/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6563 - acc: 0.5996 - val_loss: 0.6849 - val_acc: 0.5455\n",
      "Epoch 499/500\n",
      "68016/68016 [==============================] - 9s 131us/step - loss: 0.6575 - acc: 0.5976 - val_loss: 0.6849 - val_acc: 0.5465\n",
      "Epoch 500/500\n",
      "68016/68016 [==============================] - 9s 130us/step - loss: 0.6571 - acc: 0.5975 - val_loss: 0.6848 - val_acc: 0.5450\n"
     ]
    }
   ],
   "source": [
    "# Start training\n",
    "# Set up some configurations\n",
    "optimizers = {'adam': Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=None, decay=1e-2, amsgrad=False),\n",
    "              'rmsprop': RMSprop(lr=1e-2, rho=0.9, epsilon=None, decay=1e-2)}\n",
    "config = {'epochs': 500, 'batch_size': 562}\n",
    "opt = optimizers['rmsprop']\n",
    "\n",
    "model = get_hybrid(opt, num_filters = n, kernel_size = m)\n",
    "history = train(model, train_x, train_y, (val_x, val_y), config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_7 (Conv1D)            (None, 1009, 15)          615       \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 201, 15)           0         \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 201, 15)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_7 (Bidirection (None, 20)                2160      \n",
      "_________________________________________________________________\n",
      "dropout_14 (Dropout)         (None, 20)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 50)                1050      \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 1)                 51        \n",
      "=================================================================\n",
      "Total params: 3,876\n",
      "Trainable params: 3,876\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "dianostic_plots(acc, loss, val_acc, val_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model for later analysis\n",
    "save_model_path = '/home/ubuntu/data/team_neural_network/code/models'\n",
    "model_name = 'big_hybrid_net.h5'\n",
    "model.save(os.path.join(save_model_path, model_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('../../models/big_hybrid_net.h5')\n",
    "\n",
    "filters = model.layers[0].get_weights()[0]\n",
    "bias = model.layers[0].get_weights()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_name = model.layers[0].get_config()['name']\n",
    "intermediate_layer_model = Model(inputs=model.input,\n",
    "                                 outputs=model.get_layer(layer_name).output)\n",
    "intermediate_output = intermediate_layer_model.predict(val_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "activated_subseq = get_activated_subseq(intermediate_output, val_x, m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(activated_subseq):\n",
    "    char_list = get_char_list(activated_subseq[i])\n",
    "    uniques, freqs = get_freqs(char_list)\n",
    "    candidates = get_candidates(uniques, freqs, 0.45)\n",
    "    print(\"*************{}**************\".format(i))\n",
    "    print(get_motif(candidates))\n",
    "    print(\"*****************************\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
