{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Author**: Yichen Fang\n",
    "\n",
    "**Purpose**:\n",
    "\n",
    "The purpose of this notebook is to produce output files by one-hot encoding the dna sequence, and adding the tfbs scores to the one-hot encoding.\n",
    "\n",
    "The output files are saved as plain txt files in the specified output folder.\n",
    "\n",
    "**System Requirement**:\n",
    "\n",
    "The code is only **guaranteed** to work on a machine with a minimum of 32GB memory (It might work on a 16GB memory machine, but definitely not on anything smaller than 16GB). This corresponds the AWS machine with specification **t2.2xlarge**. Running through the whole file takes roughly 4 hours.\n",
    "\n",
    "\n",
    "**Important Note Before Using the File**:\n",
    "\n",
    "1. Always check all **path variables** are correct and intended. Otherwise, you may accidentally **overwrite** previous results.\n",
    "2. ALways check the motif file names corresponds to the ones you are using. Otherwise, the script would not work correctly.\n",
    "3. This file should only be used to generate outputs that contain motifs. To generate outputs without motifs attached, please use the script `producing_output_files_without_motif.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import ast\n",
    "import shelve\n",
    "import numpy as np\n",
    "from Bio import SeqIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set address variables in the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_folder_path = \"/home/ubuntu/data/team_neural_network/data/input/3.24_species_only\" + \"/\"\n",
    "output_folder_path = \"/home/ubuntu/formatted/output\" + \"/\"\n",
    "motif_folder_path = \"/home/ubuntu/raw/5_TFBS_scores_18July2018\" + \"/\"\n",
    "motif_species_shelve_path = \"/home/ubuntu/formatted/motif_dic\" # The shelve with motif as the outermost key\n",
    "species_motif_shelve_path = \"/home/ubuntu/formatted/species_motif_dic\" # The shelve with species name as the outermost key"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the motif variables in the following cell:\n",
    "\n",
    "As long as the names are distinguishable among different motifs, they are good enough to use.\n",
    "\n",
    "For example, whether you choose `zelda` or `zelda_.fm` as the motif name does not make a difference. This is because `zelda` is enough to distinguish this motif from others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motif_1 = \"zelda\"\n",
    "motif_2 = \"hb\"\n",
    "motif_3 = \"bcd\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cells import all the TFBS scores and transform them into a `shelve` (i.e. a dictionary stored in disk, rather than memory) called `all_scores`.\n",
    "\n",
    "`all_scores` has the data structure: `{motif: {species: {raw_position: score}}}`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def motif_processing(motif_name):\n",
    "    ''' Transform the motif files into the data structure specified above, one motif at a time.\n",
    "    '''\n",
    "    all_csvs = glob.glob(motif_folder_path + motif_name + '/*.csv')\n",
    "    all_scores = shelve.open(motif_species_shelve_path)\n",
    "    curr_motif = {}\n",
    "    u = 0\n",
    "    for csv_ in all_csvs:\n",
    "        with open(csv_, encoding='utf-8') as csv_file:\n",
    "            for a_line in csv_file:\n",
    "                curr_line = a_line.split('\\t')\n",
    "                strand = curr_line[6]\n",
    "                if strand == 'positive\\n':\n",
    "                    score = float(curr_line[2])\n",
    "                    species = curr_line[4]\n",
    "                    raw_position = int(curr_line[5])\n",
    "                    if species not in curr_motif:\n",
    "                        curr_motif[species] = {}\n",
    "                    curr_motif[species][raw_position] = score\n",
    "        u += 1\n",
    "        print(motif_name + ': ' + str(u))\n",
    "    all_scores[motif_name] = curr_motif\n",
    "    all_scores.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "motif_processing(motif_1)\n",
    "motif_processing(motif_2)\n",
    "motif_processing(motif_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell trnasforms the `all_scores` shelve created above into a new shelve `new_scores`.\n",
    "\n",
    "The `new_scores` has the data structure: `{species: {motif: {raw_position: score}}}`.\n",
    "\n",
    "The purpose for the transformation is that the structure of `new_scores` is quicker and more memory efficient for subsequent motif attaching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_scores = shelve.open(motif_species_shelve_path)\n",
    "new_scores = shelve.open(species_motif_shelve_path)\n",
    "\n",
    "def redesign_shelve(motif):\n",
    "    ''' Redesign the data structure as specified above, one motif at a time.\n",
    "    '''\n",
    "    v = 0\n",
    "    current_motif = all_scores[motif]\n",
    "    for species in current_motif:\n",
    "        if species not in new_scores:\n",
    "            species_dic = {}\n",
    "            species_dic[motif] = current_motif[species]\n",
    "            new_scores[species] = species_dic\n",
    "        else:\n",
    "            species_dic = new_scores[species]\n",
    "            species_dic[motif] = current_motif[species]\n",
    "            new_scores[species] = species_dic\n",
    "        v += 1\n",
    "        print(motif + \": \" + str(v))\n",
    "\n",
    "redesign_shelve(motif_1)\n",
    "redesign_shelve(motif_2)\n",
    "redesign_shelve(motif_3)\n",
    "\n",
    "new_scores.close()\n",
    "all_scores.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The aim of the following cell is to produce a one-hot encoding scheme with TFBS scores embedded for each DNA sequence segment.\n",
    "\n",
    "It consists of four parts:\n",
    "\n",
    "1. Read in all DNA sequence segments.\n",
    "2. Transform each position of the DNA sequence into a 4-letter one-hot encoding based on the `base_pairs` dictionary.\n",
    "3. For each position, attach the TFBS scores to the end of the one-hot encoding.\n",
    "4. Output the final encoding into `txt` files for bookkeeping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the following dictionary to perform the transformation\n",
    "base_pairs = {'A': [1, 0, 0, 0], \n",
    "              'C': [0, 1, 0, 0],\n",
    "              'G': [0, 0, 1, 0],\n",
    "              'T': [0, 0, 0, 1],\n",
    "              'a': [1, 0, 0, 0],\n",
    "              'c': [0, 1, 0, 0],\n",
    "              'g': [0, 0, 1, 0],\n",
    "              't': [0, 0, 0, 1],\n",
    "              'n': [0, 0, 0, 0],\n",
    "              'N': [0, 0, 0, 0]}\n",
    "\n",
    "# The maximum number of files to be decoded\n",
    "file_num_limit = 10000\n",
    "\n",
    "# A counter for file processing\n",
    "file_count = 0\n",
    "\n",
    "def lacking_motif(sequence):\n",
    "    ''' Return True if one or more motifs are missing for a sequence.\n",
    "        Otherwise, return False.\n",
    "    '''\n",
    "    if motif_1 not in sequence:\n",
    "        return True\n",
    "    elif motif_2 not in sequence:\n",
    "        return True\n",
    "    elif motif_3 not in sequence:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "new_scores = shelve.open(species_motif_shelve_path)\n",
    "\n",
    "# Iterate through every file\n",
    "for file in os.listdir(input_folder_path):\n",
    "    one_hot = []\n",
    "    # When the number of file decoded has reached the limit, stop\n",
    "    if file_count < file_num_limit:\n",
    "        data = list(SeqIO.parse(input_folder_path + file,\"fasta\"))\n",
    "        for n in range(0, len(data)):\n",
    "            # Extract the header information\n",
    "            header = data[n].description.split('|')\n",
    "            descr = data[n].description\n",
    "            regionID = header[0]\n",
    "            expressed = header[1]\n",
    "            speciesID = header[2]\n",
    "            strand = header[3]\n",
    "            # Complement all sequences in the negative DNA strand\n",
    "            if strand == '-':\n",
    "                # Using the syntax [e for e in base_pairs[n]] to create a new pointer for each position\n",
    "                one_hot.append([descr, expressed, speciesID, [[e for e in base_pairs[n]] for n in data[n].seq.complement()]])\n",
    "            else:\n",
    "                one_hot.append([descr, expressed, speciesID, [[e for e in base_pairs[n]] for n in data[n].seq]])\n",
    "        # Attach the TFBS scores to the end of each position\n",
    "        to_write = True\n",
    "        for item in one_hot:\n",
    "            # Only outputs sequences that currently have TFBS scores\n",
    "            # Ignore all sequences that do not have TFBS scores yet\n",
    "            sequence_name = item[0]\n",
    "            if sequence_name not in new_scores:\n",
    "                to_write = False\n",
    "                break\n",
    "            current_sequence = new_scores[sequence_name]\n",
    "            if lacking_motif(current_sequence):\n",
    "                to_write = False\n",
    "                break\n",
    "            i = 0\n",
    "            for encoding in item[3]:\n",
    "                # Take care of positions that do not have TFBS scores, attaching 0 as placeholder (i.e. NA)\n",
    "                if i not in current_sequence[motif_1]:\n",
    "                    encoding.extend([0, 0, 0])\n",
    "                else:\n",
    "                    encoding.append(current_sequence[motif_1][i])\n",
    "                    encoding.append(current_sequence[motif_2][i])\n",
    "                    encoding.append(current_sequence[motif_3][i])\n",
    "                i += 1\n",
    "        # Write the final encoding into txt files\n",
    "        if to_write:\n",
    "            with open(output_folder_path + regionID + \".txt\", mode=\"w\", encoding='utf-8') as output:\n",
    "                output.write(str(one_hot))\n",
    "            file_count += 1\n",
    "            print(\"output: \" + str(file_count))\n",
    "\n",
    "new_scores.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Environment (conda_tensorflow_p36)",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
